[
  {
    "name": "main.go",
    "content": "package main\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"flag\"\r\n\t\"fmt\"\r\n\t\"log\"\r\n\t\"os\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/config\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/llm\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/converter\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n)\r\n\r\nfunc main() {\r\n\t// Définition des flags de ligne de commande\r\n\tconfigPath := flag.String(\"config\", \"config.yaml\", \"Chemin vers le fichier de configuration\")\r\n\tinputFile := flag.String(\"input\", \"\", \"Chemin vers le fichier d'entrée\")\r\n\toutputFile := flag.String(\"output\", \"\", \"Chemin vers le fichier de sortie\")\r\n\tengine := flag.String(\"engine\", \"\", \"Moteur LLM à utiliser (surcharge la configuration)\")\r\n\tadditionalInstructions := flag.String(\"i\", \"\", \"Instructions supplémentaires pour le LLM\")\r\n\tflag.Parse()\r\n\r\n\t// Chargement de la configuration\r\n\terr := config.Load(*configPath)\r\n\tif err != nil {\r\n\t\tlog.Fatalf(\"Erreur lors du chargement de la configuration : %v\", err)\r\n\t}\r\n\r\n\tcfg := config.Get()\r\n\tcfg.OverrideFromEnv()\r\n\r\n\t// Surcharge du moteur LLM si spécifié en ligne de commande\r\n\tif *engine != \"\" {\r\n\t\tcfg.Conversion.Engine = *engine\r\n\t}\r\n\r\n\t// Création du client LLM\r\n\tclient, err := llm.NewLLMClient(cfg)\r\n\tif err != nil {\r\n\t\tlog.Fatalf(\"Erreur lors de la création du client LLM : %v\", err)\r\n\t}\r\n\r\n\t// Création du parseur de document\r\n\tp, err := parser.NewParser(getFileType(*inputFile))\r\n\tif err != nil {\r\n\t\tlog.Fatalf(\"Erreur lors de la création du parseur : %v\", err)\r\n\t}\r\n\r\n\t// Lecture et analyse du fichier d'entrée\r\n\tfile, err := os.Open(*inputFile)\r\n\tif err != nil {\r\n\t\tlog.Fatalf(\"Erreur lors de l'ouverture du fichier d'entrée : %v\", err)\r\n\t}\r\n\tdefer file.Close()\r\n\r\n\tdoc, err := p.Parse(file)\r\n\tif err != nil {\r\n\t\tlog.Fatalf(\"Erreur lors de l'analyse du document : %v\", err)\r\n\t}\r\n\r\n\t// Création du convertisseur\r\n\tconv := converter.NewConverter(client, cfg.Conversion.MaxTokens, cfg.Conversion.TargetBatchSize)\r\n\r\n\t// Conversion du document en JSON-LD\r\n\tctx := context.Background()\r\n\tjsonLD, err := conv.Convert(ctx, doc, *additionalInstructions)\r\n\tif err != nil {\r\n\t\tlog.Fatalf(\"Erreur lors de la conversion en JSON-LD : %v\", err)\r\n\t}\r\n\r\n\t// Écriture du résultat dans le fichier de sortie\r\n\terr = os.WriteFile(*outputFile, []byte(jsonLD), 0644)\r\n\tif err != nil {\r\n\t\tlog.Fatalf(\"Erreur lors de l'écriture du fichier de sortie : %v\", err)\r\n\t}\r\n\r\n\tfmt.Println(\"Conversion terminée avec succès.\")\r\n}\r\n\r\nfunc getFileType(filename string) string {\r\n\t// Logique pour déterminer le type de fichier basé sur l'extension\r\n\t// Cette fonction devrait être implémentée selon vos besoins\r\n\treturn \"text\" // Par défaut, on suppose que c'est un fichier texte\r\n}",
    "size": 2702,
    "modTime": "2024-10-14T18:06:16.5334761+02:00",
    "path": "cmd\\cli\\main.go"
  },
  {
    "name": "main.go",
    "content": "",
    "size": 0,
    "modTime": "2024-10-13T22:41:30.3072076+02:00",
    "path": "cmd\\server\\main.go"
  },
  {
    "name": "config.go",
    "content": "package config\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\n\t\"gopkg.in/yaml.v2\"\n)\n\ntype Config struct {\n\tServer struct {\n\t\tPort int    `yaml:\"port\"`\n\t\tHost string `yaml:\"host\"`\n\t} `yaml:\"server\"`\n\tLogging struct {\n\t\tLevel string `yaml:\"level\"`\n\t\tFile  string `yaml:\"file\"`\n\t} `yaml:\"logging\"`\n\tConversion struct {\n\t\tMaxTokens        int    `yaml:\"max_tokens\"`\n\t\tTargetBatchSize  int    `yaml:\"target_batch_size\"`\n\t\tNumThreads       int    `yaml:\"num_threads\"`\n\t\tEngine           string `yaml:\"engine\"`\n\t\tModel            string `yaml:\"model\"`\n\t\tContextSize      int    `yaml:\"context_size\"`\n\t\tTimeout          int    `yaml:\"timeout\"`\n\t\tOllamaHost       string `yaml:\"ollama_host\"`\n\t\tOllamaPort       string `yaml:\"ollama_port\"`\n\t\tAIYOUAssistantID string `yaml:\"aiyou_assistant_id\"`\n\t} `yaml:\"conversion\"`\n\tSchema struct {\n\t\tVersion string `yaml:\"version\"`\n\t} `yaml:\"schema\"`\n\tSegmentation struct {\n\t\tMaxTokens       int `yaml:\"max_tokens\"`\n\t\tTargetBatchSize int `yaml:\"target_batch_size\"`\n\t} `yaml:\"segmentation\"`\n\tSchema struct {\n\t\tFilePath string `yaml:\"file_path\"`\n\t\tVersion  string `yaml:\"version\"`\n\t} `yaml:\"schema\"`\n}\n\nvar (\n\tcfg Config\n)\n\nfunc Load(configPath string) error {\n\tdata, err := ioutil.ReadFile(configPath)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error reading config file: %v\", err)\n\t}\n\n\terr = yaml.Unmarshal(data, \u0026cfg)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error unmarshaling config: %v\", err)\n\t}\n\n\treturn nil\n}\n\nfunc Get() *Config {\n\treturn \u0026cfg\n}\n\nfunc (c *Config) OverrideFromEnv() {\n\tif port := os.Getenv(\"SERVER_PORT\"); port != \"\" {\n\t\tfmt.Sscanf(port, \"%d\", \u0026c.Server.Port)\n\t}\n\tif host := os.Getenv(\"SERVER_HOST\"); host != \"\" {\n\t\tc.Server.Host = host\n\t}\n\tif logLevel := os.Getenv(\"LOG_LEVEL\"); logLevel != \"\" {\n\t\tc.Logging.Level = logLevel\n\t}\n\tif logFile := os.Getenv(\"LOG_FILE\"); logFile != \"\" {\n\t\tc.Logging.File = logFile\n\t}\n\tif maxTokens := os.Getenv(\"MAX_TOKENS\"); maxTokens != \"\" {\n\t\tfmt.Sscanf(maxTokens, \"%d\", \u0026c.Conversion.MaxTokens)\n\t}\n\tif batchSize := os.Getenv(\"BATCH_SIZE\"); batchSize != \"\" {\n\t\tfmt.Sscanf(batchSize, \"%d\", \u0026c.Conversion.TargetBatchSize)\n\t}\n\tif numThreads := os.Getenv(\"NUM_THREADS\"); numThreads != \"\" {\n\t\tfmt.Sscanf(numThreads, \"%d\", \u0026c.Conversion.NumThreads)\n\t}\n\tif engine := os.Getenv(\"CONVERSION_ENGINE\"); engine != \"\" {\n\t\tc.Conversion.Engine = engine\n\t}\n\tif model := os.Getenv(\"CONVERSION_MODEL\"); model != \"\" {\n\t\tc.Conversion.Model = model\n\t}\n\tif contextSize := os.Getenv(\"CONTEXT_SIZE\"); contextSize != \"\" {\n\t\tfmt.Sscanf(contextSize, \"%d\", \u0026c.Conversion.ContextSize)\n\t}\n\tif timeout := os.Getenv(\"CONVERSION_TIMEOUT\"); timeout != \"\" {\n\t\tfmt.Sscanf(timeout, \"%d\", \u0026c.Conversion.Timeout)\n\t}\n\tif ollamaHost := os.Getenv(\"OLLAMA_HOST\"); ollamaHost != \"\" {\n\t\tc.Conversion.OllamaHost = ollamaHost\n\t}\n\tif ollamaPort := os.Getenv(\"OLLAMA_PORT\"); ollamaPort != \"\" {\n\t\tc.Conversion.OllamaPort = ollamaPort\n\t}\n\tif aiyouAssistantID := os.Getenv(\"AIYOU_ASSISTANT_ID\"); aiyouAssistantID != \"\" {\n\t\tc.Conversion.AIYOUAssistantID = aiyouAssistantID\n\t}\n\tif schemaVersion := os.Getenv(\"SCHEMA_VERSION\"); schemaVersion != \"\" {\n\t\tc.Schema.Version = schemaVersion\n\t}\n}\n",
    "size": 3097,
    "modTime": "2024-10-14T09:44:43.6728494+02:00",
    "path": "internal\\config\\config.go"
  },
  {
    "name": "config_test.go",
    "content": "package config\r\n\r\nimport (\r\n\t\"io/ioutil\"\r\n\t\"os\"\r\n\t\"testing\"\r\n)\r\n\r\nfunc TestLoadConfig(t *testing.T) {\r\n\t// Create a temporary config file\r\n\tcontent := []byte(`\r\nserver:\r\n  port: 8080\r\n  host: localhost\r\nlogging:\r\n  level: info\r\n  file: app.log\r\nconversion:\r\n  max_tokens: 4000\r\n  target_batch_size: 1000\r\n  num_threads: 4\r\n  engine: default\r\nschema:\r\n  version: \"1.0\"\r\n`)\r\n\ttmpfile, err := ioutil.TempFile(\"\", \"config.*.yaml\")\r\n\tif err != nil {\r\n\t\tt.Fatal(err)\r\n\t}\r\n\tdefer os.Remove(tmpfile.Name())\r\n\r\n\tif _, err := tmpfile.Write(content); err != nil {\r\n\t\tt.Fatal(err)\r\n\t}\r\n\tif err := tmpfile.Close(); err != nil {\r\n\t\tt.Fatal(err)\r\n\t}\r\n\r\n\t// Test loading the config\r\n\terr = Load(tmpfile.Name())\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"Failed to load config: %v\", err)\r\n\t}\r\n\r\n\tcfg := Get()\r\n\r\n\t// Check if values are correctly loaded\r\n\tif cfg.Server.Port != 8080 {\r\n\t\tt.Errorf(\"Expected server port 8080, got %d\", cfg.Server.Port)\r\n\t}\r\n\tif cfg.Logging.Level != \"info\" {\r\n\t\tt.Errorf(\"Expected logging level info, got %s\", cfg.Logging.Level)\r\n\t}\r\n\tif cfg.Conversion.MaxTokens != 4000 {\r\n\t\tt.Errorf(\"Expected max tokens 4000, got %d\", cfg.Conversion.MaxTokens)\r\n\t}\r\n\tif cfg.Schema.Version != \"1.0\" {\r\n\t\tt.Errorf(\"Expected schema version 1.0, got %s\", cfg.Schema.Version)\r\n\t}\r\n}\r\n\r\nfunc TestOverrideFromEnv(t *testing.T) {\r\n\t// Set environment variables\r\n\tos.Setenv(\"SERVER_PORT\", \"9090\")\r\n\tos.Setenv(\"LOG_LEVEL\", \"debug\")\r\n\tos.Setenv(\"MAX_TOKENS\", \"5000\")\r\n\tos.Setenv(\"SCHEMA_VERSION\", \"2.0\")\r\n\r\n\tcfg := \u0026Config{}\r\n\tcfg.OverrideFromEnv()\r\n\r\n\t// Check if values are correctly overridden\r\n\tif cfg.Server.Port != 9090 {\r\n\t\tt.Errorf(\"Expected server port 9090, got %d\", cfg.Server.Port)\r\n\t}\r\n\tif cfg.Logging.Level != \"debug\" {\r\n\t\tt.Errorf(\"Expected logging level debug, got %s\", cfg.Logging.Level)\r\n\t}\r\n\tif cfg.Conversion.MaxTokens != 5000 {\r\n\t\tt.Errorf(\"Expected max tokens 5000, got %d\", cfg.Conversion.MaxTokens)\r\n\t}\r\n\tif cfg.Schema.Version != \"2.0\" {\r\n\t\tt.Errorf(\"Expected schema version 2.0, got %s\", cfg.Schema.Version)\r\n\t}\r\n\r\n\t// Clean up\r\n\tos.Unsetenv(\"SERVER_PORT\")\r\n\tos.Unsetenv(\"LOG_LEVEL\")\r\n\tos.Unsetenv(\"MAX_TOKENS\")\r\n\tos.Unsetenv(\"SCHEMA_VERSION\")\r\n}\r\n",
    "size": 2149,
    "modTime": "2024-10-13T22:51:53.3523317+02:00",
    "path": "internal\\config\\config_test.go"
  },
  {
    "name": "converter.go",
    "content": "package jsonld\r\n\r\nimport (\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/llm\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/schema\"\r\n\t\"github.com/chrlesur/json-ld-converter/pkg/tokenizer\"\r\n)\r\n\r\ntype Converter struct {\r\n\tschemaVocabulary       *schema.Vocabulary\r\n\tllmClient              llm.TranslationClient\r\n\tmaxTokens              int\r\n\tadditionalInstructions string\r\n}\r\n\r\nfunc NewConverter(vocabulary *schema.Vocabulary, client llm.TranslationClient, maxTokens int, instructions string) *Converter {\r\n\treturn \u0026Converter{\r\n\t\tschemaVocabulary:       vocabulary,\r\n\t\tllmClient:              client,\r\n\t\tmaxTokens:              maxTokens,\r\n\t\tadditionalInstructions: instructions,\r\n\t}\r\n}\r\n\r\nfunc (c *Converter) Convert(segment *parser.DocumentSegment) (map[string]interface{}, error) {\r\n    // Vérifier si le contenu dépasse la limite de tokens\r\n    if tokenizer.CountTokens(segment.Content) \u003e c.maxTokens {\r\n        return nil, \u0026TokenLimitError{Limit: c.maxTokens, Count: tokenizer.CountTokens(segment.Content)}\r\n    }\r\n\r\n    // Initialiser la structure JSON-LD de base\r\n    jsonLD := map[string]interface{}{\r\n        \"@context\": \"https://schema.org\",\r\n    }\r\n\r\n    // Utiliser le LLM pour enrichir la conversion\r\n    enrichedContent, err := c.enrichContentWithLLM(segment.Content)\r\n    if err != nil {\r\n        return nil, \u0026ConversionError{Stage: \"enrichissement\", Err: err}\r\n    }\r\n\r\n    // Déterminer le type principal\r\n    mainType, err := c.determineMainType(enrichedContent)\r\n    if err != nil {\r\n        // Stratégie de repli : utiliser \"Thing\" comme type par défaut\r\n        mainType = \"Thing\"\r\n        jsonLD[\"@type\"] = mainType\r\n    }\r\n\r\n    // Gérer les structures imbriquées\r\n    nestedContent, err := c.handleNestedStructures(enrichedContent, mainType)\r\n    if err != nil {\r\n        // Stratégie de repli : utiliser une structure plate si la structure imbriquée échoue\r\n        nestedContent, err = c.extractProperties(enrichedContent, mainType)\r\n        if err != nil {\r\n            return nil, \u0026ConversionError{Stage: \"extraction des propriétés\", Err: err}\r\n        }\r\n    }\r\n\r\n    // Ajouter le contenu imbriqué à la structure JSON-LD\r\n    for key, value := range nestedContent {\r\n        jsonLD[key] = value\r\n    }\r\n\r\n    // Appliquer les instructions supplémentaires\r\n    jsonLD, err = c.applyAdditionalInstructions(jsonLD)\r\n    if err != nil {\r\n        // Ignorer l'erreur des instructions supplémentaires et continuer avec le JSON-LD non modifié\r\n        fmt.Printf(\"Avertissement : impossible d'appliquer les instructions supplémentaires : %v\\n\", err)\r\n    }\r\n\r\n    // Vérifier la limite de tokens\r\n    if err := c.checkTokenLimit(jsonLD); err != nil {\r\n        return nil, \u0026TokenLimitError{Limit: c.maxTokens, Count: tokenizer.CountTokens(fmt.Sprintf(\"%v\", jsonLD))}\r\n    }\r\n\r\n    return jsonLD, nil\r\n}\r\n\r\nfunc (c *Converter) enrichContentWithLLM(content string) (string, error) {\r\n\tprompt := fmt.Sprintf(\"Analysez et enrichissez sémantiquement le contenu suivant : %s\", content)\r\n\tenrichedContent, err := c.llmClient.Translate(prompt, \"français\", \"français\", \"\")\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"erreur lors de l'appel au LLM : %w\", err)\r\n\t}\r\n\treturn enrichedContent, nil\r\n}\r\n\r\nfunc (c *Converter) mapToSchemaOrg(content string) (map[string]interface{}, error) {\r\n\t// Analyser le contenu pour déterminer le type principal\r\n\tmainType, err := c.determineMainType(content)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"erreur lors de la détermination du type principal : %w\", err)\r\n\t}\r\n\r\n\t// Initialiser la structure JSON-LD avec le type principal\r\n\tjsonLD := map[string]interface{}{\r\n\t\t\"@type\": mainType,\r\n\t}\r\n\r\n\t// Extraire et mapper les propriétés pertinentes\r\n\tproperties, err := c.extractProperties(content, mainType)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"erreur lors de l'extraction des propriétés : %w\", err)\r\n\t}\r\n\r\n\t// Ajouter les propriétés à la structure JSON-LD\r\n\tfor key, value := range properties {\r\n\t\tjsonLD[key] = value\r\n\t}\r\n\r\n\treturn jsonLD, nil\r\n}\r\n\r\nfunc (c *Converter) determineMainType(content string) (string, error) {\r\n\t// Utiliser le LLM pour déterminer le type principal du contenu\r\n\tprompt := fmt.Sprintf(\"Déterminez le type Schema.org le plus approprié pour le contenu suivant : %s\", content)\r\n\tresponse, err := c.llmClient.Translate(prompt, \"français\", \"français\", \"\")\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"erreur lors de l'appel au LLM : %w\", err)\r\n\t}\r\n\r\n\t// Vérifier si le type retourné existe dans le vocabulaire Schema.org\r\n\tif !c.schemaVocabulary.TypeExists(response) {\r\n\t\treturn \"Thing\", nil // Utiliser \"Thing\" comme type par défaut si le type n'est pas reconnu\r\n\t}\r\n\r\n\treturn response, nil\r\n}\r\n\r\nfunc (c *Converter) extractProperties(content string, mainType string) (map[string]interface{}, error) {\r\n\tproperties := make(map[string]interface{})\r\n\r\n\t// Obtenir les propriétés applicables pour le type principal\r\n\tapplicableProperties := c.schemaVocabulary.GetPropertiesForType(mainType)\r\n\r\n\t// Utiliser le LLM pour extraire les valeurs des propriétés applicables\r\n\tfor _, prop := range applicableProperties {\r\n\t\tprompt := fmt.Sprintf(\"Extrayez la valeur de la propriété '%s' pour un objet de type '%s' à partir du contenu suivant : %s\", prop, mainType, content)\r\n\t\tvalue, err := c.llmClient.Translate(prompt, \"français\", \"français\", \"\")\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"erreur lors de l'extraction de la propriété '%s' : %w\", prop, err)\r\n\t\t}\r\n\r\n\t\tif value != \"\" {\r\n\t\t\tproperties[prop] = value\r\n\t\t}\r\n\t}\r\n\r\n\treturn properties, nil\r\n}\r\n\r\nfunc (c *Converter) checkTokenLimit(jsonLD map[string]interface{}) error {\r\n\tjsonString, err := json.Marshal(jsonLD)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"erreur lors de la sérialisation JSON : %w\", err)\r\n\t}\r\n\r\n\ttokenCount := tokenizer.CountTokens(string(jsonString))\r\n\tif tokenCount \u003e c.maxTokens {\r\n\t\treturn fmt.Errorf(\"la limite de tokens (%d) a été dépassée : %d tokens\", c.maxTokens, tokenCount)\r\n\t}\r\n\r\n\treturn nil\r\n}\r\n\r\nfunc (c *Converter) handleNestedStructures(content string, mainType string) (map[string]interface{}, error) {\r\n    jsonLD := make(map[string]interface{})\r\n    jsonLD[\"@type\"] = mainType\r\n\r\n    properties, err := c.extractProperties(content, mainType)\r\n    if err != nil {\r\n        return nil, \u0026ConversionError{Stage: \"extraction des propriétés\", Err: err}\r\n    }\r\n\r\n    for key, value := range properties {\r\n        if c.schemaVocabulary.IsObjectProperty(mainType, key) {\r\n            nestedType, err := c.schemaVocabulary.GetExpectedType(mainType, key)\r\n            if err != nil {\r\n                // Stratégie de repli : utiliser \"Thing\" comme type par défaut pour les propriétés d'objet\r\n                nestedType = \"Thing\"\r\n            }\r\n            \r\n            nestedContent, err := c.extractNestedContent(content, key)\r\n            if err != nil {\r\n                // Stratégie de repli : utiliser la valeur extraite comme contenu texte simple\r\n                jsonLD[key] = value\r\n                continue\r\n            }\r\n\r\n            nestedStructure, err := c.handleNestedStructures(nestedContent, nestedType)\r\n            if err != nil {\r\n                // Stratégie de repli : utiliser une structure plate pour le contenu imbriqué\r\n                jsonLD[key] = map[string]interface{}{\r\n                    \"@type\": nestedType,\r\n                    \"text\":  nestedContent,\r\n                }\r\n            } else {\r\n                jsonLD[key] = nestedStructure\r\n            }\r\n        } else {\r\n            jsonLD[key] = value\r\n        }\r\n    }\r\n\r\n    return jsonLD, nil\r\n}\r\n\r\nfunc (c *Converter) extractNestedContent(content string, property string) (string, error) {\r\n\tprompt := fmt.Sprintf(\"Extrayez le contenu spécifique à la propriété '%s' à partir du texte suivant : %s\", property, content)\r\n\tnestedContent, err := c.llmClient.Translate(prompt, \"français\", \"français\", \"\")\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"erreur lors de l'extraction du contenu imbriqué : %w\", err)\r\n\t}\r\n\treturn nestedContent, nil\r\n}\r\n\r\nfunc (c *Converter) applyAdditionalInstructions(jsonLD map[string]interface{}) (map[string]interface{}, error) {\r\n\tif c.additionalInstructions == \"\" {\r\n\t\treturn jsonLD, nil\r\n\t}\r\n\r\n\tprompt := fmt.Sprintf(\"Appliquez les instructions suivantes au JSON-LD : %s\\nJSON-LD actuel : %v\",\r\n\t\tc.additionalInstructions, jsonLD)\r\n\r\n\tresponse, err := c.llmClient.Translate(prompt, \"français\", \"français\", \"\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"erreur lors de l'application des instructions supplémentaires : %w\", err)\r\n\t}\r\n\r\n\tvar modifiedJsonLD map[string]interface{}\r\n\terr = json.Unmarshal([]byte(response), \u0026modifiedJsonLD)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"erreur lors de la désérialisation du JSON-LD modifié : %w\", err)\r\n\t}\r\n\r\n\treturn modifiedJsonLD, nil\r\n}\r\n\r\nfunc (c *Converter) splitContent(content string) []string {\r\n\ttokens := tokenizer.Tokenize(content)\r\n\tvar segments []string\r\n\tvar currentSegment []string\r\n\r\n\tfor _, token := range tokens {\r\n\t\tif len(currentSegment)+1 \u003e c.maxTokens/2 { // Utilisation de la moitié de la limite pour laisser de la place à la structure JSON-LD\r\n\t\t\tsegments = append(segments, strings.Join(currentSegment, \" \"))\r\n\t\t\tcurrentSegment = []string{}\r\n\t\t}\r\n\t\tcurrentSegment = append(currentSegment, token)\r\n\t}\r\n\r\n\tif len(currentSegment) \u003e 0 {\r\n\t\tsegments = append(segments, strings.Join(currentSegment, \" \"))\r\n\t}\r\n\r\n\treturn segments\r\n}\r\n\r\nfunc (c *Converter) convertLargeDocument(content string) ([]map[string]interface{}, error) {\r\n\tsegments := c.splitContent(content)\r\n\tvar results []map[string]interface{}\r\n\r\n\tfor i, segment := range segments {\r\n\t\tjsonLD, err := c.convertSegment(segment)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"erreur lors de la conversion du segment %d : %w\", i, err)\r\n\t\t}\r\n\r\n\t\t// Ajouter des métadonnées pour indiquer la segmentation\r\n\t\tjsonLD[\"segment\"] = map[string]interface{}{\r\n\t\t\t\"index\": i + 1,\r\n\t\t\t\"total\": len(segments),\r\n\t\t}\r\n\r\n\t\tresults = append(results, jsonLD)\r\n\t}\r\n\r\n\treturn results, nil\r\n}\r\n\r\nfunc (c *Converter) convertSegment(segment string) (map[string]interface{}, error) {\r\n\t// Utiliser la méthode Convert existante\r\n\treturn c.Convert(\u0026parser.DocumentSegment{Content: segment})\r\n}\r\n",
    "size": 10357,
    "modTime": "2024-10-14T18:31:27.1284785+02:00",
    "path": "internal\\jsonld\\converter.go"
  },
  {
    "name": "converter_test.go",
    "content": "package jsonld\r\n\r\nimport (\r\n\t\"testing\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/schema\"\r\n\t\"github.com/stretchr/testify/assert\"\r\n)\r\n\r\n// Mock du client LLM pour les tests\r\ntype mockLLMClient struct{}\r\n\r\nfunc (m *mockLLMClient) Translate(content, sourceLang, targetLang, additionalInstruction string) (string, error) {\r\n\t// Simuler une réponse simple pour les tests\r\n\treturn \"Contenu enrichi: \" + content, nil\r\n}\r\n\r\nfunc TestConvert(t *testing.T) {\r\n\t// Créer une instance de test du convertisseur\r\n\tmockVocabulary := schema.NewVocabulary() // Assurez-vous d'avoir une implémentation de test pour le vocabulaire\r\n\tmockLLM := \u0026mockLLMClient{}\r\n\tconverter := NewConverter(mockVocabulary, mockLLM, 1000, \"\")\r\n\r\n\ttestCases := []struct {\r\n\t\tname           string\r\n\t\tinput          string\r\n\t\texpectedOutput map[string]interface{}\r\n\t\texpectedError  error\r\n\t}{\r\n\t\t{\r\n\t\t\tname:  \"Conversion simple\",\r\n\t\t\tinput: \"Ceci est un test\",\r\n\t\t\texpectedOutput: map[string]interface{}{\r\n\t\t\t\t\"@context\": \"https://schema.org\",\r\n\t\t\t\t\"@type\":    \"Thing\",\r\n\t\t\t\t\"text\":     \"Contenu enrichi: Ceci est un test\",\r\n\t\t\t},\r\n\t\t\texpectedError: nil,\r\n\t\t},\r\n\t\t// Ajoutez d'autres cas de test ici\r\n\t}\r\n\r\n\tfor _, tc := range testCases {\r\n\t\tt.Run(tc.name, func(t *testing.T) {\r\n\t\t\tsegment := \u0026parser.DocumentSegment{Content: tc.input}\r\n\t\t\tresult, err := converter.Convert(segment)\r\n\r\n\t\t\tif tc.expectedError != nil {\r\n\t\t\t\tassert.Error(t, err)\r\n\t\t\t\tassert.Equal(t, tc.expectedError.Error(), err.Error())\r\n\t\t\t} else {\r\n\t\t\t\tassert.NoError(t, err)\r\n\t\t\t\tassert.Equal(t, tc.expectedOutput, result)\r\n\t\t\t}\r\n\t\t})\r\n\t}\r\n}\r\n\r\nfunc TestHandleNestedStructures(t *testing.T) {\r\n\t// Test similaire pour handleNestedStructures\r\n\t// ...\r\n}\r\n\r\nfunc TestApplyAdditionalInstructions(t *testing.T) {\r\n\t// Test pour applyAdditionalInstructions\r\n\t// ...\r\n}\r\n\r\nfunc TestTokenLimitHandling(t *testing.T) {\r\n\t// Test pour vérifier la gestion des limites de tokens\r\n\t// ...\r\n}\r\n\r\nfunc TestIntegration(t *testing.T) {\r\n\t// Test d'intégration simulant un flux complet de conversion\r\n\t// ...\r\n}\r\n",
    "size": 2097,
    "modTime": "2024-10-14T18:32:11.3227115+02:00",
    "path": "internal\\jsonld\\converter_test.go"
  },
  {
    "name": "error.go",
    "content": "package jsonld\r\n\r\nimport (\r\n\t\"fmt\"\r\n)\r\n\r\ntype ConversionError struct {\r\n\tStage string\r\n\tErr   error\r\n}\r\n\r\nfunc (e *ConversionError) Error() string {\r\n\treturn fmt.Sprintf(\"erreur de conversion lors de l'étape '%s': %v\", e.Stage, e.Err)\r\n}\r\n\r\ntype TokenLimitError struct {\r\n\tLimit int\r\n\tCount int\r\n}\r\n\r\nfunc (e *TokenLimitError) Error() string {\r\n\treturn fmt.Sprintf(\"limite de tokens dépassée : %d tokens (limite : %d)\", e.Count, e.Limit)\r\n}\r\n\r\ntype SchemaOrgError struct {\r\n\tType string\r\n\tErr  error\r\n}\r\n\r\nfunc (e *SchemaOrgError) Error() string {\r\n\treturn fmt.Sprintf(\"erreur liée au vocabulaire Schema.org pour le type '%s': %v\", e.Type, e.Err)\r\n}\r\n",
    "size": 655,
    "modTime": "2024-10-14T18:29:16.4992712+02:00",
    "path": "internal\\jsonld\\error.go"
  },
  {
    "name": "aiyou.go",
    "content": "package llm\r\n\r\nimport (\r\n    \"bytes\"\r\n    \"context\"\r\n    \"encoding/json\"\r\n    \"fmt\"\r\n    \"io/ioutil\"\r\n    \"net/http\"\r\n    \"time\"\r\n)\r\n\r\nconst AIYOUAPIURL = \"https://ai.dragonflygroup.fr/api\"\r\n\r\n// AIYOUClient implémente l'interface LLMClient pour AI.YOU\r\ntype AIYOUClient struct {\r\n    Token       string\r\n    AssistantID string\r\n    Timeout     time.Duration\r\n    HTTPClient  *http.Client\r\n}\r\n\r\n// NewAIYOUClient crée et retourne une nouvelle instance de AIYOUClient\r\nfunc NewAIYOUClient(assistantID string, timeout time.Duration) *AIYOUClient {\r\n    return \u0026AIYOUClient{\r\n        AssistantID: assistantID,\r\n        Timeout:     timeout,\r\n        HTTPClient:  \u0026http.Client{Timeout: timeout},\r\n    }\r\n}\r\n\r\n// Login effectue l'authentification auprès de l'API AI.YOU\r\nfunc (c *AIYOUClient) Login(email, password string) error {\r\n    loginData := map[string]string{\r\n        \"email\":    email,\r\n        \"password\": password,\r\n    }\r\n    jsonData, err := json.Marshal(loginData)\r\n    if err != nil {\r\n        return fmt.Errorf(\"error marshaling login data: %w\", err)\r\n    }\r\n\r\n    resp, err := c.makeAPICall(\"/login\", \"POST\", jsonData)\r\n    if err != nil {\r\n        return fmt.Errorf(\"login error: %w\", err)\r\n    }\r\n\r\n    var loginResp struct {\r\n        Token string `json:\"token\"`\r\n    }\r\n    if err := json.Unmarshal(resp, \u0026loginResp); err != nil {\r\n        return fmt.Errorf(\"error unmarshaling login response: %w\", err)\r\n    }\r\n\r\n    c.Token = loginResp.Token\r\n    return nil\r\n}\r\n\r\n// Translate implémente la méthode de l'interface LLMClient pour AI.YOU\r\nfunc (c *AIYOUClient) Translate(ctx context.Context, content, sourceLang, targetLang, additionalInstructions string) (string, error) {\r\n    threadID, err := c.createThread()\r\n    if err != nil {\r\n        return \"\", fmt.Errorf(\"error creating thread: %w\", err)\r\n    }\r\n\r\n    prompt := fmt.Sprintf(`Translate the following text from %s to %s. %s\r\n\r\nText to translate:\r\n%s\r\n\r\nTranslated text:`, sourceLang, targetLang, additionalInstructions, content)\r\n\r\n    if err := c.addMessage(threadID, prompt); err != nil {\r\n        return \"\", fmt.Errorf(\"error adding message to thread: %w\", err)\r\n    }\r\n\r\n    runID, err := c.createRun(threadID)\r\n    if err != nil {\r\n        return \"\", fmt.Errorf(\"error creating run: %w\", err)\r\n    }\r\n\r\n    completedRun, err := c.waitForCompletion(threadID, runID)\r\n    if err != nil {\r\n        return \"\", fmt.Errorf(\"error waiting for run completion: %w\", err)\r\n    }\r\n\r\n    response, ok := (*completedRun)[\"response\"].(string)\r\n    if !ok {\r\n        return \"\", fmt.Errorf(\"response could not be extracted from the run\")\r\n    }\r\n\r\n    return response, nil\r\n}\r\n\r\n// Les méthodes suivantes sont des utilitaires pour interagir avec l'API AI.YOU\r\n\r\nfunc (c *AIYOUClient) createThread() (string, error) {\r\n    resp, err := c.makeAPICall(\"/v1/threads\", \"POST\", []byte(\"{}\"))\r\n    if err != nil {\r\n        return \"\", err\r\n    }\r\n\r\n    var threadResp struct {\r\n        ID string `json:\"id\"`\r\n    }\r\n    if err := json.Unmarshal(resp, \u0026threadResp); err != nil {\r\n        return \"\", fmt.Errorf(\"error unmarshaling thread response: %w\", err)\r\n    }\r\n\r\n    return threadResp.ID, nil\r\n}\r\n\r\nfunc (c *AIYOUClient) addMessage(threadID, content string) error {\r\n    messageData := map[string]string{\r\n        \"role\":    \"user\",\r\n        \"content\": content,\r\n    }\r\n    jsonData, err := json.Marshal(messageData)\r\n    if err != nil {\r\n        return fmt.Errorf(\"error marshaling message data: %w\", err)\r\n    }\r\n\r\n    _, err = c.makeAPICall(fmt.Sprintf(\"/v1/threads/%s/messages\", threadID), \"POST\", jsonData)\r\n    return err\r\n}\r\n\r\nfunc (c *AIYOUClient) createRun(threadID string) (string, error) {\r\n    runData := map[string]string{\r\n        \"assistantId\": c.AssistantID,\r\n    }\r\n    jsonData, err := json.Marshal(runData)\r\n    if err != nil {\r\n        return \"\", fmt.Errorf(\"error marshaling run data: %w\", err)\r\n    }\r\n\r\n    resp, err := c.makeAPICall(fmt.Sprintf(\"/v1/threads/%s/runs\", threadID), \"POST\", jsonData)\r\n    if err != nil {\r\n        return \"\", err\r\n    }\r\n\r\n    var runResp struct {\r\n        ID string `json:\"id\"`\r\n    }\r\n    if err := json.Unmarshal(resp, \u0026runResp); err != nil {\r\n        return \"\", fmt.Errorf(\"error unmarshaling run response: %w\", err)\r\n    }\r\n\r\n    return runResp.ID, nil\r\n}\r\n\r\nfunc (c *AIYOUClient) waitForCompletion(threadID, runID string) (*map[string]interface{}, error) {\r\n    for i := 0; i \u003c 30; i++ {\r\n        run, err := c.retrieveRun(threadID, runID)\r\n        if err != nil {\r\n            return nil, err\r\n        }\r\n\r\n        status, ok := run[\"status\"].(string)\r\n        if !ok {\r\n            return nil, fmt.Errorf(\"run status not found or invalid\")\r\n        }\r\n\r\n        if status == \"completed\" {\r\n            return \u0026run, nil\r\n        }\r\n\r\n        if status == \"failed\" || status == \"cancelled\" {\r\n            return nil, fmt.Errorf(\"run failed with status: %s\", status)\r\n        }\r\n\r\n        time.Sleep(2 * time.Second)\r\n    }\r\n\r\n    return nil, fmt.Errorf(\"timeout waiting for run completion\")\r\n}\r\n\r\nfunc (c *AIYOUClient) retrieveRun(threadID, runID string) (map[string]interface{}, error) {\r\n    resp, err := c.makeAPICall(fmt.Sprintf(\"/v1/threads/%s/runs/%s\", threadID, runID), \"POST\", []byte(\"{}\"))\r\n    if err != nil {\r\n        return nil, err\r\n    }\r\n\r\n    var runStatus map[string]interface{}\r\n    if err := json.Unmarshal(resp, \u0026runStatus); err != nil {\r\n        return nil, fmt.Errorf(\"error unmarshaling run status: %w\", err)\r\n    }\r\n\r\n    return runStatus, nil\r\n}\r\n\r\nfunc (c *AIYOUClient) makeAPICall(endpoint, method string, data []byte) ([]byte, error) {\r\n    url := AIYOUAPIURL + endpoint\r\n    req, err := http.NewRequest(method, url, bytes.NewBuffer(data))\r\n    if err != nil {\r\n        return nil, fmt.Errorf(\"error creating HTTP request: %w\", err)\r\n    }\r\n\r\n    req.Header.Set(\"Content-Type\", \"application/json\")\r\n    if c.Token != \"\" {\r\n        req.Header.Set(\"Authorization\", \"Bearer \"+c.Token)\r\n    }\r\n\r\n    resp, err := c.HTTPClient.Do(req)\r\n    if err != nil {\r\n        return nil, fmt.Errorf(\"error sending request to AI.YOU API: %w\", err)\r\n    }\r\n    defer resp.Body.Close()\r\n\r\n    body, err := ioutil.ReadAll(resp.Body)\r\n    if err != nil {\r\n        return nil, fmt.Errorf(\"error reading response body: %w\", err)\r\n    }\r\n\r\n    if resp.StatusCode != http.StatusOK \u0026\u0026 resp.StatusCode != http.StatusCreated {\r\n        return nil, fmt.Errorf(\"API error (%d): %s\", resp.StatusCode, string(body))\r\n    }\r\n\r\n    return body, nil\r\n}",
    "size": 6469,
    "modTime": "2024-10-14T09:40:16.8137359+02:00",
    "path": "internal\\llm\\aiyou.go"
  },
  {
    "name": "claude.go",
    "content": "package llm\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"context\"\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"net/http\"\r\n\t\"time\"\r\n)\r\n\r\nconst ClaudeAPIURL = \"https://api.anthropic.com/v1/messages\"\r\n\r\n// ClaudeClient implémente l'interface LLMClient pour le modèle Claude d'Anthropic\r\ntype ClaudeClient struct {\r\n\tAPIKey      string\r\n\tModel       string\r\n\tContextSize int\r\n\tTimeout     time.Duration\r\n\tHTTPClient  *http.Client\r\n}\r\n\r\n// NewClaudeClient crée et retourne une nouvelle instance de ClaudeClient\r\nfunc NewClaudeClient(apiKey, model string, contextSize int, timeout time.Duration) *ClaudeClient {\r\n\treturn \u0026ClaudeClient{\r\n\t\tAPIKey:      apiKey,\r\n\t\tModel:       model,\r\n\t\tContextSize: contextSize,\r\n\t\tTimeout:     timeout,\r\n\t\tHTTPClient:  \u0026http.Client{Timeout: timeout},\r\n\t}\r\n}\r\n\r\n// claudeRequest représente la structure de la requête à l'API Claude\r\ntype claudeRequest struct {\r\n\tModel     string    `json:\"model\"`\r\n\tMessages  []message `json:\"messages\"`\r\n\tMaxTokens int       `json:\"max_tokens\"`\r\n}\r\n\r\ntype message struct {\r\n\tRole    string `json:\"role\"`\r\n\tContent string `json:\"content\"`\r\n}\r\n\r\n// claudeResponse représente la structure de la réponse de l'API Claude\r\ntype claudeResponse struct {\r\n\tContent []struct {\r\n\t\tText string `json:\"text\"`\r\n\t} `json:\"content\"`\r\n}\r\n\r\n// Translate implémente la méthode de l'interface LLMClient pour Claude\r\nfunc (c *ClaudeClient) Translate(ctx context.Context, content, sourceLang, targetLang, additionalInstructions string) (string, error) {\r\n\tprompt := fmt.Sprintf(`Translate the following text from %s to %s. %s\r\n\r\nText to translate:\r\n%s\r\n\r\nTranslated text:`, sourceLang, targetLang, additionalInstructions, content)\r\n\r\n\treqBody := claudeRequest{\r\n\t\tModel: c.Model,\r\n\t\tMessages: []message{\r\n\t\t\t{Role: \"user\", Content: prompt},\r\n\t\t},\r\n\t\tMaxTokens: c.ContextSize,\r\n\t}\r\n\r\n\tjsonData, err := json.Marshal(reqBody)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error marshaling request body: %w\", err)\r\n\t}\r\n\r\n\treq, err := http.NewRequestWithContext(ctx, \"POST\", ClaudeAPIURL, bytes.NewBuffer(jsonData))\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error creating request: %w\", err)\r\n\t}\r\n\r\n\treq.Header.Set(\"Content-Type\", \"application/json\")\r\n\treq.Header.Set(\"x-api-key\", c.APIKey)\r\n\treq.Header.Set(\"anthropic-version\", \"2023-06-01\")\r\n\r\n\tresp, err := c.HTTPClient.Do(req)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error sending request to Claude API: %w\", err)\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\treturn \"\", fmt.Errorf(\"Claude API returned non-OK status: %d\", resp.StatusCode)\r\n\t}\r\n\r\n\tvar claudeResp claudeResponse\r\n\tif err := json.NewDecoder(resp.Body).Decode(\u0026claudeResp); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error decoding Claude API response: %w\", err)\r\n\t}\r\n\r\n\tif len(claudeResp.Content) == 0 {\r\n\t\treturn \"\", fmt.Errorf(\"no content in Claude API response\")\r\n\t}\r\n\r\n\treturn claudeResp.Content[0].Text, nil\r\n}\r\n",
    "size": 2874,
    "modTime": "2024-10-14T09:35:42.2313909+02:00",
    "path": "internal\\llm\\claude.go"
  },
  {
    "name": "factory.go",
    "content": "package llm\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"os\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/config\"\r\n)\r\n\r\n// NewLLMClient crée et retourne le client LLM approprié en fonction du type de moteur spécifié\r\nfunc NewLLMClient(cfg *config.Config) (LLMClient, error) {\r\n\tswitch cfg.Conversion.Engine {\r\n\tcase \"claude\":\r\n\t\tapiKey := os.Getenv(\"CLAUDE_API_KEY\")\r\n\t\tif apiKey == \"\" {\r\n\t\t\treturn nil, fmt.Errorf(\"CLAUDE_API_KEY environment variable is not set\")\r\n\t\t}\r\n\t\treturn NewClaudeClient(apiKey, cfg.Conversion.Model, cfg.Conversion.ContextSize, time.Duration(cfg.Conversion.Timeout)*time.Second), nil\r\n\r\n\tcase \"openai\":\r\n\t\tapiKey := os.Getenv(\"OPENAI_API_KEY\")\r\n\t\tif apiKey == \"\" {\r\n\t\t\treturn nil, fmt.Errorf(\"OPENAI_API_KEY environment variable is not set\")\r\n\t\t}\r\n\t\treturn NewOpenAIClient(apiKey, cfg.Conversion.Model, cfg.Conversion.ContextSize, time.Duration(cfg.Conversion.Timeout)*time.Second), nil\r\n\r\n\tcase \"ollama\":\r\n\t\treturn NewOllamaClient(cfg.Conversion.OllamaHost, cfg.Conversion.OllamaPort, cfg.Conversion.Model, cfg.Conversion.ContextSize, time.Duration(cfg.Conversion.Timeout)*time.Second), nil\r\n\r\n\tcase \"aiyou\":\r\n\t\tclient := NewAIYOUClient(cfg.Conversion.AIYOUAssistantID, time.Duration(cfg.Conversion.Timeout)*time.Second)\r\n\t\temail := os.Getenv(\"AIYOU_EMAIL\")\r\n\t\tpassword := os.Getenv(\"AIYOU_PASSWORD\")\r\n\t\tif email == \"\" || password == \"\" {\r\n\t\t\treturn nil, fmt.Errorf(\"AIYOU_EMAIL or AIYOU_PASSWORD environment variable is not set\")\r\n\t\t}\r\n\t\terr := client.Login(email, password)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"failed to login to AI.YOU: %w\", err)\r\n\t\t}\r\n\t\treturn client, nil\r\n\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"unsupported LLM engine: %s\", cfg.Conversion.Engine)\r\n\t}\r\n}\r\n",
    "size": 1712,
    "modTime": "2024-10-14T09:42:13.7810097+02:00",
    "path": "internal\\llm\\factory.go"
  },
  {
    "name": "interface.go",
    "content": "package llm\r\n\r\nimport (\r\n    \"context\"\r\n)\r\n\r\n// LLMClient définit l'interface commune pour tous les clients LLM\r\ntype LLMClient interface {\r\n    // Translate traduit le contenu donné en utilisant le LLM spécifié\r\n    // \r\n    // Paramètres :\r\n    // - ctx : le contexte pour la gestion des timeouts et des annulations\r\n    // - content : le contenu à traduire\r\n    // - sourceLang : la langue source du contenu\r\n    // - targetLang : la langue cible pour la traduction\r\n    // - additionalInstructions : instructions supplémentaires pour le LLM\r\n    //\r\n    // Retours :\r\n    // - string : le contenu traduit\r\n    // - error : une erreur si quelque chose s'est mal passé pendant la traduction\r\n    Translate(ctx context.Context, content, sourceLang, targetLang, additionalInstructions string) (string, error)\r\n}",
    "size": 819,
    "modTime": "2024-10-14T09:33:43.1202027+02:00",
    "path": "internal\\llm\\interface.go"
  },
  {
    "name": "ollama.go",
    "content": "package llm\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"context\"\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"net/http\"\r\n\t\"time\"\r\n)\r\n\r\n// OllamaClient implémente l'interface LLMClient pour les modèles Ollama\r\ntype OllamaClient struct {\r\n\thost        string\r\n\tport        string\r\n\tmodel       string\r\n\tcontextSize int\r\n\ttimeout     time.Duration\r\n\thttpClient  *http.Client\r\n}\r\n\r\n// NewOllamaClient crée et retourne une nouvelle instance de OllamaClient\r\nfunc NewOllamaClient(host, port, model string, contextSize int, timeout time.Duration) *OllamaClient {\r\n\treturn \u0026OllamaClient{\r\n\t\thost:        host,\r\n\t\tport:        port,\r\n\t\tmodel:       model,\r\n\t\tcontextSize: contextSize,\r\n\t\ttimeout:     timeout,\r\n\t\thttpClient:  \u0026http.Client{Timeout: timeout},\r\n\t}\r\n}\r\n\r\ntype ollamaRequest struct {\r\n\tModel   string `json:\"model\"`\r\n\tPrompt  string `json:\"prompt\"`\r\n\tStream  bool   `json:\"stream\"`\r\n\tOptions struct {\r\n\t\tNumCtx int `json:\"num_ctx\"`\r\n\t} `json:\"options\"`\r\n}\r\n\r\ntype ollamaResponse struct {\r\n\tResponse string `json:\"response\"`\r\n}\r\n\r\n// Translate implémente la méthode de l'interface LLMClient pour Ollama\r\nfunc (c *OllamaClient) Translate(ctx context.Context, content, sourceLang, targetLang, additionalInstructions string) (string, error) {\r\n\tprompt := fmt.Sprintf(`Translate the following text from %s to %s. %s\r\n\r\nText to translate:\r\n%s\r\n\r\nTranslated text:`, sourceLang, targetLang, additionalInstructions, content)\r\n\r\n\treqBody := ollamaRequest{\r\n\t\tModel:  c.model,\r\n\t\tPrompt: prompt,\r\n\t\tStream: false,\r\n\t}\r\n\treqBody.Options.NumCtx = c.contextSize\r\n\r\n\tjsonData, err := json.Marshal(reqBody)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error marshaling request body: %w\", err)\r\n\t}\r\n\r\n\turl := fmt.Sprintf(\"http://%s:%s/api/generate\", c.host, c.port)\r\n\treq, err := http.NewRequestWithContext(ctx, \"POST\", url, bytes.NewBuffer(jsonData))\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error creating request: %w\", err)\r\n\t}\r\n\r\n\treq.Header.Set(\"Content-Type\", \"application/json\")\r\n\r\n\tresp, err := c.httpClient.Do(req)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error sending request to Ollama API: %w\", err)\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\treturn \"\", fmt.Errorf(\"Ollama API returned non-OK status: %d\", resp.StatusCode)\r\n\t}\r\n\r\n\tvar ollamaResp ollamaResponse\r\n\tif err := json.NewDecoder(resp.Body).Decode(\u0026ollamaResp); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error decoding Ollama API response: %w\", err)\r\n\t}\r\n\r\n\treturn ollamaResp.Response, nil\r\n}\r\n",
    "size": 2455,
    "modTime": "2024-10-14T09:38:03.7358363+02:00",
    "path": "internal\\llm\\ollama.go"
  },
  {
    "name": "openai.go",
    "content": "package llm\r\n\r\nimport (\r\n    \"context\"\r\n    \"fmt\"\r\n    \"github.com/sashabaranov/go-openai\"\r\n    \"time\"\r\n)\r\n\r\n// OpenAIClient implémente l'interface LLMClient pour les modèles GPT d'OpenAI\r\ntype OpenAIClient struct {\r\n    client      *openai.Client\r\n    model       string\r\n    contextSize int\r\n    timeout     time.Duration\r\n}\r\n\r\n// NewOpenAIClient crée et retourne une nouvelle instance de OpenAIClient\r\nfunc NewOpenAIClient(apiKey, model string, contextSize int, timeout time.Duration) *OpenAIClient {\r\n    return \u0026OpenAIClient{\r\n        client:      openai.NewClient(apiKey),\r\n        model:       model,\r\n        contextSize: contextSize,\r\n        timeout:     timeout,\r\n    }\r\n}\r\n\r\n// Translate implémente la méthode de l'interface LLMClient pour OpenAI\r\nfunc (c *OpenAIClient) Translate(ctx context.Context, content, sourceLang, targetLang, additionalInstructions string) (string, error) {\r\n    prompt := fmt.Sprintf(`Translate the following text from %s to %s. %s\r\n\r\nText to translate:\r\n%s\r\n\r\nTranslated text:`, sourceLang, targetLang, additionalInstructions, content)\r\n\r\n    req := openai.ChatCompletionRequest{\r\n        Model: c.model,\r\n        Messages: []openai.ChatCompletionMessage{\r\n            {\r\n                Role:    openai.ChatMessageRoleUser,\r\n                Content: prompt,\r\n            },\r\n        },\r\n        MaxTokens: c.contextSize,\r\n    }\r\n\r\n    ctx, cancel := context.WithTimeout(ctx, c.timeout)\r\n    defer cancel()\r\n\r\n    resp, err := c.client.CreateChatCompletion(ctx, req)\r\n    if err != nil {\r\n        return \"\", fmt.Errorf(\"error calling OpenAI API: %w\", err)\r\n    }\r\n\r\n    if len(resp.Choices) == 0 {\r\n        return \"\", fmt.Errorf(\"no content in OpenAI API response\")\r\n    }\r\n\r\n    return resp.Choices[0].Message.Content, nil\r\n}",
    "size": 1771,
    "modTime": "2024-10-14T09:36:35.6854752+02:00",
    "path": "internal\\llm\\openai.go"
  },
  {
    "name": "logger.go",
    "content": "package logger\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"sync\"\n\t\"time\"\n)\n\ntype LogLevel int\n\nconst (\n\tDEBUG LogLevel = iota\n\tINFO\n\tWARNING\n\tERROR\n)\n\nvar (\n\tlogLevel   LogLevel\n\tlogFile    *os.File\n\tconsole    io.Writer\n\tmu         sync.Mutex\n\tsilentMode bool\n\tdebugMode  bool\n)\n\nfunc Init(level LogLevel, filePath string) error {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\n\tlogLevel = level\n\n\tif filePath != \"\" {\n\t\tvar err error\n\t\tlogFile, err = os.OpenFile(filePath, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to open log file: %w\", err)\n\t\t}\n\t}\n\n\tconsole = os.Stdout\n\treturn nil\n}\n\nfunc SetLogLevel(level LogLevel) {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tlogLevel = level\n}\n\nfunc SetSilentMode(silent bool) {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tsilentMode = silent\n}\n\nfunc SetDebugMode(debug bool) {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tdebugMode = debug\n\tif debug {\n\t\tlogLevel = DEBUG\n\t}\n}\n\nfunc log(level LogLevel, message string) {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\n\tif level \u003c logLevel {\n\t\treturn\n\t}\n\n\ttimestamp := time.Now().Format(\"2006-01-02 15:04:05\")\n\tlogMessage := fmt.Sprintf(\"[%s] %s: %s\\n\", timestamp, getLevelString(level), message)\n\n\tif logFile != nil {\n\t\tlogFile.WriteString(logMessage)\n\t}\n\n\tif !silentMode {\n\t\tfmt.Fprint(console, logMessage)\n\t}\n}\n\nfunc getLevelString(level LogLevel) string {\n\tswitch level {\n\tcase DEBUG:\n\t\treturn \"DEBUG\"\n\tcase INFO:\n\t\treturn \"INFO\"\n\tcase WARNING:\n\t\treturn \"WARNING\"\n\tcase ERROR:\n\t\treturn \"ERROR\"\n\tdefault:\n\t\treturn \"UNKNOWN\"\n\t}\n}\n\nfunc Debug(message string) {\n\tif debugMode {\n\t\tlog(DEBUG, message)\n\t}\n}\n\nfunc Info(message string) {\n\tlog(INFO, message)\n}\n\nfunc Warning(message string) {\n\tlog(WARNING, message)\n}\n\nfunc Error(message string) {\n\tlog(ERROR, message)\n}\n\nfunc Close() {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\n\tif logFile != nil {\n\t\tlogFile.Close()\n\t}\n}\n",
    "size": 1811,
    "modTime": "2024-10-13T22:44:24.2222347+02:00",
    "path": "internal\\logger\\logger.go"
  },
  {
    "name": "logger_test.go",
    "content": "package logger\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"os\"\r\n\t\"strings\"\r\n\t\"testing\"\r\n)\r\n\r\nfunc TestLogging(t *testing.T) {\r\n\t// Redirect stdout to capture output\r\n\told := os.Stdout\r\n\tr, w, _ := os.Pipe()\r\n\tos.Stdout = w\r\n\r\n\t// Initialize logger\r\n\tInit(INFO, \"\")\r\n\tSetDebugMode(true)\r\n\r\n\t// Test logging\r\n\tDebug(\"This is a debug message\")\r\n\tInfo(\"This is an info message\")\r\n\tWarning(\"This is a warning message\")\r\n\tError(\"This is an error message\")\r\n\r\n\t// Reset stdout\r\n\tw.Close()\r\n\tos.Stdout = old\r\n\r\n\tvar buf bytes.Buffer\r\n\t_, _ = buf.ReadFrom(r)\r\n\toutput := buf.String()\r\n\r\n\t// Check if all messages are present\r\n\tif !strings.Contains(output, \"DEBUG\") {\r\n\t\tt.Error(\"Debug message not found in output\")\r\n\t}\r\n\tif !strings.Contains(output, \"INFO\") {\r\n\t\tt.Error(\"Info message not found in output\")\r\n\t}\r\n\tif !strings.Contains(output, \"WARNING\") {\r\n\t\tt.Error(\"Warning message not found in output\")\r\n\t}\r\n\tif !strings.Contains(output, \"ERROR\") {\r\n\t\tt.Error(\"Error message not found in output\")\r\n\t}\r\n\r\n\t// Test silent mode\r\n\tSetSilentMode(true)\r\n\tInfo(\"This message should not appear\")\r\n\r\n\tif strings.Contains(output, \"This message should not appear\") {\r\n\t\tt.Error(\"Silent mode failed\")\r\n\t}\r\n\r\n\t// Clean up\r\n\tClose()\r\n}\r\n",
    "size": 1197,
    "modTime": "2024-10-13T22:45:07.5981593+02:00",
    "path": "internal\\logger\\logger_test.go"
  },
  {
    "name": "parallel.go",
    "content": "package parallel\r\n\r\nimport (\r\n    \"sync\"\r\n    \"time\"\r\n\r\n    \"github.com/piprate/json-gold/ld\"\r\n    \"github.com/chrlesur/json-ld-converter/internal/config\"\r\n    \"github.com/chrlesur/json-ld-converter/internal/logger\"\r\n    \"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n    \"github.com/chrlesur/json-ld-converter/internal/converter\"\r\n)\r\n\r\n// ParallelProcessor gère le traitement parallèle des documents\r\ntype ParallelProcessor struct {\r\n    numWorkers int\r\n    converter  *converter.JSONLDConverter\r\n    config     *config.Config\r\n}\r\n\r\n// NewParallelProcessor crée une nouvelle instance de ParallelProcessor\r\nfunc NewParallelProcessor(numWorkers int, cfg *config.Config) *ParallelProcessor {\r\n    return \u0026ParallelProcessor{\r\n        numWorkers: numWorkers,\r\n        converter:  converter.NewJSONLDConverter(cfg),\r\n        config:     cfg,\r\n    }\r\n}\r\n\r\n// Process traite une liste de documents en parallèle\r\nfunc (p *ParallelProcessor) Process(docs []*parser.Document) ([]*ld.RDFDataset, error) {\r\n    start := time.Now()\r\n    logger.Info(\"Démarrage du traitement parallèle\")\r\n\r\n    results := make([]*ld.RDFDataset, len(docs))\r\n    errors := make([]error, len(docs))\r\n\r\n    jobs := make(chan int, len(docs))\r\n    var wg sync.WaitGroup\r\n\r\n    // Création des workers\r\n    for w := 0; w \u003c p.numWorkers; w++ {\r\n        wg.Add(1)\r\n        go p.worker(w, jobs, docs, results, errors, \u0026wg)\r\n    }\r\n\r\n    // Envoi des tâches aux workers\r\n    for i := range docs {\r\n        jobs \u003c- i\r\n    }\r\n    close(jobs)\r\n\r\n    // Attente de la fin du traitement\r\n    wg.Wait()\r\n\r\n    // Traitement des erreurs\r\n    for i, err := range errors {\r\n        if err != nil {\r\n            logger.Error(\"Erreur lors du traitement du document %d: %v\", i, err)\r\n        }\r\n    }\r\n\r\n    duration := time.Since(start)\r\n    docsPerSecond := float64(len(docs)) / duration.Seconds()\r\n    logger.Info(\"Traitement terminé en %v. %f documents/seconde\", duration, docsPerSecond)\r\n\r\n    return results, nil\r\n}\r\n\r\n// worker est la fonction exécutée par chaque goroutine worker\r\nfunc (p *ParallelProcessor) worker(id int, jobs \u003c-chan int, docs []*parser.Document, results []*ld.RDFDataset, errors []error, wg *sync.WaitGroup) {\r\n    defer wg.Done()\r\n    for j := range jobs {\r\n        logger.Debug(\"Worker %d traite le document %d\", id, j)\r\n        result, err := p.converter.Convert(docs[j])\r\n        results[j] = result\r\n        errors[j] = err\r\n    }\r\n}",
    "size": 2433,
    "modTime": "2024-10-13T23:27:00.5171181+02:00",
    "path": "internal\\parallel\\parallel.go"
  },
  {
    "name": "parallel_test.go",
    "content": "package parallel\r\n\r\nimport (\r\n\t\"testing\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/config\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n)\r\n\r\nfunc TestParallelProcessor(t *testing.T) {\r\n\t// Création d'une configuration de test\r\n\tcfg := \u0026config.Config{}\r\n\r\n\t// Création de documents de test\r\n\tdocs := []*parser.Document{\r\n\t\t{Content: \"Document 1\"},\r\n\t\t{Content: \"Document 2\"},\r\n\t\t{Content: \"Document 3\"},\r\n\t}\r\n\r\n\t// Création du processeur parallèle\r\n\tprocessor := NewParallelProcessor(2, cfg)\r\n\r\n\t// Exécution du traitement parallèle\r\n\tresults, err := processor.Process(docs)\r\n\r\n\t// Vérification des résultats\r\n\tif err != nil {\r\n\t\tt.Errorf(\"Erreur inattendue : %v\", err)\r\n\t}\r\n\tif len(results) != len(docs) {\r\n\t\tt.Errorf(\"Nombre de résultats incorrect. Attendu : %d, Obtenu : %d\", len(docs), len(results))\r\n\t}\r\n\r\n\t// Ajoutez d'autres vérifications selon vos besoins spécifiques\r\n}\r\n",
    "size": 914,
    "modTime": "2024-10-13T23:27:31.6291038+02:00",
    "path": "internal\\parallel\\parallel_test.go"
  },
  {
    "name": "factory.go",
    "content": "package parser\r\n\r\nimport \"fmt\"\r\n\r\nfunc NewParser(fileType string) (Parser, error) {\r\n\tswitch fileType {\r\n\tcase \"text\":\r\n\t\treturn NewTextParser(), nil\r\n\tcase \"markdown\":\r\n\t\treturn NewMarkdownParser(), nil\r\n\tcase \"pdf\":\r\n\t\treturn NewPDFParser(), nil\r\n\tcase \"html\":\r\n\t\treturn NewHTMLParser(), nil\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"unsupported file type: %s\", fileType)\r\n\t}\r\n}",
    "size": 376,
    "modTime": "2024-10-14T18:49:41.5361146+02:00",
    "path": "internal\\parser\\factory.go"
  },
  {
    "name": "html.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"io\"\r\n\t\"strings\"\r\n\r\n\t\"golang.org/x/net/html\"\r\n)\r\n\r\ntype HTMLParser struct{}\r\n\r\nfunc NewHTMLParser() *HTMLParser {\r\n\treturn \u0026HTMLParser{}\r\n}\r\n\r\nfunc (p *HTMLParser) Parse(r io.Reader) (*Document, error) {\r\n\tdoc, err := html.Parse(r)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\tvar contentBuilder strings.Builder\r\n\tvar structure []DocumentElement\r\n\r\n\tvar f func(*html.Node)\r\n\tf = func(n *html.Node) {\r\n\t\tif n.Type == html.TextNode {\r\n\t\t\tcontentBuilder.WriteString(n.Data)\r\n\t\t}\r\n\t\tif n.Type == html.ElementNode {\r\n\t\t\telement := DocumentElement{\r\n\t\t\t\tType: n.Data,\r\n\t\t\t}\r\n\t\t\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\r\n\t\t\t\tf(c)\r\n\t\t\t\tif c.Type == html.TextNode {\r\n\t\t\t\t\telement.Content += c.Data\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tstructure = append(structure, element)\r\n\t\t} else {\r\n\t\t\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\r\n\t\t\t\tf(c)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tf(doc)\r\n\r\n\treturn \u0026Document{\r\n\t\tContent:   contentBuilder.String(),\r\n\t\tMetadata:  make(map[string]string),\r\n\t\tStructure: structure,\r\n\t}, nil\r\n}\r\n",
    "size": 1027,
    "modTime": "2024-10-13T22:57:11.0054213+02:00",
    "path": "internal\\parser\\html.go"
  },
  {
    "name": "interface.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"io\"\r\n)\r\n\r\ntype Document struct {\r\n\tContent   string\r\n\tMetadata  map[string]string\r\n\tStructure []DocumentElement\r\n}\r\n\r\ntype DocumentElement struct {\r\n\tType     string // e.g., \"paragraph\", \"heading\", \"list\", etc.\r\n\tContent  string\r\n\tChildren []DocumentElement\r\n}\r\n\r\ntype Parser interface {\r\n\tParse(r io.Reader) (*Document, error)\r\n}\r\n",
    "size": 363,
    "modTime": "2024-10-13T22:55:13.159867+02:00",
    "path": "internal\\parser\\interface.go"
  },
  {
    "name": "markdown.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"io\"\r\n\r\n\t\"github.com/yuin/goldmark\"\r\n\t\"github.com/yuin/goldmark/ast\"\r\n\t\"github.com/yuin/goldmark/text\"\r\n)\r\n\r\ntype MarkdownParser struct{}\r\n\r\nfunc NewMarkdownParser() *MarkdownParser {\r\n\treturn \u0026MarkdownParser{}\r\n}\r\n\r\nfunc (p *MarkdownParser) Parse(r io.Reader) (*Document, error) {\r\n\tcontent, err := io.ReadAll(r)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\tmd := goldmark.New()\r\n\treader := text.NewReader(content)\r\n\tdoc := md.Parser().Parse(reader)\r\n\r\n\tvar structure []DocumentElement\r\n\terr = ast.Walk(doc, func(n ast.Node, entering bool) (ast.WalkStatus, error) {\r\n\t\tif !entering {\r\n\t\t\treturn ast.WalkContinue, nil\r\n\t\t}\r\n\r\n\t\tswitch n.Kind() {\r\n\t\tcase ast.KindHeading:\r\n\t\t\theading := n.(*ast.Heading)\r\n\t\t\tstructure = append(structure, DocumentElement{\r\n\t\t\t\tType:    \"heading\",\r\n\t\t\t\tContent: string(heading.Text(content)),\r\n\t\t\t})\r\n\t\tcase ast.KindParagraph:\r\n\t\t\tparagraph := n.(*ast.Paragraph)\r\n\t\t\tstructure = append(structure, DocumentElement{\r\n\t\t\t\tType:    \"paragraph\",\r\n\t\t\t\tContent: string(paragraph.Text(content)),\r\n\t\t\t})\r\n\t\t\t// Add more cases for other Markdown elements as needed\r\n\t\t}\r\n\r\n\t\treturn ast.WalkContinue, nil\r\n\t})\r\n\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\treturn \u0026Document{\r\n\t\tContent:   string(content),\r\n\t\tMetadata:  make(map[string]string),\r\n\t\tStructure: structure,\r\n\t}, nil\r\n}\r\n",
    "size": 1332,
    "modTime": "2024-10-13T22:55:43.7152936+02:00",
    "path": "internal\\parser\\markdown.go"
  },
  {
    "name": "parser_test.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"strings\"\r\n\t\"testing\"\r\n)\r\n\r\nfunc TestTextParser(t *testing.T) {\r\n\tinput := \"This is a test.\\nThis is another line.\"\r\n\tparser := NewTextParser()\r\n\tdoc, err := parser.Parse(strings.NewReader(input))\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"Failed to parse text: %v\", err)\r\n\t}\r\n\tif doc.Content != input+\"\\n\" {\r\n\t\tt.Errorf(\"Expected content %q, got %q\", input+\"\\n\", doc.Content)\r\n\t}\r\n\tif len(doc.Structure) != 2 {\r\n\t\tt.Errorf(\"Expected 2 paragraphs, got %d\", len(doc.Structure))\r\n\t}\r\n}\r\n\r\nfunc TestMarkdownParser(t *testing.T) {\r\n\tinput := \"# Heading\\n\\nThis is a paragraph.\"\r\n\tparser := NewMarkdownParser()\r\n\tdoc, err := parser.Parse(strings.NewReader(input))\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"Failed to parse markdown: %v\", err)\r\n\t}\r\n\tif len(doc.Structure) != 2 {\r\n\t\tt.Errorf(\"Expected 2 elements (heading and paragraph), got %d\", len(doc.Structure))\r\n\t}\r\n\tif doc.Structure[0].Type != \"heading\" || doc.Structure[1].Type != \"paragraph\" {\r\n\t\tt.Errorf(\"Unexpected structure types\")\r\n\t}\r\n}\r\n\r\n// Add similar tests for PDF and HTML parsers\r\n",
    "size": 1050,
    "modTime": "2024-10-13T22:57:42.8670185+02:00",
    "path": "internal\\parser\\parser_test.go"
  },
  {
    "name": "pdf.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"io\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/ledongthuc/pdf\"\r\n)\r\n\r\ntype PDFParser struct{}\r\n\r\nfunc NewPDFParser() *PDFParser {\r\n\treturn \u0026PDFParser{}\r\n}\r\n\r\nfunc (p *PDFParser) Parse(r io.Reader) (*Document, error) {\r\n\tcontent, err := io.ReadAll(r)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\treader, err := pdf.NewReader(strings.NewReader(string(content)))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\tvar contentBuilder strings.Builder\r\n\tvar structure []DocumentElement\r\n\r\n\tnumPages := reader.NumPage()\r\n\r\n\tfor pageIndex := 1; pageIndex \u003c= numPages; pageIndex++ {\r\n\t\tpage := reader.Page(pageIndex)\r\n\t\tif page.V.IsNull() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\r\n\t\ttext, err := page.GetPlainText(nil)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\r\n\t\tcontentBuilder.WriteString(text)\r\n\t\tstructure = append(structure, DocumentElement{\r\n\t\t\tType:    \"page\",\r\n\t\t\tContent: text,\r\n\t\t})\r\n\t}\r\n\r\n\treturn \u0026Document{\r\n\t\tContent:   contentBuilder.String(),\r\n\t\tMetadata:  make(map[string]string),\r\n\t\tStructure: structure,\r\n\t}, nil\r\n}",
    "size": 1017,
    "modTime": "2024-10-13T22:56:35.5316568+02:00",
    "path": "internal\\parser\\pdf.go"
  },
  {
    "name": "text.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"bufio\"\r\n\t\"io\"\r\n\t\"strings\"\r\n)\r\n\r\ntype TextParser struct{}\r\n\r\nfunc NewTextParser() *TextParser {\r\n\treturn \u0026TextParser{}\r\n}\r\n\r\nfunc (p *TextParser) Parse(r io.Reader) (*Document, error) {\r\n\tscanner := bufio.NewScanner(r)\r\n\tvar content strings.Builder\r\n\tvar structure []DocumentElement\r\n\r\n\tfor scanner.Scan() {\r\n\t\tline := scanner.Text()\r\n\t\tcontent.WriteString(line + \"\\n\")\r\n\t\tstructure = append(structure, DocumentElement{\r\n\t\t\tType:    \"paragraph\",\r\n\t\t\tContent: line,\r\n\t\t})\r\n\t}\r\n\r\n\tif err := scanner.Err(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\treturn \u0026Document{\r\n\t\tContent:   content.String(),\r\n\t\tMetadata:  make(map[string]string),\r\n\t\tStructure: structure,\r\n\t}, nil\r\n}",
    "size": 698,
    "modTime": "2024-10-13T22:55:25.0023478+02:00",
    "path": "internal\\parser\\text.go"
  },
  {
    "name": "parallel_processor.go",
    "content": "package processing\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"encoding/json\"\r\n\t\"errors\"\r\n\t\"fmt\"\r\n\t\"sort\"\r\n\t\"sync\"\r\n\t\"sync/atomic\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/config\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/jsonld\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/llm\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/logger\"\r\n)\r\n\r\ntype ParallelProcessor struct {\r\n\tconfig         *config.Config\r\n\tconverter      *jsonld.Converter\r\n\tllmClient      llm.Client\r\n\tworkerPool     chan struct{}\r\n\ttaskQueue      chan Task\r\n\tresultQueue    chan Result\r\n\twg             sync.WaitGroup\r\n\tactiveWorkers  int32\r\n\tsegmentResults []SegmentResult\r\n\tresultMutex    sync.Mutex\r\n\tmaxRetries     int\r\n\tretryDelay     time.Duration\r\n\tfailedTasks    chan Task\r\n}\r\n\r\ntype Task struct {\r\n\tSegment      string\r\n\tInstructions string\r\n\tIndex        int\r\n\tAttempts     int\r\n}\r\n\r\ntype Result struct {\r\n\tJSONLD string\r\n\tError  error\r\n\tIndex  int\r\n}\r\n\r\ntype SegmentResult struct {\r\n\tIndex  int\r\n\tJSONLD string\r\n}\r\n\r\nfunc NewParallelProcessor(cfg *config.Config, converter *jsonld.Converter, llmClient llm.Client) *ParallelProcessor {\r\n\treturn \u0026ParallelProcessor{\r\n\t\tconfig:      cfg,\r\n\t\tconverter:   converter,\r\n\t\tllmClient:   llmClient,\r\n\t\tworkerPool:  make(chan struct{}, cfg.Conversion.NumWorkers),\r\n\t\ttaskQueue:   make(chan Task, cfg.Conversion.QueueSize),\r\n\t\tresultQueue: make(chan Result, cfg.Conversion.QueueSize),\r\n\t\tmaxRetries:  cfg.Conversion.MaxRetries,\r\n\t\tretryDelay:  time.Duration(cfg.Conversion.RetryDelayMs) * time.Millisecond,\r\n\t\tfailedTasks: make(chan Task, cfg.Conversion.QueueSize),\r\n\t}\r\n}\r\n\r\nfunc (pp *ParallelProcessor) startWorkers(ctx context.Context) {\r\n\tfor i := 0; i \u003c pp.config.Conversion.NumWorkers; i++ {\r\n\t\tpp.wg.Add(1)\r\n\t\tgo func(workerID int) {\r\n\t\t\tdefer pp.wg.Done()\r\n\t\t\tlogger.Info(fmt.Sprintf(\"Worker %d started\", workerID))\r\n\t\t\tfor {\r\n\t\t\t\tselect {\r\n\t\t\t\tcase task, ok := \u003c-pp.taskQueue:\r\n\t\t\t\t\tif !ok {\r\n\t\t\t\t\t\tlogger.Info(fmt.Sprintf(\"Worker %d finished\", workerID))\r\n\t\t\t\t\t\treturn\r\n\t\t\t\t\t}\r\n\t\t\t\t\tatomic.AddInt32(\u0026pp.activeWorkers, 1)\r\n\t\t\t\t\tresult := pp.processTask(ctx, task)\r\n\t\t\t\t\tatomic.AddInt32(\u0026pp.activeWorkers, -1)\r\n\t\t\t\t\tpp.resultQueue \u003c- result\r\n\t\t\t\tcase task := \u003c-pp.failedTasks:\r\n\t\t\t\t\tatomic.AddInt32(\u0026pp.activeWorkers, 1)\r\n\t\t\t\t\tresult := pp.processTask(ctx, task)\r\n\t\t\t\t\tatomic.AddInt32(\u0026pp.activeWorkers, -1)\r\n\t\t\t\t\tpp.resultQueue \u003c- result\r\n\t\t\t\tcase \u003c-ctx.Done():\r\n\t\t\t\t\tlogger.Info(fmt.Sprintf(\"Worker %d stopped due to context cancellation\", workerID))\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}(i)\r\n\t}\r\n}\r\n\r\nfunc (pp *ParallelProcessor) processTask(ctx context.Context, task Task) Result {\r\n\tlogger.Debug(fmt.Sprintf(\"Processing task: %v (Attempt: %d)\", task, task.Attempts+1))\r\n\r\n\tenrichedSegment, err := pp.llmClient.EnrichSegment(ctx, task.Segment, task.Instructions)\r\n\tif err != nil {\r\n\t\tlogger.Error(fmt.Sprintf(\"Error enriching segment with LLM: %v\", err))\r\n\t\treturn pp.handleTaskError(task, err)\r\n\t}\r\n\r\n\tjsonLD, err := pp.converter.Convert(enrichedSegment)\r\n\tif err != nil {\r\n\t\tlogger.Error(fmt.Sprintf(\"Error converting to JSON-LD: %v\", err))\r\n\t\treturn pp.handleTaskError(task, err)\r\n\t}\r\n\r\n\treturn Result{JSONLD: jsonLD, Index: task.Index}\r\n}\r\n\r\nfunc (pp *ParallelProcessor) AddTask(segment string, instructions string, index int) error {\r\n\tselect {\r\n\tcase pp.taskQueue \u003c- Task{Segment: segment, Instructions: instructions, Index: index}:\r\n\t\tlogger.Debug(fmt.Sprintf(\"Added task to queue: %s\", segment[:20]))\r\n\t\treturn nil\r\n\tdefault:\r\n\t\treturn errors.New(\"task queue is full\")\r\n\t}\r\n}\r\n\r\nfunc (pp *ParallelProcessor) GetResults() \u003c-chan Result {\r\n\treturn pp.resultQueue\r\n}\r\n\r\nfunc (pp *ParallelProcessor) ProcessSegments(ctx context.Context, segments []string, instructions string) (string, error) {\r\n\tpp.segmentResults = make([]SegmentResult, len(segments))\r\n\tsuccessCount := 0\r\n\r\n\tfor i, segment := range segments {\r\n\t\tif err := pp.AddTask(segment, instructions, i); err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"failed to add task: %w\", err)\r\n\t\t}\r\n\t}\r\n\r\n\tpp.Start(ctx)\r\n\tdefer pp.Stop()\r\n\r\n\tfor successCount \u003c len(segments) {\r\n\t\tselect {\r\n\t\tcase result := \u003c-pp.GetResults():\r\n\t\t\tif result.Error != nil {\r\n\t\t\t\tlogger.Warning(fmt.Sprintf(\"Error processing segment %d: %v\", result.Index, result.Error))\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tpp.addSegmentResult(result)\r\n\t\t\tsuccessCount++\r\n\t\tcase \u003c-ctx.Done():\r\n\t\t\treturn \"\", ctx.Err()\r\n\t\t}\r\n\t}\r\n\r\n\treturn pp.reconcileResults()\r\n}\r\n\r\nfunc (pp *ParallelProcessor) Start(ctx context.Context) {\r\n\tgo pp.startWorkers(ctx)\r\n}\r\n\r\nfunc (pp *ParallelProcessor) Stop() {\r\n\tclose(pp.taskQueue)\r\n\tpp.wg.Wait()\r\n\tclose(pp.resultQueue)\r\n}\r\n\r\nfunc (pp *ParallelProcessor) addSegmentResult(result Result) {\r\n\tpp.resultMutex.Lock()\r\n\tdefer pp.resultMutex.Unlock()\r\n\tpp.segmentResults[result.Index] = SegmentResult{Index: result.Index, JSONLD: result.JSONLD}\r\n}\r\n\r\nfunc (pp *ParallelProcessor) reconcileResults() (string, error) {\r\n\tsort.Slice(pp.segmentResults, func(i, j int) bool {\r\n\t\treturn pp.segmentResults[i].Index \u003c pp.segmentResults[j].Index\r\n\t})\r\n\r\n\tvar combinedResult struct {\r\n\t\tContext string        `json:\"@context\"`\r\n\t\tGraph   []interface{} `json:\"@graph\"`\r\n\t}\r\n\tcombinedResult.Context = \"https://schema.org\"\r\n\r\n\tfor _, segmentResult := range pp.segmentResults {\r\n\t\tvar segmentData map[string]interface{}\r\n\t\tif err := json.Unmarshal([]byte(segmentResult.JSONLD), \u0026segmentData); err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"error unmarshaling segment JSON-LD: %w\", err)\r\n\t\t}\r\n\r\n\t\tif graph, ok := segmentData[\"@graph\"].([]interface{}); ok {\r\n\t\t\tcombinedResult.Graph = append(combinedResult.Graph, graph...)\r\n\t\t}\r\n\t}\r\n\r\n\tfinalJSON, err := json.MarshalIndent(combinedResult, \"\", \"  \")\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error marshaling final JSON-LD: %w\", err)\r\n\t}\r\n\r\n\treturn string(finalJSON), nil\r\n}\r\n\r\nfunc (pp *ParallelProcessor) handleTaskError(task Task, err error) Result {\r\n\tif task.Attempts \u003c pp.maxRetries {\r\n\t\ttask.Attempts++\r\n\t\ttime.Sleep(pp.retryDelay)\r\n\t\tpp.failedTasks \u003c- task\r\n\t\treturn Result{Error: fmt.Errorf(\"task rescheduled for retry: %w\", err), Index: task.Index}\r\n\t}\r\n\treturn Result{Error: fmt.Errorf(\"task failed after %d attempts: %w\", task.Attempts+1, err), Index: task.Index}\r\n}\r\n",
    "size": 6176,
    "modTime": "2024-10-14T18:48:33.4496637+02:00",
    "path": "internal\\processing\\parallel_processor.go"
  },
  {
    "name": "schema.go",
    "content": "package schema\r\n\r\nimport (\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"io/ioutil\"\r\n\t\"strings\"\r\n)\r\n\r\ntype SchemaType struct {\r\n\tID           string            `json:\"@id\"`\r\n\tLabel        string            `json:\"rdfs:label\"`\r\n\tComment      string            `json:\"rdfs:comment\"`\r\n\tProperties   []string          `json:\"properties,omitempty\"`\r\n\tSubClassOf   []string          `json:\"subClassOf,omitempty\"`\r\n\tIsPartOf     string            `json:\"isPartOf\"`\r\n\tSource       string            `json:\"source\"`\r\n\tEnumerations map[string]string `json:\"enumerations,omitempty\"`\r\n}\r\n\r\ntype SchemaProperty struct {\r\n\tID             string   `json:\"@id\"`\r\n\tLabel          string   `json:\"rdfs:label\"`\r\n\tComment        string   `json:\"rdfs:comment\"`\r\n\tDomainIncludes []string `json:\"domainIncludes,omitempty\"`\r\n\tRangeIncludes  []string `json:\"rangeIncludes,omitempty\"`\r\n\tIsPartOf       string   `json:\"isPartOf\"`\r\n\tSource         string   `json:\"source\"`\r\n}\r\n\r\ntype SchemaOrg struct {\r\n\tTypes      map[string]SchemaType\r\n\tProperties map[string]SchemaProperty\r\n}\r\n\r\nfunc LoadSchemaOrg(filePath string) (*SchemaOrg, error) {\r\n\tdata, err := ioutil.ReadFile(filePath)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error reading Schema.org file: %w\", err)\r\n\t}\r\n\r\n\tvar rawSchema map[string]json.RawMessage\r\n\tif err := json.Unmarshal(data, \u0026rawSchema); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error unmarshaling Schema.org data: %w\", err)\r\n\t}\r\n\r\n\tschema := \u0026SchemaOrg{\r\n\t\tTypes:      make(map[string]SchemaType),\r\n\t\tProperties: make(map[string]SchemaProperty),\r\n\t}\r\n\r\n\tfor key, value := range rawSchema {\r\n\t\tif strings.HasPrefix(key, \"schema:\") {\r\n\t\t\tvar schemaType SchemaType\r\n\t\t\tif err := json.Unmarshal(value, \u0026schemaType); err == nil {\r\n\t\t\t\tschema.Types[key] = schemaType\r\n\t\t\t} else {\r\n\t\t\t\tvar schemaProperty SchemaProperty\r\n\t\t\t\tif err := json.Unmarshal(value, \u0026schemaProperty); err == nil {\r\n\t\t\t\t\tschema.Properties[key] = schemaProperty\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\treturn schema, nil\r\n}\r\n\r\nfunc (s *SchemaOrg) GetType(typeName string) (SchemaType, bool) {\r\n\tt, ok := s.Types[\"schema:\"+typeName]\r\n\treturn t, ok\r\n}\r\n\r\nfunc (s *SchemaOrg) GetProperty(propertyName string) (SchemaProperty, bool) {\r\n\tp, ok := s.Properties[\"schema:\"+propertyName]\r\n\treturn p, ok\r\n}\r\n\r\nfunc (s *SchemaOrg) SuggestProperties(typeName string, content string) []string {\r\n\tschemaType, ok := s.GetType(typeName)\r\n\tif !ok {\r\n\t\treturn nil\r\n\t}\r\n\r\n\tvar suggestedProperties []string\r\n\tfor _, propName := range schemaType.Properties {\r\n\t\tprop, ok := s.GetProperty(strings.TrimPrefix(propName, \"schema:\"))\r\n\t\tif ok \u0026\u0026 strings.Contains(strings.ToLower(content), strings.ToLower(prop.Label)) {\r\n\t\t\tsuggestedProperties = append(suggestedProperties, prop.ID)\r\n\t\t}\r\n\t}\r\n\r\n\treturn suggestedProperties\r\n}\r\n",
    "size": 2733,
    "modTime": "2024-10-13T23:05:54.0227753+02:00",
    "path": "internal\\schema\\schema.go"
  },
  {
    "name": "schema_test.go",
    "content": "package schema\r\n\r\nimport (\r\n\t\"testing\"\r\n)\r\n\r\nfunc TestLoadSchemaOrg(t *testing.T) {\r\n\tschema, err := LoadSchemaOrg(\"testdata/schema.json\")\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"Failed to load Schema.org: %v\", err)\r\n\t}\r\n\r\n\tif len(schema.Types) == 0 {\r\n\t\tt.Error(\"No types loaded from Schema.org\")\r\n\t}\r\n\r\n\tif len(schema.Properties) == 0 {\r\n\t\tt.Error(\"No properties loaded from Schema.org\")\r\n\t}\r\n\r\n\t// Test GetType\r\n\tperson, ok := schema.GetType(\"Person\")\r\n\tif !ok {\r\n\t\tt.Error(\"Failed to get Person type\")\r\n\t} else if person.Label != \"Person\" {\r\n\t\tt.Errorf(\"Unexpected label for Person: %s\", person.Label)\r\n\t}\r\n\r\n\t// Test GetProperty\r\n\tname, ok := schema.GetProperty(\"name\")\r\n\tif !ok {\r\n\t\tt.Error(\"Failed to get name property\")\r\n\t} else if name.Label != \"name\" {\r\n\t\tt.Errorf(\"Unexpected label for name property: %s\", name.Label)\r\n\t}\r\n\r\n\t// Test SuggestProperties\r\n\tsuggestedProps := schema.SuggestProperties(\"Person\", \"John Doe is 30 years old\")\r\n\tif len(suggestedProps) == 0 {\r\n\t\tt.Error(\"No properties suggested for Person\")\r\n\t}\r\n}\r\n",
    "size": 1026,
    "modTime": "2024-10-13T23:06:09.9525685+02:00",
    "path": "internal\\schema\\schema_test.go"
  },
  {
    "name": "segmenter.go",
    "content": "package segmentation\r\n\r\nimport (\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n\t\"github.com/chrlesur/json-ld-converter/pkg/tokenizer\"\r\n)\r\n\r\ntype Segment struct {\r\n\tContent  string\r\n\tMetadata map[string]string\r\n}\r\n\r\ntype Segmenter struct {\r\n\tmaxTokens       int\r\n\ttargetBatchSize int\r\n}\r\n\r\nfunc NewSegmenter(maxTokens, targetBatchSize int) *Segmenter {\r\n\treturn \u0026Segmenter{\r\n\t\tmaxTokens:       maxTokens,\r\n\t\ttargetBatchSize: targetBatchSize,\r\n\t}\r\n}\r\n\r\nfunc (s *Segmenter) Segment(doc *parser.Document) ([]Segment, error) {\r\n\tvar segments []Segment\r\n\tvar currentSegment strings.Builder\r\n\tcurrentTokens := 0\r\n\r\n\tfor _, element := range doc.Structure {\r\n\t\telementTokens := tokenizer.CountTokens(element.Content)\r\n\r\n\t\tif currentTokens+elementTokens \u003e s.maxTokens {\r\n\t\t\tif currentSegment.Len() \u003e 0 {\r\n\t\t\t\tsegments = append(segments, Segment{\r\n\t\t\t\t\tContent:  currentSegment.String(),\r\n\t\t\t\t\tMetadata: make(map[string]string),\r\n\t\t\t\t})\r\n\t\t\t\tcurrentSegment.Reset()\r\n\t\t\t\tcurrentTokens = 0\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\tif elementTokens \u003e s.maxTokens {\r\n\t\t\t// Si l'élément est trop grand, le diviser en sous-segments\r\n\t\t\tsubSegments := s.splitLargeElement(element)\r\n\t\t\tsegments = append(segments, subSegments...)\r\n\t\t} else {\r\n\t\t\tcurrentSegment.WriteString(element.Content)\r\n\t\t\tcurrentSegment.WriteString(\"\\n\")\r\n\t\t\tcurrentTokens += elementTokens\r\n\r\n\t\t\tif currentTokens \u003e= s.targetBatchSize {\r\n\t\t\t\tsegments = append(segments, Segment{\r\n\t\t\t\t\tContent:  currentSegment.String(),\r\n\t\t\t\t\tMetadata: make(map[string]string),\r\n\t\t\t\t})\r\n\t\t\t\tcurrentSegment.Reset()\r\n\t\t\t\tcurrentTokens = 0\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\tif currentSegment.Len() \u003e 0 {\r\n\t\tsegments = append(segments, Segment{\r\n\t\t\tContent:  currentSegment.String(),\r\n\t\t\tMetadata: make(map[string]string),\r\n\t\t})\r\n\t}\r\n\r\n\treturn segments, nil\r\n}\r\n\r\nfunc (s *Segmenter) splitLargeElement(element parser.DocumentElement) []Segment {\r\n\tvar segments []Segment\r\n\tcontent := element.Content\r\n\tfor len(content) \u003e 0 {\r\n\t\ttokenCount := 0\r\n\t\tvar segmentBuilder strings.Builder\r\n\t\twords := strings.Fields(content)\r\n\r\n\t\tfor _, word := range words {\r\n\t\t\twordTokens := tokenizer.CountTokens(word)\r\n\t\t\tif tokenCount+wordTokens \u003e s.maxTokens {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tsegmentBuilder.WriteString(word)\r\n\t\t\tsegmentBuilder.WriteString(\" \")\r\n\t\t\ttokenCount += wordTokens\r\n\t\t}\r\n\r\n\t\tsegments = append(segments, Segment{\r\n\t\t\tContent:  segmentBuilder.String(),\r\n\t\t\tMetadata: map[string]string{\"type\": element.Type},\r\n\t\t})\r\n\r\n\t\tcontent = strings.TrimSpace(content[len(segmentBuilder.String()):])\r\n\t}\r\n\r\n\treturn segments\r\n}\r\n",
    "size": 2530,
    "modTime": "2024-10-13T23:00:40.0542261+02:00",
    "path": "internal\\segmentation\\segmenter.go"
  },
  {
    "name": "segmenter_test.go",
    "content": "package segmentation\r\n\r\nimport (\r\n\t\"strings\"\r\n\t\"testing\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n\t\"github.com/chrlesur/json-ld-converter/pkg/tokenizer\"\r\n)\r\n\r\nfunc TestSegmenter(t *testing.T) {\r\n\tdoc := \u0026parser.Document{\r\n\t\tStructure: []parser.DocumentElement{\r\n\t\t\t{Type: \"heading\", Content: \"Title\"},\r\n\t\t\t{Type: \"paragraph\", Content: \"This is a long paragraph that should be split into multiple segments. \" + strings.Repeat(\"More content. \", 100)},\r\n\t\t\t{Type: \"list\", Content: \"Item 1\\nItem 2\\nItem 3\"},\r\n\t\t},\r\n\t}\r\n\r\n\tsegmenter := NewSegmenter(1000, 500)\r\n\tsegments, err := segmenter.Segment(doc)\r\n\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"Segmentation failed: %v\", err)\r\n\t}\r\n\r\n\tif len(segments) \u003c 2 {\r\n\t\tt.Errorf(\"Expected multiple segments, got %d\", len(segments))\r\n\t}\r\n\r\n\tfor i, segment := range segments {\r\n\t\ttokens := tokenizer.CountTokens(segment.Content)\r\n\t\tif tokens \u003e 1000 {\r\n\t\t\tt.Errorf(\"Segment %d exceeds max tokens: %d\", i, tokens)\r\n\t\t}\r\n\t}\r\n}\r\n",
    "size": 969,
    "modTime": "2024-10-13T23:01:23.4928676+02:00",
    "path": "internal\\segmentation\\segmenter_test.go"
  },
  {
    "name": "tokenizer.go",
    "content": "package tokenizer\r\n\r\nimport (\r\n\t\"strings\"\r\n\t\"unicode\"\r\n)\r\n\r\nfunc CountTokens(text string) int {\r\n\treturn len(strings.Fields(text))\r\n}\r\n\r\nfunc SplitIntoTokens(text string) []string {\r\n\treturn strings.FieldsFunc(text, func(r rune) bool {\r\n\t\treturn unicode.IsSpace(r) || unicode.IsPunct(r)\r\n\t})\r\n}",
    "size": 294,
    "modTime": "2024-10-13T23:02:27.0794128+02:00",
    "path": "pkg\\tokenizer\\tokenizer.go"
  }
]