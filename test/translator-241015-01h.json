[
  {
    "name": "main.go",
    "content": "package main\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"io/ioutil\"\r\n\t\"os\"\r\n\t\"path/filepath\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/config\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/jsonld\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/llm\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/logger\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/schema\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/segmentation\"\r\n\t\"github.com/spf13/cobra\"\r\n\t\"gopkg.in/yaml.v2\"\r\n)\r\n\r\nvar (\r\n\tcfgFile      string\r\n\tinputFile    *string\r\n\toutputFile   *string\r\n\tengine       string\r\n\tinstructions string\r\n\tsilent       bool\r\n\tdebug        bool\r\n\tbatchMode    bool\r\n\tinteractive  bool\r\n)\r\n\r\nvar rootCmd = \u0026cobra.Command{\r\n\tUse:   \"json-ld-converter\",\r\n\tShort: \"Convert documents to JSON-LD\",\r\n\tLong:  `A CLI tool to convert various document formats to JSON-LD using Schema.org vocabulary.`,\r\n}\r\n\r\nvar convertCmd = \u0026cobra.Command{\r\n\tUse:   \"convert [input file]\",\r\n\tShort: \"Convert a file to JSON-LD\",\r\n\tArgs:  cobra.ExactArgs(1),\r\n\tRunE:  runConvert,\r\n}\r\n\r\nfunc init() {\r\n\tcobra.OnInitialize(initConfig)\r\n\r\n\t// Ajout de la sous-commande \"convert\"\r\n\trootCmd.AddCommand(convertCmd)\r\n\r\n\toutputFile = new(string)\r\n\t// Flags pour la sous-commande \"convert\"\r\n\tconvertCmd.Flags().StringVarP(outputFile, \"output\", \"o\", \"\", \"Output file for JSON-LD (default is inputfile.jsonld)\")\r\n\tconvertCmd.Flags().StringVarP(\u0026engine, \"engine\", \"e\", \"\", \"LLM engine to use (overrides config)\")\r\n\tconvertCmd.Flags().StringVarP(\u0026instructions, \"instructions\", \"n\", \"\", \"Additional instructions for LLM\")\r\n\r\n\t// Flags globaux\r\n\trootCmd.PersistentFlags().StringVar(\u0026cfgFile, \"config\", \"\", \"config file (default is ./config.yaml)\")\r\n\trootCmd.PersistentFlags().BoolVar(\u0026silent, \"silent\", false, \"Silent mode (no console output)\")\r\n\trootCmd.PersistentFlags().BoolVar(\u0026debug, \"debug\", false, \"Debug mode (verbose logging)\")\r\n\r\n\t// Flags pour les autres sous-commandes (si nécessaire)\r\n\trootCmd.AddCommand(newBatchCmd())\r\n\trootCmd.AddCommand(newConfigCmd())\r\n\trootCmd.AddCommand(newInteractiveCmd())\r\n}\r\n\r\nfunc initConfig() {\r\n\tif cfgFile != \"\" {\r\n\t\t// Use config file from the flag.\r\n\t\tconfig.Load(cfgFile)\r\n\t} else {\r\n\t\t// Search config in home directory with name \".json-ld-converter\" (without extension).\r\n\t\tconfig.Load(\"config.yaml\")\r\n\t}\r\n\r\n\t// Configuration du logger\r\n\tlogLevel := logger.INFO\r\n\tif debug {\r\n\t\tlogLevel = logger.DEBUG\r\n\t}\r\n\tlogger.Init(logLevel, \"\")\r\n\tlogger.SetSilentMode(silent)\r\n}\r\n\r\nfunc main() {\r\n\tif err := rootCmd.Execute(); err != nil {\r\n\t\tfmt.Println(err)\r\n\t\tos.Exit(1)\r\n\t}\r\n}\r\n\r\nfunc convert(inputFilePath, outputFilePath string) error {\r\n\tcfg := config.Get()\r\n\tlogger.Debug(fmt.Sprintf(\"Configuration loaded: %+v\", cfg))\r\n\r\n\tlogger.Debug(fmt.Sprintf(\"Input file: %s\", inputFilePath))\r\n\tlogger.Debug(fmt.Sprintf(\"Output file: %s\", outputFilePath))\r\n\r\n\t// Création du client LLM\r\n\tclient, err := llm.NewLLMClient(cfg)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error creating LLM client: %w\", err)\r\n\t}\r\n\tlogger.Debug(\"LLM client created successfully\")\r\n\r\n\t// Chargement du schéma Schema.org\r\n\tschemaOrg, err := schema.LoadSchemaOrg(cfg.Schema.FilePath)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error loading Schema.org: %w\", err)\r\n\t}\r\n\tlogger.Debug(\"Schema.org loaded successfully\")\r\n\r\n\t// Création du parseur de document\r\n\tp, err := parser.NewParser(getFileType(inputFilePath))\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error creating parser: %w\", err)\r\n\t}\r\n\tlogger.Debug(fmt.Sprintf(\"Parser created for file type: %s\", getFileType(inputFilePath)))\r\n\r\n\t// Lecture et analyse du fichier d'entrée\r\n\tfile, err := os.Open(inputFilePath)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error opening input file: %w\", err)\r\n\t}\r\n\tdefer file.Close()\r\n\tlogger.Debug(\"Input file opened successfully\")\r\n\r\n\tdoc, err := p.Parse(file)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error parsing document: %w\", err)\r\n\t}\r\n\tlogger.Debug(\"Document parsed successfully\")\r\n\r\n\t// Création du convertisseur\r\n\tconv := jsonld.NewConverter(schemaOrg, client, cfg.Conversion.MaxTokens, instructions)\r\n\tlogger.Debug(\"Converter created successfully\")\r\n\r\n\t// Segmentation du document\r\n\tsegments, err := segmentation.SegmentDocument(doc, cfg.Conversion.MaxTokens)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error segmenting document: %w\", err)\r\n\t}\r\n\tlogger.Debug(fmt.Sprintf(\"Document segmented into %d parts\", len(segments)))\r\n\r\n\tvar allResults []map[string]interface{}\r\n\r\n\t// Conversion de chaque segment en JSON-LD\r\n\tfor i, segment := range segments {\r\n\t\tlogger.Debug(fmt.Sprintf(\"Processing segment %d of %d\", i+1, len(segments)))\r\n\t\t\r\n\t\tsegmentDoc := \u0026parser.Document{\r\n\t\t\tContent:  segment.Content,  // Utilisez segment.Content au lieu de segment directement\r\n\t\t\tMetadata: doc.Metadata,\r\n\t\t}\r\n\t\r\n\t\tctx := context.Background()\r\n\t\tjsonLD, err := conv.Convert(ctx, segmentDoc)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"error converting segment %d to JSON-LD: %w\", i+1, err)\r\n\t\t}\r\n\t\r\n\t\tallResults = append(allResults, jsonLD)\r\n\t}\r\n\r\n\t// Combinaison de tous les résultats\r\n\tcombinedResult := map[string]interface{}{\r\n\t\t\"@context\": \"https://schema.org\",\r\n\t\t\"@graph\":   allResults,\r\n\t}\r\n\r\n\t// Sérialisation du JSON-LD combiné\r\n\tjsonString, err := json.MarshalIndent(combinedResult, \"\", \"  \")\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error marshaling combined JSON-LD: %w\", err)\r\n\t}\r\n\r\n\t// Écriture du résultat dans le fichier de sortie\r\n\terr = os.WriteFile(outputFilePath, jsonString, 0644)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error writing output file: %w\", err)\r\n\t}\r\n\tlogger.Debug(\"JSON-LD written to output file successfully\")\r\n\r\n\tlogger.Info(\"Conversion completed successfully.\")\r\n\treturn nil\r\n}\r\n\r\nfunc newBatchCmd() *cobra.Command {\r\n\tvar inputDir, outputDir string\r\n\r\n\tcmd := \u0026cobra.Command{\r\n\t\tUse:   \"batch\",\r\n\t\tShort: \"Process multiple files in batch mode\",\r\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\r\n\t\t\tfiles, err := ioutil.ReadDir(inputDir)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"error reading input directory: %w\", err)\r\n\t\t\t}\r\n\r\n\t\t\tfor _, file := range files {\r\n\t\t\t\tif file.IsDir() {\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tinputFilePath := filepath.Join(inputDir, file.Name())\r\n\t\t\t\toutputFilePath := filepath.Join(outputDir, file.Name()+\".jsonld\")\r\n\t\t\t\tlogger.Info(fmt.Sprintf(\"Processing file: %s\", inputFilePath))\r\n\t\t\t\terr := convert(inputFilePath, outputFilePath)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogger.Error(fmt.Sprintf(\"Error processing file %s: %v\", inputFilePath, err))\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n\r\n\tcmd.Flags().StringVarP(\u0026inputDir, \"input-dir\", \"d\", \"\", \"Input directory for batch processing\")\r\n\tcmd.Flags().StringVarP(\u0026outputDir, \"output-dir\", \"o\", \"\", \"Output directory for batch processing\")\r\n\tcmd.MarkFlagRequired(\"input-dir\")\r\n\tcmd.MarkFlagRequired(\"output-dir\")\r\n\r\n\treturn cmd\r\n}\r\n\r\nfunc newConfigCmd() *cobra.Command {\r\n\tvar showConfig bool\r\n\tvar setKey string\r\n\tvar setValue string\r\n\r\n\tcmd := \u0026cobra.Command{\r\n\t\tUse:   \"config\",\r\n\t\tShort: \"Manage configuration\",\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\tif showConfig {\r\n\t\t\t\tcfg := config.Get()\r\n\t\t\t\tdata, _ := yaml.Marshal(cfg)\r\n\t\t\t\tfmt.Println(string(data))\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\r\n\t\t\tif setKey != \"\" \u0026\u0026 setValue != \"\" {\r\n\t\t\t\terr := config.Set(setKey, setValue)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogger.Error(fmt.Sprintf(\"Error setting config: %v\", err))\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t\tlogger.Info(fmt.Sprintf(\"Config updated: %s = %s\", setKey, setValue))\r\n\t\t\t}\r\n\t\t},\r\n\t}\r\n\r\n\tcmd.Flags().BoolVar(\u0026showConfig, \"show\", false, \"Show current configuration\")\r\n\tcmd.Flags().StringVar(\u0026setKey, \"set-key\", \"\", \"Set configuration key\")\r\n\tcmd.Flags().StringVar(\u0026setValue, \"set-value\", \"\", \"Set configuration value\")\r\n\r\n\treturn cmd\r\n}\r\n\r\nfunc newInteractiveCmd() *cobra.Command {\r\n\tvar inputDir, outputDir string\r\n\r\n\treturn \u0026cobra.Command{\r\n\t\tUse:   \"interactive\",\r\n\t\tShort: \"Start interactive mode\",\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\tfmt.Println(\"Welcome to interactive mode!\")\r\n\t\t\tfor {\r\n\t\t\t\tfmt.Print(\"Enter input file path (or 'quit' to exit): \")\r\n\t\t\t\tvar input string\r\n\t\t\t\tfmt.Scanln(\u0026input)\r\n\t\t\t\tif input == \"quit\" {\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\r\n\t\t\t\t// Demander le répertoire de sortie si ce n'est pas déjà fait\r\n\t\t\t\tif outputDir == \"\" {\r\n\t\t\t\t\tfmt.Print(\"Enter output directory: \")\r\n\t\t\t\t\tfmt.Scanln(\u0026outputDir)\r\n\t\t\t\t}\r\n\r\n\t\t\t\t// Utiliser filepath.Base pour obtenir le nom du fichier\r\n\t\t\t\tfileName := filepath.Base(input)\r\n\t\t\t\tinputFilePath := filepath.Join(inputDir, fileName)\r\n\t\t\t\toutputFilePath := filepath.Join(outputDir, fileName+\".jsonld\")\r\n\r\n\t\t\t\terr := convert(inputFilePath, outputFilePath)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogger.Error(fmt.Sprintf(\"Conversion error: %v\", err))\r\n\t\t\t\t} else {\r\n\t\t\t\t\tlogger.Info(\"Conversion completed successfully.\")\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t},\r\n\t}\r\n}\r\n\r\nfunc readAndParseDocument(filePath string, p parser.Parser) (*parser.Document, error) {\r\n\tfile, err := os.Open(filePath)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error opening input file: %w\", err)\r\n\t}\r\n\tdefer file.Close()\r\n\r\n\tdoc, err := p.Parse(file)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error parsing document: %w\", err)\r\n\t}\r\n\r\n\treturn doc, nil\r\n}\r\n\r\nfunc writeOutput(filePath string, content string) error {\r\n\terr := os.WriteFile(filePath, []byte(content), 0644)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error writing output file: %w\", err)\r\n\t}\r\n\treturn nil\r\n}\r\n\r\nfunc getFileType(filename string) string {\r\n\text := strings.ToLower(filepath.Ext(filename))\r\n\tswitch ext {\r\n\tcase \".txt\":\r\n\t\treturn \"text\"\r\n\tcase \".md\":\r\n\t\treturn \"markdown\"\r\n\tcase \".pdf\":\r\n\t\treturn \"pdf\"\r\n\tcase \".html\", \".htm\":\r\n\t\treturn \"html\"\r\n\tdefault:\r\n\t\treturn \"text\" // Par défaut, on suppose que c'est un fichier texte\r\n\t}\r\n}\r\n\r\nfunc configureLLM(cmd *cobra.Command, args []string) error {\r\n\tcfg := config.Get()\r\n\r\n\t// Sélection du moteur LLM\r\n\tif engine != \"\" {\r\n\t\tcfg.Conversion.Engine = engine\r\n\t}\r\n\r\n\t// Configuration spécifique au LLM\r\n\tswitch cfg.Conversion.Engine {\r\n\tcase \"claude\":\r\n\t\tapiKey := os.Getenv(\"CLAUDE_API_KEY\")\r\n\t\tif apiKey == \"\" {\r\n\t\t\treturn fmt.Errorf(\"CLAUDE_API_KEY environment variable is not set\")\r\n\t\t}\r\n\t\tcfg.Conversion.APIKey = apiKey\r\n\tcase \"gpt\":\r\n\t\tapiKey := os.Getenv(\"OPENAI_API_KEY\")\r\n\t\tif apiKey == \"\" {\r\n\t\t\treturn fmt.Errorf(\"OPENAI_API_KEY environment variable is not set\")\r\n\t\t}\r\n\t\tcfg.Conversion.APIKey = apiKey\r\n\tcase \"ollama\":\r\n\t\t// Pas besoin de clé API pour Ollama\r\n\t\tcfg.Conversion.OllamaHost = cfg.Conversion.OllamaHost\r\n\t\tcfg.Conversion.OllamaPort = cfg.Conversion.OllamaPort\r\n\tcase \"aiyou\":\r\n\t\temail := os.Getenv(\"AIYOU_EMAIL\")\r\n\t\tpassword := os.Getenv(\"AIYOU_PASSWORD\")\r\n\t\tif email == \"\" || password == \"\" {\r\n\t\t\treturn fmt.Errorf(\"AIYOU_EMAIL or AIYOU_PASSWORD environment variable is not set\")\r\n\t\t}\r\n\t\tcfg.Conversion.AIYOUEmail = email\r\n\t\tcfg.Conversion.AIYOUPassword = password\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"unsupported LLM engine: %s\", cfg.Conversion.Engine)\r\n\t}\r\n\r\n\t// Application des instructions supplémentaires\r\n\tif instructions != \"\" {\r\n\t\tcfg.Conversion.AdditionalInstructions = instructions\r\n\t}\r\n\r\n\treturn nil\r\n}\r\n\r\nfunc runConvert(cmd *cobra.Command, args []string) error {\r\n\tinputFile := args[0]\r\n\tif *outputFile == \"\" {\r\n\t\t*outputFile = inputFile + \".jsonld\"\r\n\t}\r\n\r\n\tlogger.Debug(fmt.Sprintf(\"Input file: %s\", inputFile))\r\n\tlogger.Debug(fmt.Sprintf(\"Output file: %s\", *outputFile))\r\n\r\n\t// Vérifiez que le fichier d'entrée existe\r\n\tif _, err := os.Stat(inputFile); os.IsNotExist(err) {\r\n\t\treturn fmt.Errorf(\"input file does not exist: %s\", inputFile)\r\n\t}\r\n\r\n\t// Appel à la fonction de conversion\r\n\terr := convert(inputFile, *outputFile)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"conversion error: %w\", err)\r\n\t}\r\n\r\n\tlogger.Info(\"Conversion completed successfully.\")\r\n\treturn nil\r\n}\r\n",
    "size": 11771,
    "modTime": "2024-10-14T23:50:26.1205103+02:00",
    "path": "cmd\\cli\\main.go"
  },
  {
    "name": "main_test.go",
    "content": "package main\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"io/ioutil\"\r\n\t\"os\"\r\n\t\"path/filepath\"\r\n\t\"testing\"\r\n\r\n\t\"github.com/stretchr/testify/assert\"\r\n)\r\n\r\n// TestBatchCommand teste la fonctionnalité de traitement par lots\r\nfunc TestBatchCommand(t *testing.T) {\r\n\t// Créer un répertoire temporaire pour les tests\r\n\ttempDir, err := ioutil.TempDir(\"\", \"batch_test\")\r\n\tassert.NoError(t, err)\r\n\tdefer os.RemoveAll(tempDir)\r\n\r\n\t// Créer quelques fichiers de test\r\n\ttestFiles := []string{\"test1.txt\", \"test2.txt\", \"test3.md\"}\r\n\tfor _, file := range testFiles {\r\n\t\terr := ioutil.WriteFile(filepath.Join(tempDir, file), []byte(\"Test content\"), 0644)\r\n\t\tassert.NoError(t, err)\r\n\t}\r\n\r\n\t// Créer un répertoire de sortie\r\n\toutputDir := filepath.Join(tempDir, \"output\")\r\n\terr = os.Mkdir(outputDir, 0755)\r\n\tassert.NoError(t, err)\r\n\r\n\t// Exécuter la commande batch\r\n\tcmd := newBatchCmd()\r\n\tcmd.SetArgs([]string{\"--input-dir\", tempDir, \"--output-dir\", outputDir})\r\n\terr = cmd.Execute()\r\n\tassert.NoError(t, err)\r\n\r\n\t// Vérifier que les fichiers de sortie ont été créés\r\n\tfor _, file := range testFiles {\r\n\t\toutputFile := filepath.Join(outputDir, file+\".jsonld\")\r\n\t\t_, err := os.Stat(outputFile)\r\n\t\tassert.NoError(t, err, \"Output file should exist: %s\", outputFile)\r\n\t}\r\n}\r\n\r\n// TestConfigCommand teste la fonctionnalité de gestion de la configuration\r\nfunc TestConfigCommand(t *testing.T) {\r\n\t// Test d'affichage de la configuration\r\n\tcmd := newConfigCmd()\r\n\tbuf := new(bytes.Buffer)\r\n\tcmd.SetOut(buf)\r\n\tcmd.SetArgs([]string{\"--show\"})\r\n\terr := cmd.Execute()\r\n\tassert.NoError(t, err)\r\n\tassert.Contains(t, buf.String(), \"server:\")\r\n\tassert.Contains(t, buf.String(), \"conversion:\")\r\n\r\n\t// Test de modification de la configuration\r\n\tcmd = newConfigCmd()\r\n\tcmd.SetArgs([]string{\"--set-key\", \"conversion.max_tokens\", \"--set-value\", \"5000\"})\r\n\terr = cmd.Execute()\r\n\tassert.NoError(t, err)\r\n\r\n\t// Vérifier que la modification a été appliquée\r\n\tcmd = newConfigCmd()\r\n\tbuf = new(bytes.Buffer)\r\n\tcmd.SetOut(buf)\r\n\tcmd.SetArgs([]string{\"--show\"})\r\n\terr = cmd.Execute()\r\n\tassert.NoError(t, err)\r\n\tassert.Contains(t, buf.String(), \"max_tokens: 5000\")\r\n}\r\n\r\n// TestInteractiveCommand teste le mode interactif\r\nfunc TestInteractiveCommand(t *testing.T) {\r\n\t// Simuler une entrée utilisateur\r\n\tinput := \"test.txt\\noutput.jsonld\\nquit\\n\"\r\n\tin := bytes.NewBufferString(input)\r\n\r\n\t// Capturer la sortie\r\n\tout := new(bytes.Buffer)\r\n\r\n\t// Créer et exécuter la commande interactive\r\n\tcmd := newInteractiveCmd()\r\n\tcmd.SetIn(in)\r\n\tcmd.SetOut(out)\r\n\terr := cmd.Execute()\r\n\r\n\tassert.NoError(t, err)\r\n\tassert.Contains(t, out.String(), \"Welcome to interactive mode!\")\r\n\tassert.Contains(t, out.String(), \"Enter input file path\")\r\n\tassert.Contains(t, out.String(), \"Enter output file path\")\r\n}\r\n",
    "size": 2745,
    "modTime": "2024-10-14T19:19:07.3569013+02:00",
    "path": "cmd\\cli\\main_test.go"
  },
  {
    "name": "main.go",
    "content": "",
    "size": 0,
    "modTime": "2024-10-13T22:41:30.3072076+02:00",
    "path": "cmd\\server\\main.go"
  },
  {
    "name": "config.go",
    "content": "package config\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"strconv\"\n\n\t\"gopkg.in/yaml.v2\"\n)\n\ntype Config struct {\n\tServer struct {\n\t\tPort int    `yaml:\"port\"`\n\t\tHost string `yaml:\"host\"`\n\t} `yaml:\"server\"`\n\tLogging struct {\n\t\tLevel string `yaml:\"level\"`\n\t\tFile  string `yaml:\"file\"`\n\t} `yaml:\"logging\"`\n\tConversion struct {\n\t\tMaxTokens              int    `yaml:\"max_tokens\"`\n\t\tTargetBatchSize        int    `yaml:\"target_batch_size\"`\n\t\tNumThreads             int    `yaml:\"num_threads\"`\n\t\tEngine                 string `yaml:\"engine\"`\n\t\tModel                  string `yaml:\"model\"`\n\t\tContextSize            int    `yaml:\"context_size\"`\n\t\tTimeout                int    `yaml:\"timeout\"`\n\t\tOllamaHost             string `yaml:\"ollama_host\"`\n\t\tOllamaPort             string `yaml:\"ollama_port\"`\n\t\tAIYOUAssistantID       string `yaml:\"aiyou_assistant_id\"`\n\t\tAPIKey                 string `yaml:\"api_key\"`\n\t\tAIYOUEmail             string `yaml:\"aiyou_email\"`\n\t\tAIYOUPassword          string `yaml:\"aiyou_password\"`\n\t\tAdditionalInstructions string `yaml:\"additional_instructions\"`\n\t} `yaml:\"conversion\"`\n\tSchema struct {\n\t\tVersion  string `yaml:\"version\"`\n\t\tFilePath string `yaml:\"file_path\"`\n\t} `yaml:\"schema\"`\n\tSegmentation struct {\n\t\tMaxTokens       int `yaml:\"max_tokens\"`\n\t\tTargetBatchSize int `yaml:\"target_batch_size\"`\n\t} `yaml:\"segmentation\"`\n}\n\nvar (\n\tcfg Config\n)\n\nfunc Load(configPath string) error {\n\tdata, err := ioutil.ReadFile(configPath)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error reading config file: %v\", err)\n\t}\n\n\terr = yaml.Unmarshal(data, \u0026cfg)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error unmarshaling config: %v\", err)\n\t}\n\n\treturn nil\n}\n\nfunc Get() *Config {\n\treturn \u0026cfg\n}\n\nfunc (c *Config) OverrideFromEnv() {\n\tif port := os.Getenv(\"SERVER_PORT\"); port != \"\" {\n\t\tfmt.Sscanf(port, \"%d\", \u0026c.Server.Port)\n\t}\n\tif host := os.Getenv(\"SERVER_HOST\"); host != \"\" {\n\t\tc.Server.Host = host\n\t}\n\tif logLevel := os.Getenv(\"LOG_LEVEL\"); logLevel != \"\" {\n\t\tc.Logging.Level = logLevel\n\t}\n\tif logFile := os.Getenv(\"LOG_FILE\"); logFile != \"\" {\n\t\tc.Logging.File = logFile\n\t}\n\tif maxTokens := os.Getenv(\"MAX_TOKENS\"); maxTokens != \"\" {\n\t\tfmt.Sscanf(maxTokens, \"%d\", \u0026c.Conversion.MaxTokens)\n\t}\n\tif batchSize := os.Getenv(\"BATCH_SIZE\"); batchSize != \"\" {\n\t\tfmt.Sscanf(batchSize, \"%d\", \u0026c.Conversion.TargetBatchSize)\n\t}\n\tif numThreads := os.Getenv(\"NUM_THREADS\"); numThreads != \"\" {\n\t\tfmt.Sscanf(numThreads, \"%d\", \u0026c.Conversion.NumThreads)\n\t}\n\tif engine := os.Getenv(\"CONVERSION_ENGINE\"); engine != \"\" {\n\t\tc.Conversion.Engine = engine\n\t}\n\tif model := os.Getenv(\"CONVERSION_MODEL\"); model != \"\" {\n\t\tc.Conversion.Model = model\n\t}\n\tif contextSize := os.Getenv(\"CONTEXT_SIZE\"); contextSize != \"\" {\n\t\tfmt.Sscanf(contextSize, \"%d\", \u0026c.Conversion.ContextSize)\n\t}\n\tif timeout := os.Getenv(\"CONVERSION_TIMEOUT\"); timeout != \"\" {\n\t\tfmt.Sscanf(timeout, \"%d\", \u0026c.Conversion.Timeout)\n\t}\n\tif ollamaHost := os.Getenv(\"OLLAMA_HOST\"); ollamaHost != \"\" {\n\t\tc.Conversion.OllamaHost = ollamaHost\n\t}\n\tif ollamaPort := os.Getenv(\"OLLAMA_PORT\"); ollamaPort != \"\" {\n\t\tc.Conversion.OllamaPort = ollamaPort\n\t}\n\tif aiyouAssistantID := os.Getenv(\"AIYOU_ASSISTANT_ID\"); aiyouAssistantID != \"\" {\n\t\tc.Conversion.AIYOUAssistantID = aiyouAssistantID\n\t}\n\tif schemaVersion := os.Getenv(\"SCHEMA_VERSION\"); schemaVersion != \"\" {\n\t\tc.Schema.Version = schemaVersion\n\t}\n}\n\nfunc Set(key, value string) error {\n\t// Cette implémentation est simplifiée et ne gère que les clés de premier niveau\n\tswitch key {\n\tcase \"server.port\":\n\t\tport, err := strconv.Atoi(value)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"invalid port number: %s\", value)\n\t\t}\n\t\tcfg.Server.Port = port\n\tcase \"server.host\":\n\t\tcfg.Server.Host = value\n\t// Ajoutez d'autres cas pour les autres clés de configuration\n\tdefault:\n\t\treturn fmt.Errorf(\"unknown configuration key: %s\", key)\n\t}\n\treturn nil\n}\n",
    "size": 3812,
    "modTime": "2024-10-14T22:56:56.1724387+02:00",
    "path": "internal\\config\\config.go"
  },
  {
    "name": "config_test.go",
    "content": "package config\r\n\r\nimport (\r\n\t\"io/ioutil\"\r\n\t\"os\"\r\n\t\"testing\"\r\n)\r\n\r\nfunc TestLoadConfig(t *testing.T) {\r\n\t// Create a temporary config file\r\n\tcontent := []byte(`\r\nserver:\r\n  port: 8080\r\n  host: localhost\r\nlogging:\r\n  level: info\r\n  file: app.log\r\nconversion:\r\n  max_tokens: 4000\r\n  target_batch_size: 1000\r\n  num_threads: 4\r\n  engine: default\r\nschema:\r\n  version: \"1.0\"\r\n`)\r\n\ttmpfile, err := ioutil.TempFile(\"\", \"config.*.yaml\")\r\n\tif err != nil {\r\n\t\tt.Fatal(err)\r\n\t}\r\n\tdefer os.Remove(tmpfile.Name())\r\n\r\n\tif _, err := tmpfile.Write(content); err != nil {\r\n\t\tt.Fatal(err)\r\n\t}\r\n\tif err := tmpfile.Close(); err != nil {\r\n\t\tt.Fatal(err)\r\n\t}\r\n\r\n\t// Test loading the config\r\n\terr = Load(tmpfile.Name())\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"Failed to load config: %v\", err)\r\n\t}\r\n\r\n\tcfg := Get()\r\n\r\n\t// Check if values are correctly loaded\r\n\tif cfg.Server.Port != 8080 {\r\n\t\tt.Errorf(\"Expected server port 8080, got %d\", cfg.Server.Port)\r\n\t}\r\n\tif cfg.Logging.Level != \"info\" {\r\n\t\tt.Errorf(\"Expected logging level info, got %s\", cfg.Logging.Level)\r\n\t}\r\n\tif cfg.Conversion.MaxTokens != 4000 {\r\n\t\tt.Errorf(\"Expected max tokens 4000, got %d\", cfg.Conversion.MaxTokens)\r\n\t}\r\n\tif cfg.Schema.Version != \"1.0\" {\r\n\t\tt.Errorf(\"Expected schema version 1.0, got %s\", cfg.Schema.Version)\r\n\t}\r\n}\r\n\r\nfunc TestOverrideFromEnv(t *testing.T) {\r\n\t// Set environment variables\r\n\tos.Setenv(\"SERVER_PORT\", \"9090\")\r\n\tos.Setenv(\"LOG_LEVEL\", \"debug\")\r\n\tos.Setenv(\"MAX_TOKENS\", \"5000\")\r\n\tos.Setenv(\"SCHEMA_VERSION\", \"2.0\")\r\n\r\n\tcfg := \u0026Config{}\r\n\tcfg.OverrideFromEnv()\r\n\r\n\t// Check if values are correctly overridden\r\n\tif cfg.Server.Port != 9090 {\r\n\t\tt.Errorf(\"Expected server port 9090, got %d\", cfg.Server.Port)\r\n\t}\r\n\tif cfg.Logging.Level != \"debug\" {\r\n\t\tt.Errorf(\"Expected logging level debug, got %s\", cfg.Logging.Level)\r\n\t}\r\n\tif cfg.Conversion.MaxTokens != 5000 {\r\n\t\tt.Errorf(\"Expected max tokens 5000, got %d\", cfg.Conversion.MaxTokens)\r\n\t}\r\n\tif cfg.Schema.Version != \"2.0\" {\r\n\t\tt.Errorf(\"Expected schema version 2.0, got %s\", cfg.Schema.Version)\r\n\t}\r\n\r\n\t// Clean up\r\n\tos.Unsetenv(\"SERVER_PORT\")\r\n\tos.Unsetenv(\"LOG_LEVEL\")\r\n\tos.Unsetenv(\"MAX_TOKENS\")\r\n\tos.Unsetenv(\"SCHEMA_VERSION\")\r\n}\r\n",
    "size": 2149,
    "modTime": "2024-10-13T22:51:53.3523317+02:00",
    "path": "internal\\config\\config_test.go"
  },
  {
    "name": "converter.go",
    "content": "package jsonld\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/llm\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/schema\"\r\n\t\"github.com/chrlesur/json-ld-converter/pkg/tokenizer\"\r\n)\r\n\r\ntype Converter struct {\r\n\tschemaOrg              *schema.SchemaOrg\r\n\tllmClient              llm.LLMClient\r\n\tmaxTokens              int\r\n\tadditionalInstructions string\r\n}\r\n\r\nfunc NewConverter(schemaOrg *schema.SchemaOrg, client llm.LLMClient, maxTokens int, instructions string) *Converter {\r\n\treturn \u0026Converter{\r\n\t\tschemaOrg:              schemaOrg,\r\n\t\tllmClient:              client,\r\n\t\tmaxTokens:              maxTokens,\r\n\t\tadditionalInstructions: instructions,\r\n\t}\r\n}\r\n\r\nfunc (c *Converter) Convert(ctx context.Context, doc *parser.Document) (map[string]interface{}, error) {\r\n\t// Vérifier si le contenu dépasse la limite de tokens\r\n\tif tokenizer.CountTokens(doc.Content) \u003e c.maxTokens {\r\n\t\treturn nil, \u0026TokenLimitError{Limit: c.maxTokens, Count: tokenizer.CountTokens(doc.Content)}\r\n\t}\r\n\r\n\t// Initialiser la structure JSON-LD de base\r\n\tjsonLD := map[string]interface{}{\r\n\t\t\"@context\": \"https://schema.org\",\r\n\t}\r\n\r\n\t// Utiliser le LLM pour enrichir la conversion\r\n\tenrichedContent, err := c.enrichContentWithLLM(ctx, doc.Content)\r\n\tif err != nil {\r\n\t\treturn nil, \u0026ConversionError{Stage: \"enrichissement\", Err: err}\r\n\t}\r\n\r\n\t// Déterminer le type principal\r\n\tmainType, err := c.determineMainType(ctx, enrichedContent)\r\n\tif err != nil {\r\n\t\t// Stratégie de repli : utiliser \"Thing\" comme type par défaut\r\n\t\tmainType = \"Thing\"\r\n\t\tjsonLD[\"@type\"] = mainType\r\n\t}\r\n\r\n\t// Gérer les structures imbriquées\r\n\tnestedContent, err := c.handleNestedStructures(ctx, enrichedContent, mainType)\r\n\tif err != nil {\r\n\t\t// Stratégie de repli : utiliser une structure plate si la structure imbriquée échoue\r\n\t\tnestedContent, err = c.extractProperties(ctx, enrichedContent, mainType)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, \u0026ConversionError{Stage: \"extraction des propriétés\", Err: err}\r\n\t\t}\r\n\t}\r\n\r\n\t// Ajouter le contenu imbriqué à la structure JSON-LD\r\n\tfor key, value := range nestedContent {\r\n\t\tjsonLD[key] = value\r\n\t}\r\n\r\n\t// Appliquer les instructions supplémentaires\r\n\tjsonLD, err = c.applyAdditionalInstructions(ctx, jsonLD)\r\n\tif err != nil {\r\n\t\t// Ignorer l'erreur des instructions supplémentaires et continuer avec le JSON-LD non modifié\r\n\t\tfmt.Printf(\"Avertissement : impossible d'appliquer les instructions supplémentaires : %v\\n\", err)\r\n\t}\r\n\r\n\t// Vérifier la limite de tokens\r\n\tif err := c.checkTokenLimit(jsonLD); err != nil {\r\n\t\treturn nil, \u0026TokenLimitError{Limit: c.maxTokens, Count: tokenizer.CountTokens(fmt.Sprintf(\"%v\", jsonLD))}\r\n\t}\r\n\r\n\treturn jsonLD, nil\r\n}\r\n\r\nfunc (c *Converter) enrichContentWithLLM(ctx context.Context, content string) (string, error) {\r\n\tprompt := fmt.Sprintf(\"Analyzez et enrichissez sémantiquement le contenu suivant : %s\", content)\r\n\tenrichedContent, err := c.llmClient.Analyze(ctx, prompt)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"erreur lors de l'appel au LLM : %w\", err)\r\n\t}\r\n\treturn enrichedContent, nil\r\n}\r\n\r\nfunc (c *Converter) determineMainType(ctx context.Context, content string) (string, error) {\r\n\tprompt := fmt.Sprintf(\"Déterminez le type Schema.org le plus approprié pour le contenu suivant : %s\", content)\r\n\tresponse, err := c.llmClient.Analyze(ctx, prompt)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"erreur lors de l'appel au LLM : %w\", err)\r\n\t}\r\n\r\n\t// Vérifier si le type retourné existe dans le vocabulaire Schema.org\r\n\tif _, ok := c.schemaOrg.GetType(response); !ok {\r\n\t\treturn \"Thing\", nil // Utiliser \"Thing\" comme type par défaut si le type n'est pas reconnu\r\n\t}\r\n\r\n\treturn response, nil\r\n}\r\n\r\nfunc (c *Converter) extractProperties(ctx context.Context, content string, mainType string) (map[string]interface{}, error) {\r\n\tproperties := make(map[string]interface{})\r\n\r\n\t// Obtenir les propriétés applicables pour le type principal\r\n\tschemaType, ok := c.schemaOrg.GetType(mainType)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"type non trouvé dans le schéma : %s\", mainType)\r\n\t}\r\n\r\n\t// Utiliser le LLM pour extraire les valeurs des propriétés applicables\r\n\tfor _, prop := range schemaType.Properties {\r\n\t\tprompt := fmt.Sprintf(\"Extrayez la valeur de la propriété '%s' pour un objet de type '%s' à partir du contenu suivant : %s\", prop, mainType, content)\r\n\t\tvalue, err := c.llmClient.Analyze(ctx, prompt)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"erreur lors de l'extraction de la propriété '%s' : %w\", prop, err)\r\n\t\t}\r\n\r\n\t\tif value != \"\" {\r\n\t\t\tproperties[prop] = value\r\n\t\t}\r\n\t}\r\n\r\n\treturn properties, nil\r\n}\r\n\r\nfunc (c *Converter) handleNestedStructures(ctx context.Context, content string, mainType string) (map[string]interface{}, error) {\r\n\tjsonLD := make(map[string]interface{})\r\n\tjsonLD[\"@type\"] = mainType\r\n\r\n\tproperties, err := c.extractProperties(ctx, content, mainType)\r\n\tif err != nil {\r\n\t\treturn nil, \u0026ConversionError{Stage: \"extraction des propriétés\", Err: err}\r\n\t}\r\n\r\n\tfor key, value := range properties {\r\n\t\tif c.isObjectProperty(mainType, key) {\r\n\t\t\tnestedType, err := c.getExpectedType(mainType, key)\r\n\t\t\tif err != nil {\r\n\t\t\t\t// Stratégie de repli : utiliser \"Thing\" comme type par défaut pour les propriétés d'objet\r\n\t\t\t\tnestedType = \"Thing\"\r\n\t\t\t}\r\n\r\n\t\t\tnestedContent, err := c.extractNestedContent(ctx, content, key)\r\n\t\t\tif err != nil {\r\n\t\t\t\t// Stratégie de repli : utiliser la valeur extraite comme contenu texte simple\r\n\t\t\t\tjsonLD[key] = value\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\r\n\t\t\tnestedStructure, err := c.handleNestedStructures(ctx, nestedContent, nestedType)\r\n\t\t\tif err != nil {\r\n\t\t\t\t// Stratégie de repli : utiliser une structure plate pour le contenu imbriqué\r\n\t\t\t\tjsonLD[key] = map[string]interface{}{\r\n\t\t\t\t\t\"@type\": nestedType,\r\n\t\t\t\t\t\"text\":  nestedContent,\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\tjsonLD[key] = nestedStructure\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tjsonLD[key] = value\r\n\t\t}\r\n\t}\r\n\r\n\treturn jsonLD, nil\r\n}\r\n\r\nfunc (c *Converter) isObjectProperty(typeName, propertyName string) bool {\r\n\t// Implémentez la logique pour déterminer si une propriété est un objet\r\n\t// Cela peut impliquer de vérifier le type de la propriété dans le schéma\r\n\treturn false // Placeholder\r\n}\r\n\r\nfunc (c *Converter) getExpectedType(typeName, propertyName string) (string, error) {\r\n\t// Implémentez la logique pour obtenir le type attendu d'une propriété\r\n\treturn \"\", fmt.Errorf(\"not implemented\")\r\n}\r\n\r\nfunc (c *Converter) extractNestedContent(ctx context.Context, content string, property string) (string, error) {\r\n\tprompt := fmt.Sprintf(\"Extrayez le contenu spécifique à la propriété '%s' à partir du texte suivant : %s\", property, content)\r\n\tnestedContent, err := c.llmClient.Analyze(ctx, prompt)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"erreur lors de l'extraction du contenu imbriqué : %w\", err)\r\n\t}\r\n\treturn nestedContent, nil\r\n}\r\n\r\nfunc (c *Converter) applyAdditionalInstructions(ctx context.Context, jsonLD map[string]interface{}) (map[string]interface{}, error) {\r\n\tif c.additionalInstructions == \"\" {\r\n\t\treturn jsonLD, nil\r\n\t}\r\n\r\n\tprompt := fmt.Sprintf(\"Appliquez les instructions suivantes au JSON-LD : %s\\nJSON-LD actuel : %v\",\r\n\t\tc.additionalInstructions, jsonLD)\r\n\r\n\tresponse, err := c.llmClient.Analyze(ctx, prompt)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"erreur lors de l'application des instructions supplémentaires : %w\", err)\r\n\t}\r\n\r\n\tvar modifiedJsonLD map[string]interface{}\r\n\terr = json.Unmarshal([]byte(response), \u0026modifiedJsonLD)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"erreur lors de la désérialisation du JSON-LD modifié : %w\", err)\r\n\t}\r\n\r\n\treturn modifiedJsonLD, nil\r\n}\r\n\r\nfunc (c *Converter) checkTokenLimit(jsonLD map[string]interface{}) error {\r\n\tjsonString, err := json.Marshal(jsonLD)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"erreur lors de la sérialisation JSON : %w\", err)\r\n\t}\r\n\r\n\ttokenCount := tokenizer.CountTokens(string(jsonString))\r\n\tif tokenCount \u003e c.maxTokens {\r\n\t\treturn fmt.Errorf(\"la limite de tokens (%d) a été dépassée : %d tokens\", c.maxTokens, tokenCount)\r\n\t}\r\n\r\n\treturn nil\r\n}\r\n\r\nfunc (c *Converter) splitContent(content string) []string {\r\n\treturn tokenizer.SplitIntoTokens(content)\r\n}\r\n\r\nfunc (c *Converter) convertLargeDocument(ctx context.Context, content string) ([]map[string]interface{}, error) {\r\n\tsegments := c.splitContent(content)\r\n\tvar results []map[string]interface{}\r\n\r\n\tfor i, segment := range segments {\r\n\t\tjsonLD, err := c.convertSegment(ctx, segment)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"erreur lors de la conversion du segment %d : %w\", i, err)\r\n\t\t}\r\n\r\n\t\t// Ajouter des métadonnées pour indiquer la segmentation\r\n\t\tjsonLD[\"segment\"] = map[string]interface{}{\r\n\t\t\t\"index\": i + 1,\r\n\t\t\t\"total\": len(segments),\r\n\t\t}\r\n\r\n\t\tresults = append(results, jsonLD)\r\n\t}\r\n\r\n\treturn results, nil\r\n}\r\n\r\nfunc (c *Converter) convertSegment(ctx context.Context, segment string) (map[string]interface{}, error) {\r\n\t// Créer un Document temporaire pour le segment\r\n\tdoc := \u0026parser.Document{Content: segment}\r\n\treturn c.Convert(ctx, doc)\r\n}\r\n",
    "size": 9097,
    "modTime": "2024-10-15T00:27:56.1804761+02:00",
    "path": "internal\\jsonld\\converter.go"
  },
  {
    "name": "converter_test.go",
    "content": "package jsonld\r\n\r\nimport (\r\n\t\"testing\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/schema\"\r\n\t\"github.com/stretchr/testify/assert\"\r\n)\r\n\r\n// Mock du client LLM pour les tests\r\ntype mockLLMClient struct{}\r\n\r\nfunc (m *mockLLMClient) Translate(content, sourceLang, targetLang, additionalInstruction string) (string, error) {\r\n\t// Simuler une réponse simple pour les tests\r\n\treturn \"Contenu enrichi: \" + content, nil\r\n}\r\n\r\nfunc TestConvert(t *testing.T) {\r\n\t// Créer une instance de test du convertisseur\r\n\tmockVocabulary := schema.NewVocabulary() // Assurez-vous d'avoir une implémentation de test pour le vocabulaire\r\n\tmockLLM := \u0026mockLLMClient{}\r\n\tconverter := NewConverter(mockVocabulary, mockLLM, 1000, \"\")\r\n\r\n\ttestCases := []struct {\r\n\t\tname           string\r\n\t\tinput          string\r\n\t\texpectedOutput map[string]interface{}\r\n\t\texpectedError  error\r\n\t}{\r\n\t\t{\r\n\t\t\tname:  \"Conversion simple\",\r\n\t\t\tinput: \"Ceci est un test\",\r\n\t\t\texpectedOutput: map[string]interface{}{\r\n\t\t\t\t\"@context\": \"https://schema.org\",\r\n\t\t\t\t\"@type\":    \"Thing\",\r\n\t\t\t\t\"text\":     \"Contenu enrichi: Ceci est un test\",\r\n\t\t\t},\r\n\t\t\texpectedError: nil,\r\n\t\t},\r\n\t\t// Ajoutez d'autres cas de test ici\r\n\t}\r\n\r\n\tfor _, tc := range testCases {\r\n\t\tt.Run(tc.name, func(t *testing.T) {\r\n\t\t\tsegment := \u0026parser.DocumentSegment{Content: tc.input}\r\n\t\t\tresult, err := converter.Convert(segment)\r\n\r\n\t\t\tif tc.expectedError != nil {\r\n\t\t\t\tassert.Error(t, err)\r\n\t\t\t\tassert.Equal(t, tc.expectedError.Error(), err.Error())\r\n\t\t\t} else {\r\n\t\t\t\tassert.NoError(t, err)\r\n\t\t\t\tassert.Equal(t, tc.expectedOutput, result)\r\n\t\t\t}\r\n\t\t})\r\n\t}\r\n}\r\n\r\nfunc TestHandleNestedStructures(t *testing.T) {\r\n\t// Test similaire pour handleNestedStructures\r\n\t// ...\r\n}\r\n\r\nfunc TestApplyAdditionalInstructions(t *testing.T) {\r\n\t// Test pour applyAdditionalInstructions\r\n\t// ...\r\n}\r\n\r\nfunc TestTokenLimitHandling(t *testing.T) {\r\n\t// Test pour vérifier la gestion des limites de tokens\r\n\t// ...\r\n}\r\n\r\nfunc TestIntegration(t *testing.T) {\r\n\t// Test d'intégration simulant un flux complet de conversion\r\n\t// ...\r\n}\r\n",
    "size": 2097,
    "modTime": "2024-10-14T18:32:11.3227115+02:00",
    "path": "internal\\jsonld\\converter_test.go"
  },
  {
    "name": "error.go",
    "content": "package jsonld\r\n\r\nimport (\r\n\t\"fmt\"\r\n)\r\n\r\ntype ConversionError struct {\r\n\tStage string\r\n\tErr   error\r\n}\r\n\r\nfunc (e *ConversionError) Error() string {\r\n\treturn fmt.Sprintf(\"erreur de conversion lors de l'étape '%s': %v\", e.Stage, e.Err)\r\n}\r\n\r\ntype TokenLimitError struct {\r\n\tLimit int\r\n\tCount int\r\n}\r\n\r\nfunc (e *TokenLimitError) Error() string {\r\n\treturn fmt.Sprintf(\"limite de tokens dépassée : %d tokens (limite : %d)\", e.Count, e.Limit)\r\n}\r\n\r\ntype SchemaOrgError struct {\r\n\tType string\r\n\tErr  error\r\n}\r\n\r\nfunc (e *SchemaOrgError) Error() string {\r\n\treturn fmt.Sprintf(\"erreur liée au vocabulaire Schema.org pour le type '%s': %v\", e.Type, e.Err)\r\n}\r\n",
    "size": 655,
    "modTime": "2024-10-14T18:29:16.4992712+02:00",
    "path": "internal\\jsonld\\error.go"
  },
  {
    "name": "aiyou.go",
    "content": "package llm\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"context\"\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"io/ioutil\"\r\n\t\"net/http\"\r\n\t\"time\"\r\n)\r\n\r\nconst AIYOUAPIURL = \"https://ai.dragonflygroup.fr/api\"\r\n\r\n// AIYOUClient implémente l'interface LLMClient pour AI.YOU\r\ntype AIYOUClient struct {\r\n\tToken       string\r\n\tAssistantID string\r\n\tTimeout     time.Duration\r\n\tHTTPClient  *http.Client\r\n}\r\n\r\n// NewAIYOUClient crée et retourne une nouvelle instance de AIYOUClient\r\nfunc NewAIYOUClient(assistantID string, timeout time.Duration) *AIYOUClient {\r\n\treturn \u0026AIYOUClient{\r\n\t\tAssistantID: assistantID,\r\n\t\tTimeout:     timeout,\r\n\t\tHTTPClient:  \u0026http.Client{Timeout: timeout},\r\n\t}\r\n}\r\n\r\n// Login effectue l'authentification auprès de l'API AI.YOU\r\nfunc (c *AIYOUClient) Login(email, password string) error {\r\n\tloginData := map[string]string{\r\n\t\t\"email\":    email,\r\n\t\t\"password\": password,\r\n\t}\r\n\tjsonData, err := json.Marshal(loginData)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error marshaling login data: %w\", err)\r\n\t}\r\n\r\n\tresp, err := c.makeAPICall(\"/login\", \"POST\", jsonData)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"login error: %w\", err)\r\n\t}\r\n\r\n\tvar loginResp struct {\r\n\t\tToken string `json:\"token\"`\r\n\t}\r\n\tif err := json.Unmarshal(resp, \u0026loginResp); err != nil {\r\n\t\treturn fmt.Errorf(\"error unmarshaling login response: %w\", err)\r\n\t}\r\n\r\n\tc.Token = loginResp.Token\r\n\treturn nil\r\n}\r\n\r\n// Translate implémente la méthode de l'interface LLMClient pour AI.YOU\r\nfunc (c *AIYOUClient) Analyze(ctx context.Context, content string) (string, error) {\r\n\tprompt := `Analysez le contenu fourni (représentant une partie d'un document plus large) et identifiez les principaux triplets entité-relation-attribut présents dans le texte. Concentrez-vous sur les concepts et relations importants au niveau du paragraphe, en gardant la chronologie des événements.\r\n\r\nInstructions :\r\n1. Analysez chaque paragraphe du chunk en détail.\r\n2. Identifiez les triplets les plus pertinents et significatifs, en vous concentrant sur les idées principales et les informations clés.\r\n3. Pour chaque triplet qui représente un fait à un moment donné, indiquez un lien vers l'événement précédent et suivant s'ils existent dans le même chunk.\r\n4. Présentez les résultats sous forme de liste de triplets, un par ligne, séparés par des tabulations.\r\n\r\nFormat de réponse attendu :\r\n\"Entité principale\"\t\"Relation importante\"\t\"Attribut ou entité liée significative\"\t\"Événement précédent (si applicable)\"\t\"Événement suivant (si applicable)\"\r\n...\r\n\r\nAssurez-vous que :\r\n- Chaque triplet représente une information importante extraite du texte fourni.\r\n- Les concepts, relations et attributs identifiés sont pertinents pour la compréhension globale du document.\r\n- Les liens vers les événements précédents et suivants sont inclus uniquement pour les faits à un moment donné.\r\n- Votre analyse capture l'essence du contenu et la séquence des informations telles qu'elles apparaissent dans le document.\r\n\r\nIMPORTANT : Ne renvoyez que la liste des triplets avec leurs informations de séquence, sans aucun texte explicatif ou commentaire supplémentaire. L'application s'attend à recevoir uniquement les triplets bruts pour pouvoir les traiter correctement.\r\n\r\nContenu à analyser :\r\n` + content\r\n\r\n\tthreadID, err := c.createThread()\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error creating thread: %w\", err)\r\n\t}\r\n\r\n\tif err := c.addMessage(threadID, prompt); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error adding message to thread: %w\", err)\r\n\t}\r\n\r\n\trunID, err := c.createRun(threadID)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error creating run: %w\", err)\r\n\t}\r\n\r\n\tcompletedRun, err := c.waitForCompletion(threadID, runID)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error waiting for run completion: %w\", err)\r\n\t}\r\n\r\n\tresponse, ok := (*completedRun)[\"response\"].(string)\r\n\tif !ok {\r\n\t\treturn \"\", fmt.Errorf(\"response could not be extracted from the run\")\r\n\t}\r\n\r\n\treturn response, nil\r\n}\r\n\r\n// Les méthodes suivantes sont des utilitaires pour interagir avec l'API AI.YOU\r\n\r\nfunc (c *AIYOUClient) createThread() (string, error) {\r\n\tresp, err := c.makeAPICall(\"/v1/threads\", \"POST\", []byte(\"{}\"))\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\r\n\tvar threadResp struct {\r\n\t\tID string `json:\"id\"`\r\n\t}\r\n\tif err := json.Unmarshal(resp, \u0026threadResp); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error unmarshaling thread response: %w\", err)\r\n\t}\r\n\r\n\treturn threadResp.ID, nil\r\n}\r\n\r\nfunc (c *AIYOUClient) addMessage(threadID, content string) error {\r\n\tmessageData := map[string]string{\r\n\t\t\"role\":    \"user\",\r\n\t\t\"content\": content,\r\n\t}\r\n\tjsonData, err := json.Marshal(messageData)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error marshaling message data: %w\", err)\r\n\t}\r\n\r\n\t_, err = c.makeAPICall(fmt.Sprintf(\"/v1/threads/%s/messages\", threadID), \"POST\", jsonData)\r\n\treturn err\r\n}\r\n\r\nfunc (c *AIYOUClient) createRun(threadID string) (string, error) {\r\n\trunData := map[string]string{\r\n\t\t\"assistantId\": c.AssistantID,\r\n\t}\r\n\tjsonData, err := json.Marshal(runData)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error marshaling run data: %w\", err)\r\n\t}\r\n\r\n\tresp, err := c.makeAPICall(fmt.Sprintf(\"/v1/threads/%s/runs\", threadID), \"POST\", jsonData)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\r\n\tvar runResp struct {\r\n\t\tID string `json:\"id\"`\r\n\t}\r\n\tif err := json.Unmarshal(resp, \u0026runResp); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error unmarshaling run response: %w\", err)\r\n\t}\r\n\r\n\treturn runResp.ID, nil\r\n}\r\n\r\nfunc (c *AIYOUClient) waitForCompletion(threadID, runID string) (*map[string]interface{}, error) {\r\n\tfor i := 0; i \u003c 30; i++ {\r\n\t\trun, err := c.retrieveRun(threadID, runID)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\r\n\t\tstatus, ok := run[\"status\"].(string)\r\n\t\tif !ok {\r\n\t\t\treturn nil, fmt.Errorf(\"run status not found or invalid\")\r\n\t\t}\r\n\r\n\t\tif status == \"completed\" {\r\n\t\t\treturn \u0026run, nil\r\n\t\t}\r\n\r\n\t\tif status == \"failed\" || status == \"cancelled\" {\r\n\t\t\treturn nil, fmt.Errorf(\"run failed with status: %s\", status)\r\n\t\t}\r\n\r\n\t\ttime.Sleep(2 * time.Second)\r\n\t}\r\n\r\n\treturn nil, fmt.Errorf(\"timeout waiting for run completion\")\r\n}\r\n\r\nfunc (c *AIYOUClient) retrieveRun(threadID, runID string) (map[string]interface{}, error) {\r\n\tresp, err := c.makeAPICall(fmt.Sprintf(\"/v1/threads/%s/runs/%s\", threadID, runID), \"POST\", []byte(\"{}\"))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\tvar runStatus map[string]interface{}\r\n\tif err := json.Unmarshal(resp, \u0026runStatus); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error unmarshaling run status: %w\", err)\r\n\t}\r\n\r\n\treturn runStatus, nil\r\n}\r\n\r\nfunc (c *AIYOUClient) makeAPICall(endpoint, method string, data []byte) ([]byte, error) {\r\n\turl := AIYOUAPIURL + endpoint\r\n\treq, err := http.NewRequest(method, url, bytes.NewBuffer(data))\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error creating HTTP request: %w\", err)\r\n\t}\r\n\r\n\treq.Header.Set(\"Content-Type\", \"application/json\")\r\n\tif c.Token != \"\" {\r\n\t\treq.Header.Set(\"Authorization\", \"Bearer \"+c.Token)\r\n\t}\r\n\r\n\tresp, err := c.HTTPClient.Do(req)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error sending request to AI.YOU API: %w\", err)\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\r\n\tbody, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error reading response body: %w\", err)\r\n\t}\r\n\r\n\tif resp.StatusCode != http.StatusOK \u0026\u0026 resp.StatusCode != http.StatusCreated {\r\n\t\treturn nil, fmt.Errorf(\"API error (%d): %s\", resp.StatusCode, string(body))\r\n\t}\r\n\r\n\treturn body, nil\r\n}\r\n",
    "size": 7403,
    "modTime": "2024-10-15T00:18:31.9879182+02:00",
    "path": "internal\\llm\\aiyou.go"
  },
  {
    "name": "claude.go",
    "content": "package llm\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"context\"\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"net/http\"\r\n\t\"time\"\r\n)\r\n\r\nconst ClaudeAPIURL = \"https://api.anthropic.com/v1/messages\"\r\n\r\n// ClaudeClient implémente l'interface LLMClient pour le modèle Claude d'Anthropic\r\ntype ClaudeClient struct {\r\n\tAPIKey      string\r\n\tModel       string\r\n\tContextSize int\r\n\tTimeout     time.Duration\r\n\tHTTPClient  *http.Client\r\n}\r\n\r\n// NewClaudeClient crée et retourne une nouvelle instance de ClaudeClient\r\nfunc NewClaudeClient(apiKey, model string, contextSize int, timeout time.Duration) *ClaudeClient {\r\n\treturn \u0026ClaudeClient{\r\n\t\tAPIKey:      apiKey,\r\n\t\tModel:       model,\r\n\t\tContextSize: contextSize,\r\n\t\tTimeout:     timeout,\r\n\t\tHTTPClient:  \u0026http.Client{Timeout: timeout},\r\n\t}\r\n}\r\n\r\n// claudeRequest représente la structure de la requête à l'API Claude\r\ntype claudeRequest struct {\r\n\tModel     string    `json:\"model\"`\r\n\tMessages  []message `json:\"messages\"`\r\n\tMaxTokens int       `json:\"max_tokens\"`\r\n}\r\n\r\ntype message struct {\r\n\tRole    string `json:\"role\"`\r\n\tContent string `json:\"content\"`\r\n}\r\n\r\n// claudeResponse représente la structure de la réponse de l'API Claude\r\ntype claudeResponse struct {\r\n\tContent []struct {\r\n\t\tText string `json:\"text\"`\r\n\t} `json:\"content\"`\r\n}\r\n\r\n// Translate implémente la méthode de l'interface LLMClient pour Claude\r\nfunc (c *ClaudeClient) Analyze(ctx context.Context, content string) (string, error) {\r\n\tprompt := `Analysez le contenu fourni (représentant une partie d'un document plus large) et identifiez les principaux triplets entité-relation-attribut présents dans le texte. Concentrez-vous sur les concepts et relations importants au niveau du paragraphe, en gardant la chronologie des événements.\r\n\r\nInstructions :\r\n1. Analysez chaque paragraphe du chunk en détail.\r\n2. Identifiez les triplets les plus pertinents et significatifs, en vous concentrant sur les idées principales et les informations clés.\r\n3. Pour chaque triplet qui représente un fait à un moment donné, indiquez un lien vers l'événement précédent et suivant s'ils existent dans le même chunk.\r\n4. Présentez les résultats sous forme de liste de triplets, un par ligne, séparés par des tabulations.\r\n\r\nFormat de réponse attendu :\r\n\"Entité principale\"\t\"Relation importante\"\t\"Attribut ou entité liée significative\"\t\"Événement précédent (si applicable)\"\t\"Événement suivant (si applicable)\"\r\n...\r\n\r\nAssurez-vous que :\r\n- Chaque triplet représente une information importante extraite du texte fourni.\r\n- Les concepts, relations et attributs identifiés sont pertinents pour la compréhension globale du document.\r\n- Les liens vers les événements précédents et suivants sont inclus uniquement pour les faits à un moment donné.\r\n- Votre analyse capture l'essence du contenu et la séquence des informations telles qu'elles apparaissent dans le document.\r\n\r\nIMPORTANT : Ne renvoyez que la liste des triplets avec leurs informations de séquence, sans aucun texte explicatif ou commentaire supplémentaire. L'application s'attend à recevoir uniquement les triplets bruts pour pouvoir les traiter correctement.\r\n\r\nContenu à analyser :\r\n` + content\r\n\r\n\treqBody := claudeRequest{\r\n\t\tModel: c.Model,\r\n\t\tMessages: []message{\r\n\t\t\t{Role: \"user\", Content: prompt},\r\n\t\t},\r\n\t\tMaxTokens: c.ContextSize,\r\n\t}\r\n\r\n\tjsonData, err := json.Marshal(reqBody)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error marshaling request body: %w\", err)\r\n\t}\r\n\r\n\treq, err := http.NewRequestWithContext(ctx, \"POST\", ClaudeAPIURL, bytes.NewBuffer(jsonData))\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error creating request: %w\", err)\r\n\t}\r\n\r\n\treq.Header.Set(\"Content-Type\", \"application/json\")\r\n\treq.Header.Set(\"x-api-key\", c.APIKey)\r\n\treq.Header.Set(\"anthropic-version\", \"2023-06-01\")\r\n\r\n\tresp, err := c.HTTPClient.Do(req)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error sending request to Claude API: %w\", err)\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\treturn \"\", fmt.Errorf(\"Claude API returned non-OK status: %d\", resp.StatusCode)\r\n\t}\r\n\r\n\tvar claudeResp claudeResponse\r\n\tif err := json.NewDecoder(resp.Body).Decode(\u0026claudeResp); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error decoding Claude API response: %w\", err)\r\n\t}\r\n\r\n\tif len(claudeResp.Content) == 0 {\r\n\t\treturn \"\", fmt.Errorf(\"no content in Claude API response\")\r\n\t}\r\n\r\n\treturn claudeResp.Content[0].Text, nil\r\n}\r\n",
    "size": 4394,
    "modTime": "2024-10-15T00:15:18.1567429+02:00",
    "path": "internal\\llm\\claude.go"
  },
  {
    "name": "factory.go",
    "content": "package llm\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"os\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/config\"\r\n)\r\n\r\n// NewLLMClient crée et retourne le client LLM approprié en fonction du type de moteur spécifié\r\nfunc NewLLMClient(cfg *config.Config) (LLMClient, error) {\r\n    switch cfg.Conversion.Engine {\r\n    case \"claude\":\r\n        apiKey := os.Getenv(\"CLAUDE_API_KEY\")\r\n        if apiKey == \"\" {\r\n            return nil, fmt.Errorf(\"CLAUDE_API_KEY environment variable is not set\")\r\n        }\r\n        return NewClaudeClient(apiKey, cfg.Conversion.Model, cfg.Conversion.ContextSize, time.Duration(cfg.Conversion.Timeout)*time.Second), nil\r\n    case \"openai\":\r\n        apiKey := os.Getenv(\"OPENAI_API_KEY\")\r\n        if apiKey == \"\" {\r\n            return nil, fmt.Errorf(\"OPENAI_API_KEY environment variable is not set\")\r\n        }\r\n        return NewOpenAIClient(apiKey, cfg.Conversion.Model, cfg.Conversion.ContextSize, time.Duration(cfg.Conversion.Timeout)*time.Second), nil\r\n    case \"ollama\":\r\n        return NewOllamaClient(cfg.Conversion.OllamaHost, cfg.Conversion.OllamaPort, cfg.Conversion.Model, cfg.Conversion.ContextSize, time.Duration(cfg.Conversion.Timeout)*time.Second), nil\r\n    case \"aiyou\":\r\n        client := NewAIYOUClient(cfg.Conversion.AIYOUAssistantID, time.Duration(cfg.Conversion.Timeout)*time.Second)\r\n        email := os.Getenv(\"AIYOU_EMAIL\")\r\n        password := os.Getenv(\"AIYOU_PASSWORD\")\r\n        if email == \"\" || password == \"\" {\r\n            return nil, fmt.Errorf(\"AIYOU_EMAIL or AIYOU_PASSWORD environment variable is not set\")\r\n        }\r\n        err := client.Login(email, password)\r\n        if err != nil {\r\n            return nil, fmt.Errorf(\"failed to login to AI.YOU: %w\", err)\r\n        }\r\n        return client, nil\r\n    default:\r\n        return nil, fmt.Errorf(\"unsupported LLM engine: %s\", cfg.Conversion.Engine)\r\n    }\r\n}",
    "size": 1873,
    "modTime": "2024-10-14T19:23:43.35824+02:00",
    "path": "internal\\llm\\factory.go"
  },
  {
    "name": "interface.go",
    "content": "package llm\r\n\r\nimport (\r\n\t\"context\"\r\n)\r\n\r\ntype LLMClient interface {\r\n\tAnalyze(ctx context.Context, content string) (string, error)\r\n}\r\n",
    "size": 136,
    "modTime": "2024-10-15T00:12:11.5681451+02:00",
    "path": "internal\\llm\\interface.go"
  },
  {
    "name": "ollama.go",
    "content": "package llm\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"context\"\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"net/http\"\r\n\t\"time\"\r\n)\r\n\r\n// OllamaClient implémente l'interface LLMClient pour les modèles Ollama\r\ntype OllamaClient struct {\r\n\thost        string\r\n\tport        string\r\n\tmodel       string\r\n\tcontextSize int\r\n\ttimeout     time.Duration\r\n\thttpClient  *http.Client\r\n}\r\n\r\n// NewOllamaClient crée et retourne une nouvelle instance de OllamaClient\r\nfunc NewOllamaClient(host, port, model string, contextSize int, timeout time.Duration) *OllamaClient {\r\n\treturn \u0026OllamaClient{\r\n\t\thost:        host,\r\n\t\tport:        port,\r\n\t\tmodel:       model,\r\n\t\tcontextSize: contextSize,\r\n\t\ttimeout:     timeout,\r\n\t\thttpClient:  \u0026http.Client{Timeout: timeout},\r\n\t}\r\n}\r\n\r\ntype ollamaRequest struct {\r\n\tModel   string `json:\"model\"`\r\n\tPrompt  string `json:\"prompt\"`\r\n\tStream  bool   `json:\"stream\"`\r\n\tOptions struct {\r\n\t\tNumCtx int `json:\"num_ctx\"`\r\n\t} `json:\"options\"`\r\n}\r\n\r\ntype ollamaResponse struct {\r\n\tResponse string `json:\"response\"`\r\n}\r\n\r\n// Translate implémente la méthode de l'interface LLMClient pour Ollama\r\nfunc (c *OllamaClient) Analyze(ctx context.Context, content string) (string, error) {\r\n\tprompt := `Analysez le contenu fourni (représentant une partie d'un document plus large) et identifiez les principaux triplets entité-relation-attribut présents dans le texte. Concentrez-vous sur les concepts et relations importants au niveau du paragraphe, en gardant la chronologie des événements.\r\n\r\nInstructions :\r\n1. Analysez chaque paragraphe du chunk en détail.\r\n2. Identifiez les triplets les plus pertinents et significatifs, en vous concentrant sur les idées principales et les informations clés.\r\n3. Pour chaque triplet qui représente un fait à un moment donné, indiquez un lien vers l'événement précédent et suivant s'ils existent dans le même chunk.\r\n4. Présentez les résultats sous forme de liste de triplets, un par ligne, séparés par des tabulations.\r\n\r\nFormat de réponse attendu :\r\n\"Entité principale\"\t\"Relation importante\"\t\"Attribut ou entité liée significative\"\t\"Événement précédent (si applicable)\"\t\"Événement suivant (si applicable)\"\r\n...\r\n\r\nAssurez-vous que :\r\n- Chaque triplet représente une information importante extraite du texte fourni.\r\n- Les concepts, relations et attributs identifiés sont pertinents pour la compréhension globale du document.\r\n- Les liens vers les événements précédents et suivants sont inclus uniquement pour les faits à un moment donné.\r\n- Votre analyse capture l'essence du contenu et la séquence des informations telles qu'elles apparaissent dans le document.\r\n\r\nIMPORTANT : Ne renvoyez que la liste des triplets avec leurs informations de séquence, sans aucun texte explicatif ou commentaire supplémentaire. L'application s'attend à recevoir uniquement les triplets bruts pour pouvoir les traiter correctement.\r\n\r\nContenu à analyser :\r\n` + content\r\n\r\n\treqBody := ollamaRequest{\r\n\t\tModel:  c.model,\r\n\t\tPrompt: prompt,\r\n\t\tStream: false,\r\n\t}\r\n\treqBody.Options.NumCtx = c.contextSize\r\n\r\n\tjsonData, err := json.Marshal(reqBody)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error marshaling request body: %w\", err)\r\n\t}\r\n\r\n\turl := fmt.Sprintf(\"http://%s:%s/api/generate\", c.host, c.port)\r\n\treq, err := http.NewRequestWithContext(ctx, \"POST\", url, bytes.NewBuffer(jsonData))\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error creating request: %w\", err)\r\n\t}\r\n\r\n\treq.Header.Set(\"Content-Type\", \"application/json\")\r\n\r\n\tresp, err := c.httpClient.Do(req)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error sending request to Ollama API: %w\", err)\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\treturn \"\", fmt.Errorf(\"Ollama API returned non-OK status: %d\", resp.StatusCode)\r\n\t}\r\n\r\n\tvar ollamaResp ollamaResponse\r\n\tif err := json.NewDecoder(resp.Body).Decode(\u0026ollamaResp); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error decoding Ollama API response: %w\", err)\r\n\t}\r\n\r\n\treturn ollamaResp.Response, nil\r\n}\r\n",
    "size": 3975,
    "modTime": "2024-10-15T00:17:18.110378+02:00",
    "path": "internal\\llm\\ollama.go"
  },
  {
    "name": "openai.go",
    "content": "package llm\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"fmt\"\r\n\t\"time\"\r\n\r\n\t\"github.com/sashabaranov/go-openai\"\r\n)\r\n\r\n// OpenAIClient implémente l'interface LLMClient pour les modèles GPT d'OpenAI\r\ntype OpenAIClient struct {\r\n\tclient      *openai.Client\r\n\tmodel       string\r\n\tcontextSize int\r\n\ttimeout     time.Duration\r\n}\r\n\r\n// NewOpenAIClient crée et retourne une nouvelle instance de OpenAIClient\r\nfunc NewOpenAIClient(apiKey, model string, contextSize int, timeout time.Duration) *OpenAIClient {\r\n\treturn \u0026OpenAIClient{\r\n\t\tclient:      openai.NewClient(apiKey),\r\n\t\tmodel:       model,\r\n\t\tcontextSize: contextSize,\r\n\t\ttimeout:     timeout,\r\n\t}\r\n}\r\n\r\n// Translate implémente la méthode de l'interface LLMClient pour OpenAI\r\nfunc (c *OpenAIClient) Analyze(ctx context.Context, content string) (string, error) {\r\n\tprompt := `Analysez le contenu fourni (représentant une partie d'un document plus large) et identifiez les principaux triplets entité-relation-attribut présents dans le texte. Concentrez-vous sur les concepts et relations importants au niveau du paragraphe, en gardant la chronologie des événements.\r\n\r\nInstructions :\r\n1. Analysez chaque paragraphe du chunk en détail.\r\n2. Identifiez les triplets les plus pertinents et significatifs, en vous concentrant sur les idées principales et les informations clés.\r\n3. Pour chaque triplet qui représente un fait à un moment donné, indiquez un lien vers l'événement précédent et suivant s'ils existent dans le même chunk.\r\n4. Présentez les résultats sous forme de liste de triplets, un par ligne, séparés par des tabulations.\r\n\r\nFormat de réponse attendu :\r\n\"Entité principale\"\t\"Relation importante\"\t\"Attribut ou entité liée significative\"\t\"Événement précédent (si applicable)\"\t\"Événement suivant (si applicable)\"\r\n...\r\n\r\nAssurez-vous que :\r\n- Chaque triplet représente une information importante extraite du texte fourni.\r\n- Les concepts, relations et attributs identifiés sont pertinents pour la compréhension globale du document.\r\n- Les liens vers les événements précédents et suivants sont inclus uniquement pour les faits à un moment donné.\r\n- Votre analyse capture l'essence du contenu et la séquence des informations telles qu'elles apparaissent dans le document.\r\n\r\nIMPORTANT : Ne renvoyez que la liste des triplets avec leurs informations de séquence, sans aucun texte explicatif ou commentaire supplémentaire. L'application s'attend à recevoir uniquement les triplets bruts pour pouvoir les traiter correctement.\r\n\r\nContenu à analyser :\r\n` + content\r\n\r\n\treq := openai.ChatCompletionRequest{\r\n\t\tModel: c.model,\r\n\t\tMessages: []openai.ChatCompletionMessage{\r\n\t\t\t{\r\n\t\t\t\tRole:    openai.ChatMessageRoleUser,\r\n\t\t\t\tContent: prompt,\r\n\t\t\t},\r\n\t\t},\r\n\t\tMaxTokens: c.contextSize,\r\n\t}\r\n\r\n\tctx, cancel := context.WithTimeout(ctx, c.timeout)\r\n\tdefer cancel()\r\n\r\n\tresp, err := c.client.CreateChatCompletion(ctx, req)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error calling OpenAI API: %w\", err)\r\n\t}\r\n\r\n\tif len(resp.Choices) == 0 {\r\n\t\treturn \"\", fmt.Errorf(\"no content in OpenAI API response\")\r\n\t}\r\n\r\n\treturn resp.Choices[0].Message.Content, nil\r\n}\r\n",
    "size": 3130,
    "modTime": "2024-10-15T00:19:33.478941+02:00",
    "path": "internal\\llm\\openai.go"
  },
  {
    "name": "logger.go",
    "content": "package logger\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"sync\"\n\t\"time\"\n)\n\ntype LogLevel int\n\nconst (\n\tDEBUG LogLevel = iota\n\tINFO\n\tWARNING\n\tERROR\n)\n\nvar (\n\tlogLevel   LogLevel\n\tlogFile    *os.File\n\tconsole    io.Writer\n\tmu         sync.Mutex\n\tsilentMode bool\n\tdebugMode  bool\n)\n\nfunc Init(level LogLevel, filePath string) error {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\n\tlogLevel = level\n\n\tif filePath != \"\" {\n\t\tvar err error\n\t\tlogFile, err = os.OpenFile(filePath, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to open log file: %w\", err)\n\t\t}\n\t}\n\n\tconsole = os.Stdout\n\treturn nil\n}\n\nfunc SetLogLevel(level LogLevel) {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tlogLevel = level\n}\n\nfunc SetSilentMode(silent bool) {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tsilentMode = silent\n}\n\nfunc SetDebugMode(debug bool) {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tdebugMode = debug\n\tif debug {\n\t\tlogLevel = DEBUG\n\t}\n}\n\nfunc log(level LogLevel, message string) {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\n\tif level \u003c logLevel {\n\t\treturn\n\t}\n\n\ttimestamp := time.Now().Format(\"2006-01-02 15:04:05\")\n\tlogMessage := fmt.Sprintf(\"[%s] %s: %s\\n\", timestamp, getLevelString(level), message)\n\n\tif logFile != nil {\n\t\tlogFile.WriteString(logMessage)\n\t}\n\n\tif !silentMode {\n\t\tfmt.Fprint(console, logMessage)\n\t}\n}\n\nfunc getLevelString(level LogLevel) string {\n\tswitch level {\n\tcase DEBUG:\n\t\treturn \"DEBUG\"\n\tcase INFO:\n\t\treturn \"INFO\"\n\tcase WARNING:\n\t\treturn \"WARNING\"\n\tcase ERROR:\n\t\treturn \"ERROR\"\n\tdefault:\n\t\treturn \"UNKNOWN\"\n\t}\n}\n\nfunc Debug(message string) {\n\tif debugMode {\n\t\tlog(DEBUG, message)\n\t}\n}\n\nfunc Info(message string) {\n\tlog(INFO, message)\n}\n\nfunc Warning(message string) {\n\tlog(WARNING, message)\n}\n\nfunc Error(message string) {\n\tlog(ERROR, message)\n}\n\nfunc Close() {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\n\tif logFile != nil {\n\t\tlogFile.Close()\n\t}\n}\n",
    "size": 1811,
    "modTime": "2024-10-13T22:44:24.2222347+02:00",
    "path": "internal\\logger\\logger.go"
  },
  {
    "name": "logger_test.go",
    "content": "package logger\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"os\"\r\n\t\"strings\"\r\n\t\"testing\"\r\n)\r\n\r\nfunc TestLogging(t *testing.T) {\r\n\t// Redirect stdout to capture output\r\n\told := os.Stdout\r\n\tr, w, _ := os.Pipe()\r\n\tos.Stdout = w\r\n\r\n\t// Initialize logger\r\n\tInit(INFO, \"\")\r\n\tSetDebugMode(true)\r\n\r\n\t// Test logging\r\n\tDebug(\"This is a debug message\")\r\n\tInfo(\"This is an info message\")\r\n\tWarning(\"This is a warning message\")\r\n\tError(\"This is an error message\")\r\n\r\n\t// Reset stdout\r\n\tw.Close()\r\n\tos.Stdout = old\r\n\r\n\tvar buf bytes.Buffer\r\n\t_, _ = buf.ReadFrom(r)\r\n\toutput := buf.String()\r\n\r\n\t// Check if all messages are present\r\n\tif !strings.Contains(output, \"DEBUG\") {\r\n\t\tt.Error(\"Debug message not found in output\")\r\n\t}\r\n\tif !strings.Contains(output, \"INFO\") {\r\n\t\tt.Error(\"Info message not found in output\")\r\n\t}\r\n\tif !strings.Contains(output, \"WARNING\") {\r\n\t\tt.Error(\"Warning message not found in output\")\r\n\t}\r\n\tif !strings.Contains(output, \"ERROR\") {\r\n\t\tt.Error(\"Error message not found in output\")\r\n\t}\r\n\r\n\t// Test silent mode\r\n\tSetSilentMode(true)\r\n\tInfo(\"This message should not appear\")\r\n\r\n\tif strings.Contains(output, \"This message should not appear\") {\r\n\t\tt.Error(\"Silent mode failed\")\r\n\t}\r\n\r\n\t// Clean up\r\n\tClose()\r\n}\r\n",
    "size": 1197,
    "modTime": "2024-10-13T22:45:07.5981593+02:00",
    "path": "internal\\logger\\logger_test.go"
  },
  {
    "name": "parallel.go",
    "content": "package parallel\r\n\r\nimport (\r\n    \"sync\"\r\n    \"time\"\r\n\r\n    \"github.com/piprate/json-gold/ld\"\r\n    \"github.com/chrlesur/json-ld-converter/internal/config\"\r\n    \"github.com/chrlesur/json-ld-converter/internal/logger\"\r\n    \"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n    \"github.com/chrlesur/json-ld-converter/internal/converter\"\r\n)\r\n\r\n// ParallelProcessor gère le traitement parallèle des documents\r\ntype ParallelProcessor struct {\r\n    numWorkers int\r\n    converter  *converter.JSONLDConverter\r\n    config     *config.Config\r\n}\r\n\r\n// NewParallelProcessor crée une nouvelle instance de ParallelProcessor\r\nfunc NewParallelProcessor(numWorkers int, cfg *config.Config) *ParallelProcessor {\r\n    return \u0026ParallelProcessor{\r\n        numWorkers: numWorkers,\r\n        converter:  converter.NewJSONLDConverter(cfg),\r\n        config:     cfg,\r\n    }\r\n}\r\n\r\n// Process traite une liste de documents en parallèle\r\nfunc (p *ParallelProcessor) Process(docs []*parser.Document) ([]*ld.RDFDataset, error) {\r\n    start := time.Now()\r\n    logger.Info(\"Démarrage du traitement parallèle\")\r\n\r\n    results := make([]*ld.RDFDataset, len(docs))\r\n    errors := make([]error, len(docs))\r\n\r\n    jobs := make(chan int, len(docs))\r\n    var wg sync.WaitGroup\r\n\r\n    // Création des workers\r\n    for w := 0; w \u003c p.numWorkers; w++ {\r\n        wg.Add(1)\r\n        go p.worker(w, jobs, docs, results, errors, \u0026wg)\r\n    }\r\n\r\n    // Envoi des tâches aux workers\r\n    for i := range docs {\r\n        jobs \u003c- i\r\n    }\r\n    close(jobs)\r\n\r\n    // Attente de la fin du traitement\r\n    wg.Wait()\r\n\r\n    // Traitement des erreurs\r\n    for i, err := range errors {\r\n        if err != nil {\r\n            logger.Error(\"Erreur lors du traitement du document %d: %v\", i, err)\r\n        }\r\n    }\r\n\r\n    duration := time.Since(start)\r\n    docsPerSecond := float64(len(docs)) / duration.Seconds()\r\n    logger.Info(\"Traitement terminé en %v. %f documents/seconde\", duration, docsPerSecond)\r\n\r\n    return results, nil\r\n}\r\n\r\n// worker est la fonction exécutée par chaque goroutine worker\r\nfunc (p *ParallelProcessor) worker(id int, jobs \u003c-chan int, docs []*parser.Document, results []*ld.RDFDataset, errors []error, wg *sync.WaitGroup) {\r\n    defer wg.Done()\r\n    for j := range jobs {\r\n        logger.Debug(\"Worker %d traite le document %d\", id, j)\r\n        result, err := p.converter.Convert(docs[j])\r\n        results[j] = result\r\n        errors[j] = err\r\n    }\r\n}",
    "size": 2433,
    "modTime": "2024-10-13T23:27:00.5171181+02:00",
    "path": "internal\\parallel\\parallel.go"
  },
  {
    "name": "parallel_test.go",
    "content": "package parallel\r\n\r\nimport (\r\n\t\"testing\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/config\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n)\r\n\r\nfunc TestParallelProcessor(t *testing.T) {\r\n\t// Création d'une configuration de test\r\n\tcfg := \u0026config.Config{}\r\n\r\n\t// Création de documents de test\r\n\tdocs := []*parser.Document{\r\n\t\t{Content: \"Document 1\"},\r\n\t\t{Content: \"Document 2\"},\r\n\t\t{Content: \"Document 3\"},\r\n\t}\r\n\r\n\t// Création du processeur parallèle\r\n\tprocessor := NewParallelProcessor(2, cfg)\r\n\r\n\t// Exécution du traitement parallèle\r\n\tresults, err := processor.Process(docs)\r\n\r\n\t// Vérification des résultats\r\n\tif err != nil {\r\n\t\tt.Errorf(\"Erreur inattendue : %v\", err)\r\n\t}\r\n\tif len(results) != len(docs) {\r\n\t\tt.Errorf(\"Nombre de résultats incorrect. Attendu : %d, Obtenu : %d\", len(docs), len(results))\r\n\t}\r\n\r\n\t// Ajoutez d'autres vérifications selon vos besoins spécifiques\r\n}\r\n",
    "size": 914,
    "modTime": "2024-10-13T23:27:31.6291038+02:00",
    "path": "internal\\parallel\\parallel_test.go"
  },
  {
    "name": "factory.go",
    "content": "package parser\r\n\r\nimport \"fmt\"\r\n\r\nfunc NewParser(fileType string) (Parser, error) {\r\n\tswitch fileType {\r\n\tcase \"text\":\r\n\t\treturn NewTextParser(), nil\r\n\tcase \"markdown\":\r\n\t\treturn NewMarkdownParser(), nil\r\n\tcase \"pdf\":\r\n\t\treturn NewPDFParser(), nil\r\n\tcase \"html\":\r\n\t\treturn NewHTMLParser(), nil\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"unsupported file type: %s\", fileType)\r\n\t}\r\n}",
    "size": 376,
    "modTime": "2024-10-14T18:49:41.5361146+02:00",
    "path": "internal\\parser\\factory.go"
  },
  {
    "name": "html.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"io\"\r\n\t\"strings\"\r\n\r\n\t\"golang.org/x/net/html\"\r\n)\r\n\r\ntype HTMLParser struct{}\r\n\r\nfunc NewHTMLParser() *HTMLParser {\r\n\treturn \u0026HTMLParser{}\r\n}\r\n\r\nfunc (p *HTMLParser) Parse(r io.Reader) (*Document, error) {\r\n\tdoc, err := html.Parse(r)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\tvar contentBuilder strings.Builder\r\n\tvar structure []DocumentElement\r\n\r\n\tvar f func(*html.Node)\r\n\tf = func(n *html.Node) {\r\n\t\tif n.Type == html.TextNode {\r\n\t\t\tcontentBuilder.WriteString(n.Data)\r\n\t\t}\r\n\t\tif n.Type == html.ElementNode {\r\n\t\t\telement := DocumentElement{\r\n\t\t\t\tType: n.Data,\r\n\t\t\t}\r\n\t\t\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\r\n\t\t\t\tf(c)\r\n\t\t\t\tif c.Type == html.TextNode {\r\n\t\t\t\t\telement.Content += c.Data\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tstructure = append(structure, element)\r\n\t\t} else {\r\n\t\t\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\r\n\t\t\t\tf(c)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tf(doc)\r\n\r\n\treturn \u0026Document{\r\n\t\tContent:   contentBuilder.String(),\r\n\t\tMetadata:  make(map[string]string),\r\n\t\tStructure: structure,\r\n\t}, nil\r\n}\r\n",
    "size": 1027,
    "modTime": "2024-10-13T22:57:11.0054213+02:00",
    "path": "internal\\parser\\html.go"
  },
  {
    "name": "interface.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"io\"\r\n)\r\n\r\ntype Document struct {\r\n\tContent   string\r\n\tMetadata  map[string]string\r\n\tStructure []DocumentElement\r\n}\r\n\r\ntype DocumentElement struct {\r\n\tType     string // e.g., \"paragraph\", \"heading\", \"list\", etc.\r\n\tContent  string\r\n\tChildren []DocumentElement\r\n}\r\n\r\ntype Parser interface {\r\n\tParse(r io.Reader) (*Document, error)\r\n}\r\n",
    "size": 363,
    "modTime": "2024-10-13T22:55:13.159867+02:00",
    "path": "internal\\parser\\interface.go"
  },
  {
    "name": "markdown.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"io\"\r\n\r\n\t\"github.com/yuin/goldmark\"\r\n\t\"github.com/yuin/goldmark/ast\"\r\n\t\"github.com/yuin/goldmark/text\"\r\n)\r\n\r\ntype MarkdownParser struct{}\r\n\r\nfunc NewMarkdownParser() *MarkdownParser {\r\n\treturn \u0026MarkdownParser{}\r\n}\r\n\r\nfunc (p *MarkdownParser) Parse(r io.Reader) (*Document, error) {\r\n\tcontent, err := io.ReadAll(r)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\tmd := goldmark.New()\r\n\treader := text.NewReader(content)\r\n\tdoc := md.Parser().Parse(reader)\r\n\r\n\tvar structure []DocumentElement\r\n\terr = ast.Walk(doc, func(n ast.Node, entering bool) (ast.WalkStatus, error) {\r\n\t\tif !entering {\r\n\t\t\treturn ast.WalkContinue, nil\r\n\t\t}\r\n\r\n\t\tswitch n.Kind() {\r\n\t\tcase ast.KindHeading:\r\n\t\t\theading := n.(*ast.Heading)\r\n\t\t\tstructure = append(structure, DocumentElement{\r\n\t\t\t\tType:    \"heading\",\r\n\t\t\t\tContent: string(heading.Text(content)),\r\n\t\t\t})\r\n\t\tcase ast.KindParagraph:\r\n\t\t\tparagraph := n.(*ast.Paragraph)\r\n\t\t\tstructure = append(structure, DocumentElement{\r\n\t\t\t\tType:    \"paragraph\",\r\n\t\t\t\tContent: string(paragraph.Text(content)),\r\n\t\t\t})\r\n\t\t\t// Add more cases for other Markdown elements as needed\r\n\t\t}\r\n\r\n\t\treturn ast.WalkContinue, nil\r\n\t})\r\n\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\treturn \u0026Document{\r\n\t\tContent:   string(content),\r\n\t\tMetadata:  make(map[string]string),\r\n\t\tStructure: structure,\r\n\t}, nil\r\n}\r\n",
    "size": 1332,
    "modTime": "2024-10-13T22:55:43.7152936+02:00",
    "path": "internal\\parser\\markdown.go"
  },
  {
    "name": "parser_test.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"strings\"\r\n\t\"testing\"\r\n)\r\n\r\nfunc TestTextParser(t *testing.T) {\r\n\tinput := \"This is a test.\\nThis is another line.\"\r\n\tparser := NewTextParser()\r\n\tdoc, err := parser.Parse(strings.NewReader(input))\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"Failed to parse text: %v\", err)\r\n\t}\r\n\tif doc.Content != input+\"\\n\" {\r\n\t\tt.Errorf(\"Expected content %q, got %q\", input+\"\\n\", doc.Content)\r\n\t}\r\n\tif len(doc.Structure) != 2 {\r\n\t\tt.Errorf(\"Expected 2 paragraphs, got %d\", len(doc.Structure))\r\n\t}\r\n}\r\n\r\nfunc TestMarkdownParser(t *testing.T) {\r\n\tinput := \"# Heading\\n\\nThis is a paragraph.\"\r\n\tparser := NewMarkdownParser()\r\n\tdoc, err := parser.Parse(strings.NewReader(input))\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"Failed to parse markdown: %v\", err)\r\n\t}\r\n\tif len(doc.Structure) != 2 {\r\n\t\tt.Errorf(\"Expected 2 elements (heading and paragraph), got %d\", len(doc.Structure))\r\n\t}\r\n\tif doc.Structure[0].Type != \"heading\" || doc.Structure[1].Type != \"paragraph\" {\r\n\t\tt.Errorf(\"Unexpected structure types\")\r\n\t}\r\n}\r\n\r\n// Add similar tests for PDF and HTML parsers\r\n",
    "size": 1050,
    "modTime": "2024-10-13T22:57:42.8670185+02:00",
    "path": "internal\\parser\\parser_test.go"
  },
  {
    "name": "pdf.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"io\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/ledongthuc/pdf\"\r\n)\r\n\r\ntype PDFParser struct{}\r\n\r\nfunc NewPDFParser() *PDFParser {\r\n\treturn \u0026PDFParser{}\r\n}\r\n\r\nfunc (p *PDFParser) Parse(r io.Reader) (*Document, error) {\r\n\tcontent, err := io.ReadAll(r)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\t// Créer un io.ReaderAt à partir du contenu\r\n\tcontentReader := strings.NewReader(string(content))\r\n\tsize := int64(len(content))\r\n\r\n\treader, err := pdf.NewReader(contentReader, size)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\tvar contentBuilder strings.Builder\r\n\tvar structure []DocumentElement\r\n\r\n\tnumPages := reader.NumPage()\r\n\r\n\tfor pageIndex := 1; pageIndex \u003c= numPages; pageIndex++ {\r\n\t\tpage := reader.Page(pageIndex)\r\n\t\tif page.V.IsNull() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\r\n\t\ttext, err := page.GetPlainText(nil)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\r\n\t\tcontentBuilder.WriteString(text)\r\n\t\tstructure = append(structure, DocumentElement{\r\n\t\t\tType:    \"page\",\r\n\t\t\tContent: text,\r\n\t\t})\r\n\t}\r\n\r\n\treturn \u0026Document{\r\n\t\tContent:   contentBuilder.String(),\r\n\t\tMetadata:  make(map[string]string),\r\n\t\tStructure: structure,\r\n\t}, nil\r\n}\r\n",
    "size": 1138,
    "modTime": "2024-10-14T19:41:07.3437529+02:00",
    "path": "internal\\parser\\pdf.go"
  },
  {
    "name": "text.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"bufio\"\r\n\t\"io\"\r\n\t\"strings\"\r\n)\r\n\r\ntype TextParser struct{}\r\n\r\nfunc NewTextParser() *TextParser {\r\n\treturn \u0026TextParser{}\r\n}\r\n\r\nfunc (p *TextParser) Parse(r io.Reader) (*Document, error) {\r\n\tscanner := bufio.NewScanner(r)\r\n\tvar content strings.Builder\r\n\tvar structure []DocumentElement\r\n\r\n\tfor scanner.Scan() {\r\n\t\tline := scanner.Text()\r\n\t\tcontent.WriteString(line + \"\\n\")\r\n\t\tstructure = append(structure, DocumentElement{\r\n\t\t\tType:    \"paragraph\",\r\n\t\t\tContent: line,\r\n\t\t})\r\n\t}\r\n\r\n\tif err := scanner.Err(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\treturn \u0026Document{\r\n\t\tContent:   content.String(),\r\n\t\tMetadata:  make(map[string]string),\r\n\t\tStructure: structure,\r\n\t}, nil\r\n}",
    "size": 698,
    "modTime": "2024-10-13T22:55:25.0023478+02:00",
    "path": "internal\\parser\\text.go"
  },
  {
    "name": "parallel_processor.go",
    "content": "package processing\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"encoding/json\"\r\n\t\"errors\"\r\n\t\"fmt\"\r\n\t\"sort\"\r\n\t\"sync\"\r\n\t\"sync/atomic\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/config\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/jsonld\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/llm\"\r\n\t\"github.com/chrlesur/json-ld-converter/internal/logger\"\r\n)\r\n\r\ntype ParallelProcessor struct {\r\n\tconfig         *config.Config\r\n\tconverter      *jsonld.Converter\r\n\tllmClient      llm.Client\r\n\tworkerPool     chan struct{}\r\n\ttaskQueue      chan Task\r\n\tresultQueue    chan Result\r\n\twg             sync.WaitGroup\r\n\tactiveWorkers  int32\r\n\tsegmentResults []SegmentResult\r\n\tresultMutex    sync.Mutex\r\n\tmaxRetries     int\r\n\tretryDelay     time.Duration\r\n\tfailedTasks    chan Task\r\n}\r\n\r\ntype Task struct {\r\n\tSegment      string\r\n\tInstructions string\r\n\tIndex        int\r\n\tAttempts     int\r\n}\r\n\r\ntype Result struct {\r\n\tJSONLD string\r\n\tError  error\r\n\tIndex  int\r\n}\r\n\r\ntype SegmentResult struct {\r\n\tIndex  int\r\n\tJSONLD string\r\n}\r\n\r\nfunc NewParallelProcessor(cfg *config.Config, converter *jsonld.Converter, llmClient llm.Client) *ParallelProcessor {\r\n\treturn \u0026ParallelProcessor{\r\n\t\tconfig:      cfg,\r\n\t\tconverter:   converter,\r\n\t\tllmClient:   llmClient,\r\n\t\tworkerPool:  make(chan struct{}, cfg.Conversion.NumWorkers),\r\n\t\ttaskQueue:   make(chan Task, cfg.Conversion.QueueSize),\r\n\t\tresultQueue: make(chan Result, cfg.Conversion.QueueSize),\r\n\t\tmaxRetries:  cfg.Conversion.MaxRetries,\r\n\t\tretryDelay:  time.Duration(cfg.Conversion.RetryDelayMs) * time.Millisecond,\r\n\t\tfailedTasks: make(chan Task, cfg.Conversion.QueueSize),\r\n\t}\r\n}\r\n\r\nfunc (pp *ParallelProcessor) startWorkers(ctx context.Context) {\r\n\tfor i := 0; i \u003c pp.config.Conversion.NumWorkers; i++ {\r\n\t\tpp.wg.Add(1)\r\n\t\tgo func(workerID int) {\r\n\t\t\tdefer pp.wg.Done()\r\n\t\t\tlogger.Info(fmt.Sprintf(\"Worker %d started\", workerID))\r\n\t\t\tfor {\r\n\t\t\t\tselect {\r\n\t\t\t\tcase task, ok := \u003c-pp.taskQueue:\r\n\t\t\t\t\tif !ok {\r\n\t\t\t\t\t\tlogger.Info(fmt.Sprintf(\"Worker %d finished\", workerID))\r\n\t\t\t\t\t\treturn\r\n\t\t\t\t\t}\r\n\t\t\t\t\tatomic.AddInt32(\u0026pp.activeWorkers, 1)\r\n\t\t\t\t\tresult := pp.processTask(ctx, task)\r\n\t\t\t\t\tatomic.AddInt32(\u0026pp.activeWorkers, -1)\r\n\t\t\t\t\tpp.resultQueue \u003c- result\r\n\t\t\t\tcase task := \u003c-pp.failedTasks:\r\n\t\t\t\t\tatomic.AddInt32(\u0026pp.activeWorkers, 1)\r\n\t\t\t\t\tresult := pp.processTask(ctx, task)\r\n\t\t\t\t\tatomic.AddInt32(\u0026pp.activeWorkers, -1)\r\n\t\t\t\t\tpp.resultQueue \u003c- result\r\n\t\t\t\tcase \u003c-ctx.Done():\r\n\t\t\t\t\tlogger.Info(fmt.Sprintf(\"Worker %d stopped due to context cancellation\", workerID))\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}(i)\r\n\t}\r\n}\r\n\r\nfunc (pp *ParallelProcessor) processTask(ctx context.Context, task Task) Result {\r\n\tlogger.Debug(fmt.Sprintf(\"Processing task: %v (Attempt: %d)\", task, task.Attempts+1))\r\n\r\n\tenrichedSegment, err := pp.llmClient.EnrichSegment(ctx, task.Segment, task.Instructions)\r\n\tif err != nil {\r\n\t\tlogger.Error(fmt.Sprintf(\"Error enriching segment with LLM: %v\", err))\r\n\t\treturn pp.handleTaskError(task, err)\r\n\t}\r\n\r\n\tjsonLD, err := pp.converter.Convert(enrichedSegment)\r\n\tif err != nil {\r\n\t\tlogger.Error(fmt.Sprintf(\"Error converting to JSON-LD: %v\", err))\r\n\t\treturn pp.handleTaskError(task, err)\r\n\t}\r\n\r\n\treturn Result{JSONLD: jsonLD, Index: task.Index}\r\n}\r\n\r\nfunc (pp *ParallelProcessor) AddTask(segment string, instructions string, index int) error {\r\n\tselect {\r\n\tcase pp.taskQueue \u003c- Task{Segment: segment, Instructions: instructions, Index: index}:\r\n\t\tlogger.Debug(fmt.Sprintf(\"Added task to queue: %s\", segment[:20]))\r\n\t\treturn nil\r\n\tdefault:\r\n\t\treturn errors.New(\"task queue is full\")\r\n\t}\r\n}\r\n\r\nfunc (pp *ParallelProcessor) GetResults() \u003c-chan Result {\r\n\treturn pp.resultQueue\r\n}\r\n\r\nfunc (pp *ParallelProcessor) ProcessSegments(ctx context.Context, segments []string, instructions string) (string, error) {\r\n\tpp.segmentResults = make([]SegmentResult, len(segments))\r\n\tsuccessCount := 0\r\n\r\n\tfor i, segment := range segments {\r\n\t\tif err := pp.AddTask(segment, instructions, i); err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"failed to add task: %w\", err)\r\n\t\t}\r\n\t}\r\n\r\n\tpp.Start(ctx)\r\n\tdefer pp.Stop()\r\n\r\n\tfor successCount \u003c len(segments) {\r\n\t\tselect {\r\n\t\tcase result := \u003c-pp.GetResults():\r\n\t\t\tif result.Error != nil {\r\n\t\t\t\tlogger.Warning(fmt.Sprintf(\"Error processing segment %d: %v\", result.Index, result.Error))\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tpp.addSegmentResult(result)\r\n\t\t\tsuccessCount++\r\n\t\tcase \u003c-ctx.Done():\r\n\t\t\treturn \"\", ctx.Err()\r\n\t\t}\r\n\t}\r\n\r\n\treturn pp.reconcileResults()\r\n}\r\n\r\nfunc (pp *ParallelProcessor) Start(ctx context.Context) {\r\n\tgo pp.startWorkers(ctx)\r\n}\r\n\r\nfunc (pp *ParallelProcessor) Stop() {\r\n\tclose(pp.taskQueue)\r\n\tpp.wg.Wait()\r\n\tclose(pp.resultQueue)\r\n}\r\n\r\nfunc (pp *ParallelProcessor) addSegmentResult(result Result) {\r\n\tpp.resultMutex.Lock()\r\n\tdefer pp.resultMutex.Unlock()\r\n\tpp.segmentResults[result.Index] = SegmentResult{Index: result.Index, JSONLD: result.JSONLD}\r\n}\r\n\r\nfunc (pp *ParallelProcessor) reconcileResults() (string, error) {\r\n\tsort.Slice(pp.segmentResults, func(i, j int) bool {\r\n\t\treturn pp.segmentResults[i].Index \u003c pp.segmentResults[j].Index\r\n\t})\r\n\r\n\tvar combinedResult struct {\r\n\t\tContext string        `json:\"@context\"`\r\n\t\tGraph   []interface{} `json:\"@graph\"`\r\n\t}\r\n\tcombinedResult.Context = \"https://schema.org\"\r\n\r\n\tfor _, segmentResult := range pp.segmentResults {\r\n\t\tvar segmentData map[string]interface{}\r\n\t\tif err := json.Unmarshal([]byte(segmentResult.JSONLD), \u0026segmentData); err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"error unmarshaling segment JSON-LD: %w\", err)\r\n\t\t}\r\n\r\n\t\tif graph, ok := segmentData[\"@graph\"].([]interface{}); ok {\r\n\t\t\tcombinedResult.Graph = append(combinedResult.Graph, graph...)\r\n\t\t}\r\n\t}\r\n\r\n\tfinalJSON, err := json.MarshalIndent(combinedResult, \"\", \"  \")\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error marshaling final JSON-LD: %w\", err)\r\n\t}\r\n\r\n\treturn string(finalJSON), nil\r\n}\r\n\r\nfunc (pp *ParallelProcessor) handleTaskError(task Task, err error) Result {\r\n\tif task.Attempts \u003c pp.maxRetries {\r\n\t\ttask.Attempts++\r\n\t\ttime.Sleep(pp.retryDelay)\r\n\t\tpp.failedTasks \u003c- task\r\n\t\treturn Result{Error: fmt.Errorf(\"task rescheduled for retry: %w\", err), Index: task.Index}\r\n\t}\r\n\treturn Result{Error: fmt.Errorf(\"task failed after %d attempts: %w\", task.Attempts+1, err), Index: task.Index}\r\n}\r\n",
    "size": 6176,
    "modTime": "2024-10-14T18:48:33.4496637+02:00",
    "path": "internal\\processing\\parallel_processor.go"
  },
  {
    "name": "schema.go",
    "content": "package schema\r\n\r\nimport (\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"io/ioutil\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/logger\"\r\n)\r\n\r\ntype SchemaType struct {\r\n\tID           string            `json:\"@id\"`\r\n\tLabel        string            `json:\"rdfs:label\"`\r\n\tComment      string            `json:\"rdfs:comment\"`\r\n\tProperties   []string          `json:\"properties,omitempty\"`\r\n\tSubClassOf   []string          `json:\"subClassOf,omitempty\"`\r\n\tIsPartOf     string            `json:\"isPartOf\"`\r\n\tSource       string            `json:\"source\"`\r\n\tEnumerations map[string]string `json:\"enumerations,omitempty\"`\r\n}\r\n\r\ntype SchemaProperty struct {\r\n\tID             string   `json:\"@id\"`\r\n\tLabel          string   `json:\"rdfs:label\"`\r\n\tComment        string   `json:\"rdfs:comment\"`\r\n\tDomainIncludes []string `json:\"domainIncludes,omitempty\"`\r\n\tRangeIncludes  []string `json:\"rangeIncludes,omitempty\"`\r\n\tIsPartOf       string   `json:\"isPartOf\"`\r\n\tSource         string   `json:\"source\"`\r\n}\r\n\r\ntype SchemaOrg struct {\r\n\tTypes      map[string]SchemaType\r\n\tProperties map[string]SchemaProperty\r\n}\r\n\r\nfunc LoadSchemaOrg(filePath string) (*SchemaOrg, error) {\r\n\tlogger.Debug(fmt.Sprintf(\"Loading Schema.org from file: %s\", filePath))\r\n\r\n\tdata, err := ioutil.ReadFile(filePath)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error reading Schema.org file: %w\", err)\r\n\t}\r\n\r\n\tvar jsonldSchema map[string]interface{}\r\n\tif err := json.Unmarshal(data, \u0026jsonldSchema); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error unmarshaling Schema.org data: %w\", err)\r\n\t}\r\n\r\n\tschema := \u0026SchemaOrg{\r\n\t\tTypes:      make(map[string]SchemaType),\r\n\t\tProperties: make(map[string]SchemaProperty),\r\n\t}\r\n\r\n\tgraph, ok := jsonldSchema[\"@graph\"].([]interface{})\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"@graph element not found or not an array\")\r\n\t}\r\n\r\n\tfor _, item := range graph {\r\n\t\titemMap, ok := item.(map[string]interface{})\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\r\n\t\tid, ok := itemMap[\"@id\"].(string)\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\r\n\t\titemType, ok := itemMap[\"@type\"].(string)\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\r\n\t\tswitch itemType {\r\n\t\tcase \"rdfs:Class\":\r\n\t\t\tschemaType := SchemaType{\r\n\t\t\t\tID:      id,\r\n\t\t\t\tLabel:   getStringValue(itemMap, \"rdfs:label\"),\r\n\t\t\t\tComment: getStringValue(itemMap, \"rdfs:comment\"),\r\n\t\t\t}\r\n\t\t\tschema.Types[id] = schemaType\r\n\t\t\tlogger.Debug(fmt.Sprintf(\"Loaded schema type: %s\", id))\r\n\t\tcase \"rdf:Property\":\r\n\t\t\tschemaProperty := SchemaProperty{\r\n\t\t\t\tID:      id,\r\n\t\t\t\tLabel:   getStringValue(itemMap, \"rdfs:label\"),\r\n\t\t\t\tComment: getStringValue(itemMap, \"rdfs:comment\"),\r\n\t\t\t}\r\n\t\t\tschema.Properties[id] = schemaProperty\r\n\t\t\tlogger.Debug(fmt.Sprintf(\"Loaded schema property: %s\", id))\r\n\t\tdefault:\r\n\t\t\tlogger.Warning(fmt.Sprintf(\"Unknown schema element type: %s for id: %s\", itemType, id))\r\n\t\t}\r\n\t}\r\n\r\n\tif len(schema.Types) == 0 {\r\n\t\treturn nil, fmt.Errorf(\"no types loaded from Schema.org\")\r\n\t}\r\n\r\n\tlogger.Info(fmt.Sprintf(\"Loaded %d types and %d properties from Schema.org\", len(schema.Types), len(schema.Properties)))\r\n\r\n\treturn schema, nil\r\n}\r\n\r\nfunc getStringValue(m map[string]interface{}, key string) string {\r\n\tif v, ok := m[key].(string); ok {\r\n\t\treturn v\r\n\t}\r\n\treturn \"\"\r\n}\r\n\r\nfunc (s *SchemaOrg) GetType(typeName string) (SchemaType, bool) {\r\n\t// Try with \"schema:\" prefix\r\n\tif t, ok := s.Types[\"schema:\"+typeName]; ok {\r\n\t\tlogger.Debug(fmt.Sprintf(\"Found type with schema: prefix: %s\", typeName))\r\n\t\treturn t, true\r\n\t}\r\n\t// Try without prefix\r\n\tif t, ok := s.Types[typeName]; ok {\r\n\t\tlogger.Debug(fmt.Sprintf(\"Found type without prefix: %s\", typeName))\r\n\t\treturn t, true\r\n\t}\r\n\t// Try with lowercase\r\n\tlowercaseTypeName := strings.ToLower(typeName)\r\n\tfor key, value := range s.Types {\r\n\t\tif strings.ToLower(key) == lowercaseTypeName {\r\n\t\t\tlogger.Debug(fmt.Sprintf(\"Found type with case-insensitive match: %s\", key))\r\n\t\t\treturn value, true\r\n\t\t}\r\n\t}\r\n\tlogger.Warning(fmt.Sprintf(\"Type not found: %s\", typeName))\r\n\treturn SchemaType{}, false\r\n}\r\n\r\nfunc (s *SchemaOrg) GetProperty(propertyName string) (SchemaProperty, bool) {\r\n\t// Similar implementation as GetType, but for properties\r\n\tif p, ok := s.Properties[\"schema:\"+propertyName]; ok {\r\n\t\tlogger.Debug(fmt.Sprintf(\"Found property with schema: prefix: %s\", propertyName))\r\n\t\treturn p, true\r\n\t}\r\n\tif p, ok := s.Properties[propertyName]; ok {\r\n\t\tlogger.Debug(fmt.Sprintf(\"Found property without prefix: %s\", propertyName))\r\n\t\treturn p, true\r\n\t}\r\n\tlowercasePropertyName := strings.ToLower(propertyName)\r\n\tfor key, value := range s.Properties {\r\n\t\tif strings.ToLower(key) == lowercasePropertyName {\r\n\t\t\tlogger.Debug(fmt.Sprintf(\"Found property with case-insensitive match: %s\", key))\r\n\t\t\treturn value, true\r\n\t\t}\r\n\t}\r\n\tlogger.Warning(fmt.Sprintf(\"Property not found: %s\", propertyName))\r\n\treturn SchemaProperty{}, false\r\n}\r\n\r\nfunc (s *SchemaOrg) SuggestProperties(typeName string, content string) []string {\r\n\tschemaType, ok := s.GetType(typeName)\r\n\tif !ok {\r\n\t\tlogger.Warning(fmt.Sprintf(\"Cannot suggest properties for unknown type: %s\", typeName))\r\n\t\treturn nil\r\n\t}\r\n\r\n\tvar suggestedProperties []string\r\n\tfor _, propName := range schemaType.Properties {\r\n\t\tprop, ok := s.GetProperty(strings.TrimPrefix(propName, \"schema:\"))\r\n\t\tif ok \u0026\u0026 strings.Contains(strings.ToLower(content), strings.ToLower(prop.Label)) {\r\n\t\t\tsuggestedProperties = append(suggestedProperties, prop.ID)\r\n\t\t\tlogger.Debug(fmt.Sprintf(\"Suggested property for %s: %s\", typeName, prop.ID))\r\n\t\t}\r\n\t}\r\n\r\n\tlogger.Info(fmt.Sprintf(\"Suggested %d properties for type %s\", len(suggestedProperties), typeName))\r\n\treturn suggestedProperties\r\n}\r\n",
    "size": 5543,
    "modTime": "2024-10-15T00:01:18.1162309+02:00",
    "path": "internal\\schema\\schema.go"
  },
  {
    "name": "schema_test.go",
    "content": "package schema\r\n\r\nimport (\r\n\t\"testing\"\r\n)\r\n\r\nfunc TestLoadSchemaOrg(t *testing.T) {\r\n\tschema, err := LoadSchemaOrg(\"testdata/schema.json\")\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"Failed to load Schema.org: %v\", err)\r\n\t}\r\n\r\n\tif len(schema.Types) == 0 {\r\n\t\tt.Error(\"No types loaded from Schema.org\")\r\n\t}\r\n\r\n\tif len(schema.Properties) == 0 {\r\n\t\tt.Error(\"No properties loaded from Schema.org\")\r\n\t}\r\n\r\n\t// Test GetType\r\n\tperson, ok := schema.GetType(\"Person\")\r\n\tif !ok {\r\n\t\tt.Error(\"Failed to get Person type\")\r\n\t} else if person.Label != \"Person\" {\r\n\t\tt.Errorf(\"Unexpected label for Person: %s\", person.Label)\r\n\t}\r\n\r\n\t// Test GetProperty\r\n\tname, ok := schema.GetProperty(\"name\")\r\n\tif !ok {\r\n\t\tt.Error(\"Failed to get name property\")\r\n\t} else if name.Label != \"name\" {\r\n\t\tt.Errorf(\"Unexpected label for name property: %s\", name.Label)\r\n\t}\r\n\r\n\t// Test SuggestProperties\r\n\tsuggestedProps := schema.SuggestProperties(\"Person\", \"John Doe is 30 years old\")\r\n\tif len(suggestedProps) == 0 {\r\n\t\tt.Error(\"No properties suggested for Person\")\r\n\t}\r\n}\r\n",
    "size": 1026,
    "modTime": "2024-10-13T23:06:09.9525685+02:00",
    "path": "internal\\schema\\schema_test.go"
  },
  {
    "name": "segmenter.go",
    "content": "package segmentation\r\n\r\nimport (\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n\t\"github.com/chrlesur/json-ld-converter/pkg/tokenizer\"\r\n)\r\n\r\ntype Segment struct {\r\n\tContent  string\r\n\tMetadata map[string]string\r\n}\r\n\r\ntype Segmenter struct {\r\n\tmaxTokens       int\r\n\ttargetBatchSize int\r\n}\r\n\r\nfunc NewSegmenter(maxTokens, targetBatchSize int) *Segmenter {\r\n\treturn \u0026Segmenter{\r\n\t\tmaxTokens:       maxTokens,\r\n\t\ttargetBatchSize: targetBatchSize,\r\n\t}\r\n}\r\n\r\nfunc SegmentDocument(doc *parser.Document, maxTokens int) ([]Segment, error) {\r\n    var segments []Segment\r\n    var currentSegment strings.Builder\r\n    currentTokens := 0\r\n\r\n    for _, element := range doc.Structure {\r\n        elementTokens := tokenizer.CountTokens(element.Content)\r\n\r\n        if elementTokens \u003e maxTokens {\r\n            // Si l'élément est trop grand, le diviser en sous-segments\r\n            subSegments := splitLargeElement(element, maxTokens)\r\n            segments = append(segments, subSegments...)\r\n        } else if currentTokens+elementTokens \u003e maxTokens {\r\n            if currentSegment.Len() \u003e 0 {\r\n                segments = append(segments, Segment{\r\n                    Content:  currentSegment.String(),\r\n                    Metadata: make(map[string]string),\r\n                })\r\n                currentSegment.Reset()\r\n                currentTokens = 0\r\n            }\r\n            currentSegment.WriteString(element.Content)\r\n            currentSegment.WriteString(\"\\n\")\r\n            currentTokens += elementTokens\r\n        } else {\r\n            currentSegment.WriteString(element.Content)\r\n            currentSegment.WriteString(\"\\n\")\r\n            currentTokens += elementTokens\r\n        }\r\n\r\n        if currentTokens \u003e= maxTokens {\r\n            segments = append(segments, Segment{\r\n                Content:  currentSegment.String(),\r\n                Metadata: make(map[string]string),\r\n            })\r\n            currentSegment.Reset()\r\n            currentTokens = 0\r\n        }\r\n    }\r\n\r\n    if currentSegment.Len() \u003e 0 {\r\n        segments = append(segments, Segment{\r\n            Content:  currentSegment.String(),\r\n            Metadata: make(map[string]string),\r\n        })\r\n    }\r\n\r\n    return segments, nil\r\n}\r\n\r\nfunc splitLargeElement(element parser.DocumentElement, maxTokens int) []Segment {\r\n    var segments []Segment\r\n    content := element.Content\r\n    for len(content) \u003e 0 {\r\n        tokenCount := 0\r\n        var segmentBuilder strings.Builder\r\n        words := strings.Fields(content)\r\n\r\n        for _, word := range words {\r\n            wordTokens := tokenizer.CountTokens(word)\r\n            if tokenCount+wordTokens \u003e maxTokens {\r\n                break\r\n            }\r\n            segmentBuilder.WriteString(word)\r\n            segmentBuilder.WriteString(\" \")\r\n            tokenCount += wordTokens\r\n        }\r\n\r\n        segments = append(segments, Segment{\r\n            Content:  segmentBuilder.String(),\r\n            Metadata: map[string]string{\"type\": element.Type},\r\n        })\r\n\r\n        content = strings.TrimSpace(content[len(segmentBuilder.String()):])\r\n    }\r\n\r\n    return segments\r\n}\r\n",
    "size": 3125,
    "modTime": "2024-10-14T23:48:08.6299843+02:00",
    "path": "internal\\segmentation\\segmenter.go"
  },
  {
    "name": "segmenter_test.go",
    "content": "package segmentation\r\n\r\nimport (\r\n\t\"strings\"\r\n\t\"testing\"\r\n\r\n\t\"github.com/chrlesur/json-ld-converter/internal/parser\"\r\n\t\"github.com/chrlesur/json-ld-converter/pkg/tokenizer\"\r\n)\r\n\r\nfunc TestSegmenter(t *testing.T) {\r\n\tdoc := \u0026parser.Document{\r\n\t\tStructure: []parser.DocumentElement{\r\n\t\t\t{Type: \"heading\", Content: \"Title\"},\r\n\t\t\t{Type: \"paragraph\", Content: \"This is a long paragraph that should be split into multiple segments. \" + strings.Repeat(\"More content. \", 100)},\r\n\t\t\t{Type: \"list\", Content: \"Item 1\\nItem 2\\nItem 3\"},\r\n\t\t},\r\n\t}\r\n\r\n\tsegmenter := NewSegmenter(1000, 500)\r\n\tsegments, err := segmenter.Segment(doc)\r\n\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"Segmentation failed: %v\", err)\r\n\t}\r\n\r\n\tif len(segments) \u003c 2 {\r\n\t\tt.Errorf(\"Expected multiple segments, got %d\", len(segments))\r\n\t}\r\n\r\n\tfor i, segment := range segments {\r\n\t\ttokens := tokenizer.CountTokens(segment.Content)\r\n\t\tif tokens \u003e 1000 {\r\n\t\t\tt.Errorf(\"Segment %d exceeds max tokens: %d\", i, tokens)\r\n\t\t}\r\n\t}\r\n}\r\n",
    "size": 969,
    "modTime": "2024-10-13T23:01:23.4928676+02:00",
    "path": "internal\\segmentation\\segmenter_test.go"
  },
  {
    "name": "tokenizer.go",
    "content": "package tokenizer\r\n\r\nimport (\r\n\t\"strings\"\r\n\t\"unicode\"\r\n)\r\n\r\nfunc CountTokens(text string) int {\r\n\treturn len(strings.Fields(text))\r\n}\r\n\r\nfunc SplitIntoTokens(text string) []string {\r\n\treturn strings.FieldsFunc(text, func(r rune) bool {\r\n\t\treturn unicode.IsSpace(r) || unicode.IsPunct(r)\r\n\t})\r\n}",
    "size": 294,
    "modTime": "2024-10-13T23:02:27.0794128+02:00",
    "path": "pkg\\tokenizer\\tokenizer.go"
  }
]